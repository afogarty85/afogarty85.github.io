<!DOCTYPE html>

<html xmlns="http://www.w3.org/1999/xhtml">

<head>

<meta charset="utf-8" />
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="generator" content="pandoc" />

<meta name="viewport" content="width=device-width, initial-scale=1">

<meta name="author" content="Andrew Fogarty" />


<title>Text Classification: CNN</title>



<style type="text/css">code{white-space: pre;}</style>
<style type="text/css" data-origin="pandoc">
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */

</style>
<script>
// apply pandoc div.sourceCode style to pre.sourceCode instead
(function() {
  var sheets = document.styleSheets;
  for (var i = 0; i < sheets.length; i++) {
    if (sheets[i].ownerNode.dataset["origin"] !== "pandoc") continue;
    try { var rules = sheets[i].cssRules; } catch (e) { continue; }
    for (var j = 0; j < rules.length; j++) {
      var rule = rules[j];
      // check if there is a div.sourceCode rule
      if (rule.type !== rule.STYLE_RULE || rule.selectorText !== "div.sourceCode") continue;
      var style = rule.style.cssText;
      // check if color or background-color is set
      if (rule.style.color === '' || rule.style.backgroundColor === '') continue;
      // replace div.sourceCode by a pre.sourceCode rule
      sheets[i].deleteRule(j);
      sheets[i].insertRule('pre.sourceCode{' + style + '}', j);
    }
  }
})();
</script>



<style type="text/css">body {
background-color: #fff;
margin: 1em auto;
max-width: 700px;
overflow: visible;
padding-left: 2em;
padding-right: 2em;
font-family: "Open Sans", "Helvetica Neue", Helvetica, Arial, sans-serif;
font-size: 14px;
line-height: 1.35;
}
#header {
text-align: center;
}
#TOC {
clear: both;
margin: 0 0 10px 10px;
padding: 4px;
width: 400px;
border: 1px solid #CCCCCC;
border-radius: 5px;
background-color: #f6f6f6;
font-size: 13px;
line-height: 1.3;
}
#TOC .toctitle {
font-weight: bold;
font-size: 15px;
margin-left: 5px;
}
#TOC ul {
padding-left: 40px;
margin-left: -1.5em;
margin-top: 5px;
margin-bottom: 5px;
}
#TOC ul ul {
margin-left: -2em;
}
#TOC li {
line-height: 16px;
}
table {
margin: 1em auto;
border-width: 1px;
border-color: #DDDDDD;
border-style: outset;
border-collapse: collapse;
}
table th {
border-width: 2px;
padding: 5px;
border-style: inset;
}
table td {
border-width: 1px;
border-style: inset;
line-height: 18px;
padding: 5px 5px;
}
table, table th, table td {
border-left-style: none;
border-right-style: none;
}
table thead, table tr.even {
background-color: #f7f7f7;
}
p {
margin: 0.5em 0;
}
blockquote {
background-color: #f6f6f6;
padding: 0.25em 0.75em;
}
hr {
border-style: solid;
border: none;
border-top: 1px solid #777;
margin: 28px 0;
}
dl {
margin-left: 0;
}
dl dd {
margin-bottom: 13px;
margin-left: 13px;
}
dl dt {
font-weight: bold;
}
ul {
margin-top: 0;
}
ul li {
list-style: circle outside;
}
ul ul {
margin-bottom: 0;
}
pre, code {
background-color: #f7f7f7;
border-radius: 3px;
color: #333;
white-space: pre-wrap; 
}
pre {
border-radius: 3px;
margin: 5px 0px 10px 0px;
padding: 10px;
}
pre:not([class]) {
background-color: #f7f7f7;
}
code {
font-family: Consolas, Monaco, 'Courier New', monospace;
font-size: 85%;
}
p > code, li > code {
padding: 2px 0px;
}
div.figure {
text-align: center;
}
img {
background-color: #FFFFFF;
padding: 2px;
border: 1px solid #DDDDDD;
border-radius: 3px;
border: 1px solid #CCCCCC;
margin: 0 5px;
}
h1 {
margin-top: 0;
font-size: 35px;
line-height: 40px;
}
h2 {
border-bottom: 4px solid #f7f7f7;
padding-top: 10px;
padding-bottom: 2px;
font-size: 145%;
}
h3 {
border-bottom: 2px solid #f7f7f7;
padding-top: 10px;
font-size: 120%;
}
h4 {
border-bottom: 1px solid #f7f7f7;
margin-left: 8px;
font-size: 105%;
}
h5, h6 {
border-bottom: 1px solid #ccc;
font-size: 105%;
}
a {
color: #0033dd;
text-decoration: none;
}
a:hover {
color: #6666ff; }
a:visited {
color: #800080; }
a:visited:hover {
color: #BB00BB; }
a[href^="http:"] {
text-decoration: underline; }
a[href^="https:"] {
text-decoration: underline; }

code > span.kw { color: #555; font-weight: bold; } 
code > span.dt { color: #902000; } 
code > span.dv { color: #40a070; } 
code > span.bn { color: #d14; } 
code > span.fl { color: #d14; } 
code > span.ch { color: #d14; } 
code > span.st { color: #d14; } 
code > span.co { color: #888888; font-style: italic; } 
code > span.ot { color: #007020; } 
code > span.al { color: #ff0000; font-weight: bold; } 
code > span.fu { color: #900; font-weight: bold; }  code > span.er { color: #a61717; background-color: #e3d2d2; } 
</style>




</head>

<body>




<h1 class="title toc-ignore">Text Classification: CNN</h1>
<h4 class="author">Andrew Fogarty</h4>
<h4 class="date">7/14/2020</h4>


<div id="TOC">
<ul>
<li><a href="#introduction"><span class="toc-section-number">1</span> Introduction</a></li>
<li><a href="#convolutional-neural-networks"><span class="toc-section-number">2</span> Convolutional Neural Networks</a></li>
<li><a href="#cnns-using-glove-embeddings"><span class="toc-section-number">3</span> CNNs using GloVe Embeddings</a></li>
<li><a href="#cnn-inference"><span class="toc-section-number">4</span> CNN: Inference</a></li>
<li><a href="#cnn-hyperband-and-asha-hyperparameter-search-with-optuna"><span class="toc-section-number">5</span> CNN: Hyperband and ASHA Hyperparameter Search with Optuna</a></li>
<li><a href="#sources"><span class="toc-section-number">6</span> Sources</a></li>
</ul>
</div>

<div class="sourceCode" id="cb1"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb1-1"><a href="#cb1-1"></a><span class="co"># load python</span></span>
<span id="cb1-2"><a href="#cb1-2"></a><span class="kw">library</span>(reticulate)</span>
<span id="cb1-3"><a href="#cb1-3"></a><span class="kw">use_condaenv</span>(<span class="st">&quot;my_ml&quot;</span>)</span></code></pre></div>
<div class="sourceCode" id="cb2"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb2-1"><a href="#cb2-1"></a><span class="co"># load packages</span></span>
<span id="cb2-2"><a href="#cb2-2"></a><span class="im">import</span> torch</span>
<span id="cb2-3"><a href="#cb2-3"></a><span class="im">import</span> torch.nn <span class="im">as</span> nn</span>
<span id="cb2-4"><a href="#cb2-4"></a><span class="im">import</span> torch.nn.functional <span class="im">as</span> F</span>
<span id="cb2-5"><a href="#cb2-5"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb2-6"><a href="#cb2-6"></a><span class="im">import</span> pandas <span class="im">as</span> pd</span>
<span id="cb2-7"><a href="#cb2-7"></a><span class="im">from</span> sklearn.model_selection <span class="im">import</span> train_test_split</span>
<span id="cb2-8"><a href="#cb2-8"></a><span class="im">import</span> torch.optim <span class="im">as</span> optim</span>
<span id="cb2-9"><a href="#cb2-9"></a><span class="im">from</span> torchvision <span class="im">import</span> datasets, transforms</span>
<span id="cb2-10"><a href="#cb2-10"></a><span class="im">from</span> torch.utils.data <span class="im">import</span> TensorDataset, random_split, DataLoader, RandomSampler, SequentialSampler</span>
<span id="cb2-11"><a href="#cb2-11"></a><span class="im">import</span> time, datetime, re, random, string</span>
<span id="cb2-12"><a href="#cb2-12"></a><span class="im">from</span> sklearn.metrics <span class="im">import</span> accuracy_score, f1_score, precision_score, recall_score</span>
<span id="cb2-13"><a href="#cb2-13"></a><span class="im">from</span> collections <span class="im">import</span> Counter</span>
<span id="cb2-14"><a href="#cb2-14"></a><span class="im">from</span> transformers <span class="im">import</span> get_linear_schedule_with_warmup</span>
<span id="cb2-15"><a href="#cb2-15"></a><span class="im">from</span> itertools <span class="im">import</span> repeat</span>
<span id="cb2-16"><a href="#cb2-16"></a><span class="im">import</span> optuna</span>
<span id="cb2-17"><a href="#cb2-17"></a><span class="im">from</span> optuna.pruners <span class="im">import</span> SuccessiveHalvingPruner</span>
<span id="cb2-18"><a href="#cb2-18"></a><span class="im">from</span> optuna.samplers <span class="im">import</span> TPESampler</span>
<span id="cb2-19"><a href="#cb2-19"></a><span class="im">import</span> matplotlib.pyplot <span class="im">as</span> plt</span>
<span id="cb2-20"><a href="#cb2-20"></a><span class="im">import</span> seaborn <span class="im">as</span> sns</span>
<span id="cb2-21"><a href="#cb2-21"></a><span class="im">from</span> torch.cuda.amp <span class="im">import</span> autocast, GradScaler</span>
<span id="cb2-22"><a href="#cb2-22"></a><span class="im">from</span> transformers <span class="im">import</span> get_linear_schedule_with_warmup, AdamW</span>
<span id="cb2-23"><a href="#cb2-23"></a></span>
<span id="cb2-24"><a href="#cb2-24"></a>SEED <span class="op">=</span> <span class="dv">15</span></span>
<span id="cb2-25"><a href="#cb2-25"></a>random.seed(SEED)</span>
<span id="cb2-26"><a href="#cb2-26"></a>np.random.seed(SEED)</span>
<span id="cb2-27"><a href="#cb2-27"></a>torch.manual_seed(SEED)</span></code></pre></div>
<pre><code>## &lt;torch._C.Generator object at 0x000000001FAEE050&gt;</code></pre>
<div class="sourceCode" id="cb4"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb4-1"><a href="#cb4-1"></a>torch.backends.cudnn.deterministic <span class="op">=</span> <span class="va">True</span></span>
<span id="cb4-2"><a href="#cb4-2"></a>torch.cuda.amp.autocast(enabled<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb4-3"><a href="#cb4-3"></a></span>
<span id="cb4-4"><a href="#cb4-4"></a><span class="co"># tell pytorch to use cuda</span></span></code></pre></div>
<pre><code>## &lt;torch.cuda.amp.autocast_mode.autocast object at 0x0000000034066848&gt;</code></pre>
<div class="sourceCode" id="cb6"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb6-1"><a href="#cb6-1"></a>device <span class="op">=</span> torch.device(<span class="st">&quot;cuda&quot;</span>)</span></code></pre></div>
<div id="introduction" class="section level1" number="1">
<h1 number="1"><span class="header-section-number">1</span> Introduction</h1>
<p>Text or sequence classification aims to label a sentence or document based on its content. In this post, we use Convolutional Neural Networks to classify a novel data set that I created based on insurgent propaganda messages. This guide stands in contrast to other walk-throughs on the model in that it: (1) offers a full treatment of data preparation and PyTorch, (2) uses GloVe embeddings correctly by taking into account unknown or padding tokens by generating unique vectors for them, and (3) specifically tells the <code>embedding</code> layer which look-up index is the padding token.</p>
</div>
<div id="convolutional-neural-networks" class="section level1" number="2">
<h1 number="2"><span class="header-section-number">2</span> Convolutional Neural Networks</h1>
<p>In this section, we run a CNN with GloVe embeddings after addressing some of the high points about CNNs. Convolutional layers aim to find spatial patterns, predominantly in images, through the use of <em>kernels</em>. Kernels can be thought of as small windows that slide across the pixels of an image - calculating the respective weight by multiplying the pixel values with the kernel weight. These values are then summed to get a filtered pixel value which in turn are representative of local features.</p>
<p>In Natural Language Processing, text is one-dimensional but we often represent each word (or character) with an embedding vector, thereby giving our text a two-dimensional representation. The convolutional kernel slides over the embeddings (features) of multiple words rather than pixels. Instead of three input channels like Red Green Blue for images, text processing has just 1 (akin to gray scale) because a single sentence/document will be associated with a single list of embeddings. To slide a kernel over sequences of word embeddings, the sliding window needs to be allowed to look at multiple word embeddings in a sequence. Instead of a square, kernels take on shapes associated with the number of words (<span class="math inline">\(n\)</span>) to look at in a sequence and the length of the embedding sequence (<span class="math inline">\(m\)</span>). This <span class="math inline">\(n\times m\)</span> kernel tells us how many word embeddings it will view at once, like n-grams, while also the length of the word embedding that it will take it account, say 200 or 300 for GLoVe or 768 for BERT.</p>
<p>CNNs tend to include multiple kernel heights, typically 3, each representing a different n-gram range. As a CNN trains, kernel weights are learned for words and surrounding words in a sequential window, yielding local features. CNNs then use max-pooling which aims to retain only the most important (highest value) local feature while discarding less important features.</p>
</div>
<div id="cnns-using-glove-embeddings" class="section level1" number="3">
<h1 number="3"><span class="header-section-number">3</span> CNNs using GloVe Embeddings</h1>
<p>GloVe is a common set of embeddings used by practitioners and academics in text analysis containing features for 400,000 words. Embeddings capture the similarities between words (e.g., they have high cosine similarities) and are the basis of NLP. Word embedding methods represent words as continuous vectors in a low dimensional space which capture lexical and semantic properties of words. Embeddings can be obtained from the internal representations from neural network models of text or by low rank approximation of co-occurrence statistics.</p>
<p>In this section, I will describe how to set up, correctly, a CNN in PyTorch that relies on GloVe. I begin by loading and preparing my data, sub-setting it to yield only two classes.</p>
<div class="sourceCode" id="cb7"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb7-1"><a href="#cb7-1"></a><span class="co"># prepare and load data</span></span>
<span id="cb7-2"><a href="#cb7-2"></a><span class="kw">def</span> prepare_df(pkl_location):</span>
<span id="cb7-3"><a href="#cb7-3"></a>    <span class="co"># read pkl as pandas</span></span>
<span id="cb7-4"><a href="#cb7-4"></a>    df <span class="op">=</span> pd.read_pickle(pkl_location)</span>
<span id="cb7-5"><a href="#cb7-5"></a>    <span class="co"># just keep us/kabul labels</span></span>
<span id="cb7-6"><a href="#cb7-6"></a>    df <span class="op">=</span> df.loc[(df[<span class="st">&#39;target&#39;</span>] <span class="op">==</span> <span class="st">&#39;US&#39;</span>) <span class="op">|</span> (df[<span class="st">&#39;target&#39;</span>] <span class="op">==</span> <span class="st">&#39;Kabul&#39;</span>)]</span>
<span id="cb7-7"><a href="#cb7-7"></a>    <span class="co"># mask DV to recode</span></span>
<span id="cb7-8"><a href="#cb7-8"></a>    us <span class="op">=</span> df[<span class="st">&#39;target&#39;</span>] <span class="op">==</span> <span class="st">&#39;US&#39;</span></span>
<span id="cb7-9"><a href="#cb7-9"></a>    kabul <span class="op">=</span> df[<span class="st">&#39;target&#39;</span>] <span class="op">==</span> <span class="st">&#39;Kabul&#39;</span></span>
<span id="cb7-10"><a href="#cb7-10"></a>    <span class="co"># apply mask</span></span>
<span id="cb7-11"><a href="#cb7-11"></a>    df.loc[us, <span class="st">&#39;target&#39;</span>] <span class="op">=</span> <span class="dv">1</span></span>
<span id="cb7-12"><a href="#cb7-12"></a>    df.loc[kabul, <span class="st">&#39;target&#39;</span>] <span class="op">=</span> <span class="dv">0</span></span>
<span id="cb7-13"><a href="#cb7-13"></a>    <span class="co"># reset index</span></span>
<span id="cb7-14"><a href="#cb7-14"></a>    df <span class="op">=</span> df.reset_index(drop<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb7-15"><a href="#cb7-15"></a>    <span class="cf">return</span> df</span>
<span id="cb7-16"><a href="#cb7-16"></a></span>
<span id="cb7-17"><a href="#cb7-17"></a></span>
<span id="cb7-18"><a href="#cb7-18"></a>df <span class="op">=</span> prepare_df(<span class="st">&#39;C:</span><span class="ch">\\</span><span class="st">Users</span><span class="ch">\\</span><span class="st">Andrew</span><span class="ch">\\</span><span class="st">Desktop</span><span class="ch">\\</span><span class="st">df.pkl&#39;</span>)</span></code></pre></div>
<p>Next, I do a small amount of additional data cleaning to my text, as described below.</p>
<div class="sourceCode" id="cb8"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb8-1"><a href="#cb8-1"></a><span class="co"># prepare data</span></span>
<span id="cb8-2"><a href="#cb8-2"></a><span class="kw">def</span> clean_df(df):</span>
<span id="cb8-3"><a href="#cb8-3"></a>    <span class="co"># strip dash but keep a space</span></span>
<span id="cb8-4"><a href="#cb8-4"></a>    df[<span class="st">&#39;body&#39;</span>] <span class="op">=</span> df[<span class="st">&#39;body&#39;</span>].<span class="bu">str</span>.replace(<span class="st">&#39;-&#39;</span>, <span class="st">&#39; &#39;</span>)</span>
<span id="cb8-5"><a href="#cb8-5"></a>    <span class="co"># prepare keys for punctuation removal</span></span>
<span id="cb8-6"><a href="#cb8-6"></a>    translator <span class="op">=</span> <span class="bu">str</span>.maketrans(<span class="bu">dict</span>.fromkeys(string.punctuation))</span>
<span id="cb8-7"><a href="#cb8-7"></a>    <span class="co"># lower case the data</span></span>
<span id="cb8-8"><a href="#cb8-8"></a>    df[<span class="st">&#39;body&#39;</span>] <span class="op">=</span> df[<span class="st">&#39;body&#39;</span>].<span class="bu">apply</span>(<span class="kw">lambda</span> x: x.lower())</span>
<span id="cb8-9"><a href="#cb8-9"></a>    <span class="co"># remove excess spaces near punctuation</span></span>
<span id="cb8-10"><a href="#cb8-10"></a>    df[<span class="st">&#39;body&#39;</span>] <span class="op">=</span> df[<span class="st">&#39;body&#39;</span>].<span class="bu">apply</span>(<span class="kw">lambda</span> x: re.sub(<span class="vs">r&#39;\s([?.!&quot;](?:\s|$))&#39;</span>, <span class="vs">r&#39;\1&#39;</span>, x))</span>
<span id="cb8-11"><a href="#cb8-11"></a>    <span class="co"># remove punctuation  -- f1 improves by .05 by disabling this</span></span>
<span id="cb8-12"><a href="#cb8-12"></a>    df[<span class="st">&#39;body&#39;</span>] <span class="op">=</span> df[<span class="st">&#39;body&#39;</span>].<span class="bu">apply</span>(<span class="kw">lambda</span> x: x.translate(translator))</span>
<span id="cb8-13"><a href="#cb8-13"></a>    <span class="co"># generate a word count</span></span>
<span id="cb8-14"><a href="#cb8-14"></a>    df[<span class="st">&#39;word_count&#39;</span>] <span class="op">=</span> df[<span class="st">&#39;body&#39;</span>].<span class="bu">apply</span>(<span class="kw">lambda</span> x: <span class="bu">len</span>(x.split()))</span>
<span id="cb8-15"><a href="#cb8-15"></a>    <span class="co"># remove excess white spaces</span></span>
<span id="cb8-16"><a href="#cb8-16"></a>    df[<span class="st">&#39;body&#39;</span>] <span class="op">=</span> df[<span class="st">&#39;body&#39;</span>].<span class="bu">apply</span>(<span class="kw">lambda</span> x: <span class="st">&quot; &quot;</span>.join(x.split()))</span>
<span id="cb8-17"><a href="#cb8-17"></a></span>
<span id="cb8-18"><a href="#cb8-18"></a>    <span class="cf">return</span> df</span>
<span id="cb8-19"><a href="#cb8-19"></a>    </span>
<span id="cb8-20"><a href="#cb8-20"></a>df <span class="op">=</span> clean_df(df)</span></code></pre></div>
<p>Since my corpus includes transliterations of Afghan words, there are a sizable amount of words that are not in the GloVe embedding and are otherwise probably not very helpful to helping us understand important local features through the lens of a CNN even if we were to give them coefficients for an unknown word. As such, I remove rare words from my corpus by:</p>
<ol style="list-style-type: decimal">
<li>collecting counts of each word in a key:value pair dictionary</li>
<li>removing keys from the dictionary if used less than twice</li>
<li>using <code>filter</code> to drop the rare words from the list</li>
</ol>
<div class="sourceCode" id="cb9"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb9-1"><a href="#cb9-1"></a><span class="co"># lets remove rare words</span></span>
<span id="cb9-2"><a href="#cb9-2"></a><span class="kw">def</span> remove_rare_words(df):</span>
<span id="cb9-3"><a href="#cb9-3"></a>    <span class="co"># get counts of each word -- necessary for vocab</span></span>
<span id="cb9-4"><a href="#cb9-4"></a>    counts <span class="op">=</span> Counter(<span class="st">&quot; &quot;</span>.join(df[<span class="st">&#39;body&#39;</span>].values.tolist()).split(<span class="st">&quot; &quot;</span>))</span>
<span id="cb9-5"><a href="#cb9-5"></a>    <span class="co"># remove low counts -- keep those above 2</span></span>
<span id="cb9-6"><a href="#cb9-6"></a>    counts <span class="op">=</span> {key: value <span class="cf">for</span> key, value <span class="kw">in</span> counts.items() <span class="cf">if</span> value <span class="op">&gt;</span> <span class="dv">2</span>}</span>
<span id="cb9-7"><a href="#cb9-7"></a></span>
<span id="cb9-8"><a href="#cb9-8"></a>    <span class="co"># remove rare words from corpus</span></span>
<span id="cb9-9"><a href="#cb9-9"></a>    <span class="kw">def</span> remove_rare(x):</span>
<span id="cb9-10"><a href="#cb9-10"></a>        <span class="cf">return</span> <span class="st">&#39; &#39;</span>.join(<span class="bu">list</span>(<span class="bu">filter</span>(<span class="kw">lambda</span> x: x <span class="kw">in</span> counts.keys(), x.split())))</span>
<span id="cb9-11"><a href="#cb9-11"></a></span>
<span id="cb9-12"><a href="#cb9-12"></a>    <span class="co"># apply funx</span></span>
<span id="cb9-13"><a href="#cb9-13"></a>    df[<span class="st">&#39;body&#39;</span>] <span class="op">=</span> df[<span class="st">&#39;body&#39;</span>].<span class="bu">apply</span>(remove_rare)</span>
<span id="cb9-14"><a href="#cb9-14"></a>    <span class="cf">return</span> df</span>
<span id="cb9-15"><a href="#cb9-15"></a></span>
<span id="cb9-16"><a href="#cb9-16"></a></span>
<span id="cb9-17"><a href="#cb9-17"></a>df <span class="op">=</span> remove_rare_words(df)</span></code></pre></div>
<p>Next, I execute a few functions to clean up the data set further and to learn a bit more about my corpus in its entirety.</p>
<div class="sourceCode" id="cb10"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb10-1"><a href="#cb10-1"></a><span class="co"># find min/max word count</span></span>
<span id="cb10-2"><a href="#cb10-2"></a><span class="bu">max</span>(df[<span class="st">&#39;word_count&#39;</span>])</span></code></pre></div>
<pre><code>## 5472</code></pre>
<div class="sourceCode" id="cb12"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb12-1"><a href="#cb12-1"></a><span class="bu">min</span>(df[<span class="st">&#39;word_count&#39;</span>])</span>
<span id="cb12-2"><a href="#cb12-2"></a></span>
<span id="cb12-3"><a href="#cb12-3"></a><span class="co"># trim the corpus of really small messages</span></span></code></pre></div>
<pre><code>## 0</code></pre>
<div class="sourceCode" id="cb14"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb14-1"><a href="#cb14-1"></a>df <span class="op">=</span> df.loc[df[<span class="st">&#39;word_count&#39;</span>] <span class="op">&gt;</span> <span class="dv">20</span>]</span>
<span id="cb14-2"><a href="#cb14-2"></a></span>
<span id="cb14-3"><a href="#cb14-3"></a><span class="co"># what is 95th percentile of word count?</span></span>
<span id="cb14-4"><a href="#cb14-4"></a>percentile_95 <span class="op">=</span> <span class="bu">int</span>(df[<span class="st">&#39;word_count&#39;</span>].quantile(<span class="fl">0.95</span>))</span>
<span id="cb14-5"><a href="#cb14-5"></a><span class="bu">print</span>(percentile_95)</span>
<span id="cb14-6"><a href="#cb14-6"></a></span>
<span id="cb14-7"><a href="#cb14-7"></a><span class="co"># whats the length of the vocab?</span></span></code></pre></div>
<pre><code>## 974</code></pre>
<div class="sourceCode" id="cb16"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb16-1"><a href="#cb16-1"></a>counts <span class="op">=</span> Counter(<span class="st">&quot; &quot;</span>.join(df[<span class="st">&#39;body&#39;</span>].values.tolist()).split(<span class="st">&quot; &quot;</span>))</span>
<span id="cb16-2"><a href="#cb16-2"></a>vocab <span class="op">=</span> <span class="bu">sorted</span>(counts, key<span class="op">=</span>counts.get, reverse<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb16-3"><a href="#cb16-3"></a><span class="bu">print</span>(<span class="bu">len</span>(vocab))</span></code></pre></div>
<pre><code>## 16354</code></pre>
<p>Now I am ready to load my GloVe embeddings.</p>
<div class="sourceCode" id="cb18"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb18-1"><a href="#cb18-1"></a><span class="co"># load GloVe embeddings</span></span>
<span id="cb18-2"><a href="#cb18-2"></a><span class="kw">def</span> load_GloVe(file_path):</span>
<span id="cb18-3"><a href="#cb18-3"></a>    <span class="co"># create empty dict to store data</span></span>
<span id="cb18-4"><a href="#cb18-4"></a>    embeddings_dictionary <span class="op">=</span> <span class="bu">dict</span>()</span>
<span id="cb18-5"><a href="#cb18-5"></a>    <span class="co"># load the file</span></span>
<span id="cb18-6"><a href="#cb18-6"></a>    glove_file <span class="op">=</span> <span class="bu">open</span>(file_path, encoding<span class="op">=</span><span class="st">&quot;utf8&quot;</span>)</span>
<span id="cb18-7"><a href="#cb18-7"></a>    <span class="co"># for each entry</span></span>
<span id="cb18-8"><a href="#cb18-8"></a>    <span class="cf">for</span> line <span class="kw">in</span> glove_file:</span>
<span id="cb18-9"><a href="#cb18-9"></a>        <span class="co"># split on spaces</span></span>
<span id="cb18-10"><a href="#cb18-10"></a>        records <span class="op">=</span> line.split()</span>
<span id="cb18-11"><a href="#cb18-11"></a>        <span class="co"># get the word located in position 0</span></span>
<span id="cb18-12"><a href="#cb18-12"></a>        word <span class="op">=</span> records[<span class="dv">0</span>]</span>
<span id="cb18-13"><a href="#cb18-13"></a>        <span class="co"># get the embeddings which is the remainder</span></span>
<span id="cb18-14"><a href="#cb18-14"></a>        vector_dimensions <span class="op">=</span> np.asarray(records[<span class="dv">1</span>:], dtype<span class="op">=</span><span class="st">&#39;float32&#39;</span>)</span>
<span id="cb18-15"><a href="#cb18-15"></a>        <span class="co"># add to dictionary</span></span>
<span id="cb18-16"><a href="#cb18-16"></a>        embeddings_dictionary[word] <span class="op">=</span> vector_dimensions</span>
<span id="cb18-17"><a href="#cb18-17"></a>    <span class="co"># close the file</span></span>
<span id="cb18-18"><a href="#cb18-18"></a>    glove_file.close()</span>
<span id="cb18-19"><a href="#cb18-19"></a>    <span class="cf">return</span> embeddings_dictionary</span>
<span id="cb18-20"><a href="#cb18-20"></a></span>
<span id="cb18-21"><a href="#cb18-21"></a></span>
<span id="cb18-22"><a href="#cb18-22"></a><span class="co"># load GloVe</span></span>
<span id="cb18-23"><a href="#cb18-23"></a>file_path <span class="op">=</span> <span class="st">&#39;C:</span><span class="ch">\\</span><span class="st">Users</span><span class="ch">\\</span><span class="st">Andrew</span><span class="ch">\\</span><span class="st">Desktop</span><span class="ch">\\</span><span class="st">glove.6B.200d.txt&#39;</span></span>
<span id="cb18-24"><a href="#cb18-24"></a>embeddings_dictionary <span class="op">=</span> load_GloVe(file_path)</span>
<span id="cb18-25"><a href="#cb18-25"></a></span>
<span id="cb18-26"><a href="#cb18-26"></a><span class="co"># useful computing to check vector values and indices</span></span>
<span id="cb18-27"><a href="#cb18-27"></a>embeddings_dictionary.get(<span class="st">&#39;.&#39;</span>)  <span class="co"># get key value</span></span></code></pre></div>
<pre><code>## array([ 1.2289e-01,  5.8037e-01, -6.9635e-02, -5.0288e-01,  1.0503e-01,
##         3.9945e-01, -3.8635e-01, -8.4279e-02,  1.2219e-01,  8.0312e-02,
##         3.2337e-01,  4.7579e-01, -3.8375e-02, -7.0900e-03,  4.1524e-01,
##         3.2121e-01, -2.1185e-01,  3.6144e-01, -5.5623e-02, -3.0512e-02,
##         4.2854e-01,  2.8547e+00, -1.4623e-01, -1.7557e-01,  3.1197e-01,
##        -1.3118e-01,  3.3298e-02,  1.3093e-01,  8.9889e-02, -1.2417e-01,
##         2.3396e-03, -6.8954e-02, -1.0754e-01, -1.1551e-01, -3.1052e-01,
##        -1.2097e-01, -4.6691e-01, -8.3600e-02, -3.7664e-02, -7.1779e-02,
##        -1.1899e-01, -2.0381e-01, -1.2424e-01,  4.6339e-01, -1.9828e-01,
##        -8.0365e-03,  5.3718e-01,  3.1739e-02,  3.4331e-01,  7.9704e-03,
##         4.8744e-03,  3.0592e-02, -1.7615e-01,  8.2342e-01, -1.3793e-01,
##        -1.0075e-01, -1.2686e-01,  7.4735e-02, -8.8719e-02, -4.2719e-02,
##         7.6624e-02,  8.9263e-02,  6.4445e-02, -3.1958e-02,  1.5254e-01,
##        -1.0384e-01,  7.6604e-02,  3.4099e-01,  2.4331e-01, -1.0452e-01,
##         4.0714e-01, -1.8260e-01, -4.0667e-02,  5.0878e-01,  8.0760e-02,
##         2.2759e-01, -4.2162e-02, -1.8171e-01, -9.5025e-02,  3.0334e-02,
##         8.8202e-02, -3.9843e-06, -3.9877e-03,  1.5724e-01,  3.3167e-01,
##         8.4710e-02, -2.5919e-01, -4.1384e-01,  2.9920e-01, -5.4255e-01,
##         3.2129e-02,  1.0030e-01,  4.4202e-01,  4.4682e-02, -9.0681e-02,
##        -1.0481e-01, -1.1860e-01, -3.1972e-01, -2.0790e-01, -4.0203e-02,
##        -2.2988e-02,  2.2824e-01,  5.5238e-03,  1.2568e-01, -1.4640e-01,
##        -1.4904e-01, -1.1561e-01,  1.0517e+00, -1.9498e-01,  8.3958e-02,
##         4.4812e-02, -1.2965e-01, -9.3468e-02,  2.1237e-01, -8.8332e-02,
##        -1.8680e-01,  2.6521e-01,  1.3097e-01, -4.8102e-02, -2.2467e-01,
##         2.8412e-01,  3.4907e-01,  3.4833e-01,  1.7877e-02,  3.0504e-01,
##        -8.3453e-01,  4.8856e-02, -1.9330e-01,  2.0764e-01, -4.9701e-01,
##        -1.8747e-01, -7.6801e-02,  1.5558e-01, -4.6844e-01,  4.0944e-01,
##         2.1386e-01,  8.2392e-02, -2.6491e-01, -2.1224e-01, -1.3293e-01,
##         1.4738e-01, -1.4192e-01,  1.8994e-01, -1.5587e-01,  1.0738e+00,
##         4.0789e-01, -2.7452e-01, -1.8431e-01,  6.8679e-04, -8.7115e-02,
##         1.9672e-01,  4.0918e-01, -3.5462e-01, -6.3260e-02,  4.4920e-01,
##        -6.0568e-02, -4.1636e-02,  2.0531e-01,  1.7025e-02, -5.8448e-01,
##         7.5441e-02,  8.2116e-02, -4.6008e-01,  1.2393e-02, -2.5310e-02,
##         1.4177e-01, -9.2192e-02,  3.4505e-01, -5.2136e-01,  5.7304e-01,
##         1.1973e-02,  3.3196e-02,  2.9672e-01, -2.7899e-01,  1.9979e-01,
##         2.5666e-01,  8.2079e-02, -7.8436e-02,  9.3719e-02,  2.4202e-01,
##         1.3495e+00, -3.0434e-01, -3.0936e-01,  4.2047e-01, -7.9068e-02,
##        -1.4819e-01, -8.9404e-02,  6.6800e-02,  2.2405e-01,  2.7226e-01,
##        -3.5236e-02,  1.7688e-01, -5.3600e-02,  7.0031e-03, -3.3006e-02,
##        -8.0021e-02, -2.4451e-01, -3.9174e-02, -1.6236e-01, -9.6652e-02],
##       dtype=float32)</code></pre>
<div class="sourceCode" id="cb20"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb20-1"><a href="#cb20-1"></a><span class="bu">list</span>(embeddings_dictionary.keys()).index(<span class="st">&#39;.&#39;</span>)  <span class="co"># get key index</span></span></code></pre></div>
<pre><code>## 2</code></pre>
<p>One issue I see with many guides that use GloVe is that they do not do anything to account for padding tokens nor for unknown words. The function remedies that in several ways:</p>
<ol style="list-style-type: decimal">
<li>It creates one nearly empty vector for the <em>padding</em> tokens.</li>
<li>It creates a randomly initialized vector between <span class="math inline">\([-0.14, 0.14]\)</span> (mimicking the variance of 200d GLoVe) to account for <em>unknown</em> tokens.</li>
<li>It extends the GloVe dimensions from 200 to 201 to account for this variation.</li>
</ol>
<div class="sourceCode" id="cb22"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb22-1"><a href="#cb22-1"></a><span class="co"># create vectors for &quot;unknown&quot; and &quot;padding&quot; and add to GloVe</span></span>
<span id="cb22-2"><a href="#cb22-2"></a><span class="kw">def</span> modify_GloVe(embeddings_dictionary):</span>
<span id="cb22-3"><a href="#cb22-3"></a>    <span class="co"># create key values for unknown</span></span>
<span id="cb22-4"><a href="#cb22-4"></a>    unknown_vector <span class="op">=</span> np.random.uniform(<span class="op">-</span><span class="fl">0.14</span>, <span class="fl">0.14</span>, <span class="dv">201</span>)  <span class="co"># var of GloVe 200d</span></span>
<span id="cb22-5"><a href="#cb22-5"></a>    <span class="co"># create key values for padding</span></span>
<span id="cb22-6"><a href="#cb22-6"></a>    pad_vector <span class="op">=</span> np.repeat(<span class="dv">0</span>, <span class="dv">200</span>)</span>
<span id="cb22-7"><a href="#cb22-7"></a>    pad_vector <span class="op">=</span> np.append(pad_vector, <span class="dv">1</span>)</span>
<span id="cb22-8"><a href="#cb22-8"></a>    <span class="co"># turn dict into list to append easily</span></span>
<span id="cb22-9"><a href="#cb22-9"></a>    embeddings_tensor <span class="op">=</span> <span class="bu">list</span>(embeddings_dictionary.values())</span>
<span id="cb22-10"><a href="#cb22-10"></a>    <span class="co"># extend GloVe dimension by 2</span></span>
<span id="cb22-11"><a href="#cb22-11"></a>    embeddings_tensor <span class="op">=</span> [np.append(i, <span class="dv">0</span>) <span class="cf">for</span> i <span class="kw">in</span> embeddings_tensor]</span>
<span id="cb22-12"><a href="#cb22-12"></a>    <span class="co"># add unknown and pad vectors via vstack</span></span>
<span id="cb22-13"><a href="#cb22-13"></a>    embeddings_tensor <span class="op">=</span> np.vstack([embeddings_tensor, unknown_vector])</span>
<span id="cb22-14"><a href="#cb22-14"></a>    embeddings_tensor <span class="op">=</span> np.vstack([embeddings_tensor, pad_vector])</span>
<span id="cb22-15"><a href="#cb22-15"></a>    <span class="co"># finalize transform into tensor</span></span>
<span id="cb22-16"><a href="#cb22-16"></a>    embeddings_tensor <span class="op">=</span> torch.Tensor(embeddings_tensor)</span>
<span id="cb22-17"><a href="#cb22-17"></a>    <span class="cf">return</span> embeddings_tensor</span>
<span id="cb22-18"><a href="#cb22-18"></a>    </span>
<span id="cb22-19"><a href="#cb22-19"></a><span class="co"># modify GloVe and turn into torch tensor</span></span>
<span id="cb22-20"><a href="#cb22-20"></a>embeddings_tensor <span class="op">=</span> modify_GloVe(embeddings_dictionary)</span>
<span id="cb22-21"><a href="#cb22-21"></a><span class="co"># check shape</span></span>
<span id="cb22-22"><a href="#cb22-22"></a><span class="bu">print</span>(embeddings_tensor.shape)</span></code></pre></div>
<pre><code>## torch.Size([400002, 201])</code></pre>
<p>With GloVe loaded, we need to tokenize our corpus into GloVe tokens. This is because when we feed our tokens into the model, it uses an <code>embedding</code> layer that acts as a look-up table. We will eventually specify that this look-up table be the object we just created, <code>embeddings_tensor</code>, so that when a token is fed into our model, the <code>embedding</code> layer will “look-up” the 200 dimension feature for that word inside the <code>embeddings_tensor</code> object and append the features to our batch undergoing forward propagation.</p>
<div class="sourceCode" id="cb24"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb24-1"><a href="#cb24-1"></a><span class="co"># convert strings to GloVe familiar tokens</span></span>
<span id="cb24-2"><a href="#cb24-2"></a><span class="kw">def</span> text_to_GloVe_tokens(df, embeddings_dictionary):</span>
<span id="cb24-3"><a href="#cb24-3"></a>    <span class="co"># create container for words that do not match</span></span>
<span id="cb24-4"><a href="#cb24-4"></a>    no_matches <span class="op">=</span> []</span>
<span id="cb24-5"><a href="#cb24-5"></a>    <span class="co"># create container for tokenized strings</span></span>
<span id="cb24-6"><a href="#cb24-6"></a>    glove_tokenized_data <span class="op">=</span> []</span>
<span id="cb24-7"><a href="#cb24-7"></a>    <span class="co"># create lookup for token ids</span></span>
<span id="cb24-8"><a href="#cb24-8"></a>    word_map <span class="op">=</span> <span class="bu">dict</span>(<span class="bu">zip</span>(embeddings_dictionary.keys(), <span class="bu">range</span>(<span class="bu">len</span>(embeddings_dictionary))))</span>
<span id="cb24-9"><a href="#cb24-9"></a>    <span class="co"># for each document</span></span>
<span id="cb24-10"><a href="#cb24-10"></a>    <span class="cf">for</span> doc <span class="kw">in</span> df[<span class="st">&#39;body&#39;</span>]:</span>
<span id="cb24-11"><a href="#cb24-11"></a>        <span class="co"># split each string</span></span>
<span id="cb24-12"><a href="#cb24-12"></a>        doc <span class="op">=</span> doc.split()</span>
<span id="cb24-13"><a href="#cb24-13"></a>        <span class="co"># create token container</span></span>
<span id="cb24-14"><a href="#cb24-14"></a>        tokens <span class="op">=</span> []</span>
<span id="cb24-15"><a href="#cb24-15"></a>        <span class="co"># for each word in the document</span></span>
<span id="cb24-16"><a href="#cb24-16"></a>        <span class="cf">for</span> word <span class="kw">in</span> doc:</span>
<span id="cb24-17"><a href="#cb24-17"></a>            <span class="co"># if word is a GloVE word</span></span>
<span id="cb24-18"><a href="#cb24-18"></a>            <span class="cf">if</span> word <span class="kw">in</span> word_map:</span>
<span id="cb24-19"><a href="#cb24-19"></a>                <span class="co"># get its GloVe index</span></span>
<span id="cb24-20"><a href="#cb24-20"></a>                idx <span class="op">=</span> word_map.get(word)</span>
<span id="cb24-21"><a href="#cb24-21"></a>                <span class="co"># save its token</span></span>
<span id="cb24-22"><a href="#cb24-22"></a>                tokens.append(idx)</span>
<span id="cb24-23"><a href="#cb24-23"></a>            <span class="co"># otherwise</span></span>
<span id="cb24-24"><a href="#cb24-24"></a>            <span class="cf">else</span>:</span>
<span id="cb24-25"><a href="#cb24-25"></a>                <span class="co"># it must be an unknown word to GloVe</span></span>
<span id="cb24-26"><a href="#cb24-26"></a>                idx <span class="op">=</span> <span class="dv">400000</span>  <span class="co"># unknown word</span></span>
<span id="cb24-27"><a href="#cb24-27"></a>                <span class="co"># so append that word to no matches</span></span>
<span id="cb24-28"><a href="#cb24-28"></a>                no_matches.append(word)</span>
<span id="cb24-29"><a href="#cb24-29"></a>                <span class="co"># but also give it a vector lookup</span></span>
<span id="cb24-30"><a href="#cb24-30"></a>                tokens.append(idx)</span>
<span id="cb24-31"><a href="#cb24-31"></a>        <span class="co"># combine the tokens</span></span>
<span id="cb24-32"><a href="#cb24-32"></a>        glove_tokenized_data.append(tokens)</span>
<span id="cb24-33"><a href="#cb24-33"></a>    <span class="cf">return</span> no_matches, glove_tokenized_data</span></code></pre></div>
<p>With our corpus tokenized to match GloVe, it is in our interest to know just how many words in our corpus have no embedding features. The code below determines that for us.</p>
<div class="sourceCode" id="cb25"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb25-1"><a href="#cb25-1"></a><span class="co"># get a list of no matches and our GloVe tokens</span></span>
<span id="cb25-2"><a href="#cb25-2"></a>no_matches, glove_tokenized_data <span class="op">=</span> text_to_GloVe_tokens(df, embeddings_dictionary)</span>
<span id="cb25-3"><a href="#cb25-3"></a></span>
<span id="cb25-4"><a href="#cb25-4"></a><span class="co"># after removing rare words, how many words are we not accounting for now?</span></span>
<span id="cb25-5"><a href="#cb25-5"></a><span class="bu">print</span>(<span class="bu">len</span>(<span class="bu">set</span>(no_matches)))</span></code></pre></div>
<pre><code>## 1495</code></pre>
<p>Our next challenge is managing the lengths of our messages as they all need to be equal. The function below receives the GloVe tokenized data and a specified max length. It then proceeds to check the size of each item in the corpus and then either truncates or adds our new specialized padding token to the end of the message.</p>
<p><code>max_len</code> is a hyperparameter that we can experiment with, however, I have chosen the 95th percentile of my corpus’ <code>word_count</code> as my desired max length.</p>
<div class="sourceCode" id="cb27"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb27-1"><a href="#cb27-1"></a><span class="co"># post pad GloVe</span></span>
<span id="cb27-2"><a href="#cb27-2"></a><span class="kw">def</span> pad_GloVe(tokenized_data, max_len):</span>
<span id="cb27-3"><a href="#cb27-3"></a>    padded_tokens <span class="op">=</span> []</span>
<span id="cb27-4"><a href="#cb27-4"></a>    max_len <span class="op">=</span> max_len</span>
<span id="cb27-5"><a href="#cb27-5"></a>    <span class="co"># for each tokenized document</span></span>
<span id="cb27-6"><a href="#cb27-6"></a>    <span class="cf">for</span> tokenized_sent <span class="kw">in</span> tokenized_data:</span>
<span id="cb27-7"><a href="#cb27-7"></a>        <span class="co"># if current doc length is greater than max length</span></span>
<span id="cb27-8"><a href="#cb27-8"></a>        <span class="cf">if</span> <span class="bu">len</span>(tokenized_sent) <span class="op">&gt;</span> max_len:</span>
<span id="cb27-9"><a href="#cb27-9"></a>            <span class="co"># trim it to max length</span></span>
<span id="cb27-10"><a href="#cb27-10"></a>            current_sent <span class="op">=</span> tokenized_sent[:max_len]</span>
<span id="cb27-11"><a href="#cb27-11"></a>            <span class="co"># append</span></span>
<span id="cb27-12"><a href="#cb27-12"></a>            padded_tokens.append(current_sent)</span>
<span id="cb27-13"><a href="#cb27-13"></a></span>
<span id="cb27-14"><a href="#cb27-14"></a>        <span class="co"># if current doc length is less than max length</span></span>
<span id="cb27-15"><a href="#cb27-15"></a>        <span class="cf">if</span> <span class="bu">len</span>(tokenized_sent) <span class="op">&lt;</span> max_len:</span>
<span id="cb27-16"><a href="#cb27-16"></a>            <span class="co"># find the difference in length</span></span>
<span id="cb27-17"><a href="#cb27-17"></a>            extension <span class="op">=</span> max_len <span class="op">-</span> <span class="bu">len</span>(tokenized_sent)</span>
<span id="cb27-18"><a href="#cb27-18"></a>            <span class="co"># pad sentences to max_len</span></span>
<span id="cb27-19"><a href="#cb27-19"></a>            tokenized_sent.extend(repeat(<span class="dv">400001</span>, extension))</span>
<span id="cb27-20"><a href="#cb27-20"></a>            <span class="co"># append new padded token</span></span>
<span id="cb27-21"><a href="#cb27-21"></a>            padded_tokens.append(tokenized_sent)</span>
<span id="cb27-22"><a href="#cb27-22"></a></span>
<span id="cb27-23"><a href="#cb27-23"></a>        <span class="cf">elif</span> <span class="bu">len</span>(tokenized_sent) <span class="op">==</span> max_len:</span>
<span id="cb27-24"><a href="#cb27-24"></a>            padded_tokens.append(tokenized_sent)</span>
<span id="cb27-25"><a href="#cb27-25"></a></span>
<span id="cb27-26"><a href="#cb27-26"></a>    <span class="cf">return</span> np.array(padded_tokens, dtype<span class="op">=</span>np.int64)</span>
<span id="cb27-27"><a href="#cb27-27"></a></span>
<span id="cb27-28"><a href="#cb27-28"></a><span class="co"># get new padded tokens</span></span>
<span id="cb27-29"><a href="#cb27-29"></a>padded_GloVe <span class="op">=</span> pad_GloVe(glove_tokenized_data, percentile_95)</span>
<span id="cb27-30"><a href="#cb27-30"></a><span class="co"># check shape; 9994 documents, 974 length</span></span>
<span id="cb27-31"><a href="#cb27-31"></a><span class="bu">print</span>(padded_GloVe.shape)</span>
<span id="cb27-32"><a href="#cb27-32"></a></span>
<span id="cb27-33"><a href="#cb27-33"></a><span class="co"># check to make sure padding done right</span></span></code></pre></div>
<pre><code>## (10041, 974)</code></pre>
<div class="sourceCode" id="cb29"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb29-1"><a href="#cb29-1"></a><span class="bu">print</span>([i <span class="cf">for</span> i, x <span class="kw">in</span> <span class="bu">enumerate</span>(padded_GloVe) <span class="cf">if</span> <span class="bu">len</span>(x) <span class="op">!=</span> percentile_95])    </span></code></pre></div>
<pre><code>## []</code></pre>
<p>With the corpus work out of the way, we now proceed to prepare our data for analysis in PyTorch. The code below creates a <code>TensorDataset</code> comprised of our features, padded GloVe tokens, and our labels. It then proceeds to spit the data sets into train, validation, and test sets.</p>
<div class="sourceCode" id="cb31"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb31-1"><a href="#cb31-1"></a><span class="co"># prepare tensor data sets</span></span>
<span id="cb31-2"><a href="#cb31-2"></a><span class="kw">def</span> prepare_dataset(padded_tokens, target):</span>
<span id="cb31-3"><a href="#cb31-3"></a>    <span class="co"># prepare target into np array</span></span>
<span id="cb31-4"><a href="#cb31-4"></a>    target <span class="op">=</span> np.array(target.values, dtype<span class="op">=</span>np.int64).reshape(<span class="op">-</span><span class="dv">1</span>, <span class="dv">1</span>)</span>
<span id="cb31-5"><a href="#cb31-5"></a>    <span class="co"># create tensor data sets</span></span>
<span id="cb31-6"><a href="#cb31-6"></a>    tensor_df <span class="op">=</span> TensorDataset(torch.from_numpy(padded_tokens), torch.from_numpy(target))</span>
<span id="cb31-7"><a href="#cb31-7"></a>    <span class="co"># 80% of df</span></span>
<span id="cb31-8"><a href="#cb31-8"></a>    train_size <span class="op">=</span> <span class="bu">int</span>(<span class="fl">0.8</span> <span class="op">*</span> <span class="bu">len</span>(df))</span>
<span id="cb31-9"><a href="#cb31-9"></a>    <span class="co"># 20% of df</span></span>
<span id="cb31-10"><a href="#cb31-10"></a>    val_size <span class="op">=</span> <span class="bu">len</span>(df) <span class="op">-</span> train_size</span>
<span id="cb31-11"><a href="#cb31-11"></a>    <span class="co"># 50% of validation</span></span>
<span id="cb31-12"><a href="#cb31-12"></a>    test_size <span class="op">=</span> <span class="bu">int</span>(val_size <span class="op">-</span> <span class="fl">0.5</span><span class="op">*</span>val_size)</span>
<span id="cb31-13"><a href="#cb31-13"></a>    <span class="co"># divide the dataset by randomly selecting samples</span></span>
<span id="cb31-14"><a href="#cb31-14"></a>    train_dataset, val_dataset <span class="op">=</span> random_split(tensor_df, [train_size, val_size])</span>
<span id="cb31-15"><a href="#cb31-15"></a>    <span class="co"># divide validation by randomly selecting samples</span></span>
<span id="cb31-16"><a href="#cb31-16"></a>    val_dataset, test_dataset <span class="op">=</span> random_split(val_dataset, [test_size, test_size<span class="op">+</span><span class="dv">1</span>])</span>
<span id="cb31-17"><a href="#cb31-17"></a></span>
<span id="cb31-18"><a href="#cb31-18"></a>    <span class="cf">return</span> train_dataset, val_dataset, test_dataset</span>
<span id="cb31-19"><a href="#cb31-19"></a></span>
<span id="cb31-20"><a href="#cb31-20"></a><span class="co"># create tenor data sets</span></span>
<span id="cb31-21"><a href="#cb31-21"></a>train_dataset, val_dataset, test_dataset <span class="op">=</span> prepare_dataset(padded_GloVe, df[<span class="st">&#39;target&#39;</span>])</span></code></pre></div>
<p>Since my corpus is imbalanced, I produce weighted samplers to help balance the distribution of data as it is fed outside of my data loaders.</p>
<div class="sourceCode" id="cb32"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb32-1"><a href="#cb32-1"></a><span class="co"># helper function to count target distribution inside tensor data sets</span></span>
<span id="cb32-2"><a href="#cb32-2"></a><span class="kw">def</span> target_count(tensor_dataset):</span>
<span id="cb32-3"><a href="#cb32-3"></a>    <span class="co"># set empty count containers</span></span>
<span id="cb32-4"><a href="#cb32-4"></a>    count0 <span class="op">=</span> <span class="dv">0</span></span>
<span id="cb32-5"><a href="#cb32-5"></a>    count1 <span class="op">=</span> <span class="dv">0</span></span>
<span id="cb32-6"><a href="#cb32-6"></a>    <span class="co"># set total container to turn into torch tensor</span></span>
<span id="cb32-7"><a href="#cb32-7"></a>    total <span class="op">=</span> []</span>
<span id="cb32-8"><a href="#cb32-8"></a>    <span class="co"># for every item in the tensor data set</span></span>
<span id="cb32-9"><a href="#cb32-9"></a>    <span class="cf">for</span> i <span class="kw">in</span> tensor_dataset:</span>
<span id="cb32-10"><a href="#cb32-10"></a>        <span class="co"># if the target is equal to 0</span></span>
<span id="cb32-11"><a href="#cb32-11"></a>        <span class="cf">if</span> i[<span class="dv">1</span>].item() <span class="op">==</span> <span class="dv">0</span>:</span>
<span id="cb32-12"><a href="#cb32-12"></a>            count0 <span class="op">+=</span> <span class="dv">1</span></span>
<span id="cb32-13"><a href="#cb32-13"></a>        <span class="co"># if the target is equal to 1</span></span>
<span id="cb32-14"><a href="#cb32-14"></a>        <span class="cf">elif</span> i[<span class="dv">1</span>].item() <span class="op">==</span> <span class="dv">1</span>:</span>
<span id="cb32-15"><a href="#cb32-15"></a>            count1 <span class="op">+=</span> <span class="dv">1</span></span>
<span id="cb32-16"><a href="#cb32-16"></a>    total.append(count0)</span>
<span id="cb32-17"><a href="#cb32-17"></a>    total.append(count1)</span>
<span id="cb32-18"><a href="#cb32-18"></a>    <span class="cf">return</span> torch.tensor(total)</span>
<span id="cb32-19"><a href="#cb32-19"></a></span>
<span id="cb32-20"><a href="#cb32-20"></a></span>
<span id="cb32-21"><a href="#cb32-21"></a><span class="co"># prepare weighted sampling for imbalanced classification</span></span>
<span id="cb32-22"><a href="#cb32-22"></a><span class="kw">def</span> create_sampler(target_tensor, tensor_dataset):</span>
<span id="cb32-23"><a href="#cb32-23"></a>    <span class="co"># generate class distributions [x, y]</span></span>
<span id="cb32-24"><a href="#cb32-24"></a>    class_sample_count <span class="op">=</span> target_count(tensor_dataset)</span>
<span id="cb32-25"><a href="#cb32-25"></a>    <span class="co"># weight</span></span>
<span id="cb32-26"><a href="#cb32-26"></a>    weight <span class="op">=</span> <span class="fl">1.</span> <span class="op">/</span> class_sample_count.<span class="bu">float</span>()</span>
<span id="cb32-27"><a href="#cb32-27"></a>    <span class="co"># produce weights for each observation in the data set</span></span>
<span id="cb32-28"><a href="#cb32-28"></a>    samples_weight <span class="op">=</span> torch.tensor([weight[t[<span class="dv">1</span>]] <span class="cf">for</span> t <span class="kw">in</span> tensor_dataset])</span>
<span id="cb32-29"><a href="#cb32-29"></a>    <span class="co"># prepare sampler</span></span>
<span id="cb32-30"><a href="#cb32-30"></a>    sampler <span class="op">=</span> torch.utils.data.WeightedRandomSampler(weights<span class="op">=</span>samples_weight,</span>
<span id="cb32-31"><a href="#cb32-31"></a>                                                     num_samples<span class="op">=</span><span class="bu">len</span>(samples_weight),</span>
<span id="cb32-32"><a href="#cb32-32"></a>                                                     replacement<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb32-33"><a href="#cb32-33"></a>    <span class="cf">return</span> sampler</span>
<span id="cb32-34"><a href="#cb32-34"></a></span>
<span id="cb32-35"><a href="#cb32-35"></a></span>
<span id="cb32-36"><a href="#cb32-36"></a><span class="co"># create samplers for just training</span></span>
<span id="cb32-37"><a href="#cb32-37"></a>train_sampler <span class="op">=</span> create_sampler(target_count(train_dataset), train_dataset)</span></code></pre></div>
<p>As you might have guessed, preparing data loaders for each of our train, dev, and test data sets is our next task.</p>
<div class="sourceCode" id="cb33"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb33-1"><a href="#cb33-1"></a><span class="co"># create DataLoaders with samplers</span></span>
<span id="cb33-2"><a href="#cb33-2"></a>train_dataloader <span class="op">=</span> DataLoader(train_dataset,</span>
<span id="cb33-3"><a href="#cb33-3"></a>                              batch_size<span class="op">=</span><span class="dv">80</span>,</span>
<span id="cb33-4"><a href="#cb33-4"></a>                              sampler<span class="op">=</span>train_sampler,</span>
<span id="cb33-5"><a href="#cb33-5"></a>                              shuffle<span class="op">=</span><span class="va">False</span>)</span>
<span id="cb33-6"><a href="#cb33-6"></a></span>
<span id="cb33-7"><a href="#cb33-7"></a>valid_dataloader <span class="op">=</span> DataLoader(val_dataset,</span>
<span id="cb33-8"><a href="#cb33-8"></a>                              batch_size<span class="op">=</span><span class="dv">80</span>,</span>
<span id="cb33-9"><a href="#cb33-9"></a>                              shuffle<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb33-10"><a href="#cb33-10"></a></span>
<span id="cb33-11"><a href="#cb33-11"></a>test_dataloader <span class="op">=</span> DataLoader(test_dataset,</span>
<span id="cb33-12"><a href="#cb33-12"></a>                              batch_size<span class="op">=</span><span class="dv">80</span>,</span>
<span id="cb33-13"><a href="#cb33-13"></a>                              shuffle<span class="op">=</span><span class="va">True</span>)</span></code></pre></div>
<p>We can check to see how our sampler is working by running the loop below. As we can see, the data loader is outputting relatively balanced data into each batch.</p>
<div class="sourceCode" id="cb34"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb34-1"><a href="#cb34-1"></a><span class="co"># lets check class balance for each batch to see how the sampler is working</span></span>
<span id="cb34-2"><a href="#cb34-2"></a><span class="cf">for</span> i, (x, y) <span class="kw">in</span> <span class="bu">enumerate</span>(train_dataloader):</span>
<span id="cb34-3"><a href="#cb34-3"></a>    <span class="cf">if</span> i <span class="kw">in</span> <span class="bu">range</span>(<span class="dv">0</span>, <span class="dv">10</span>):</span>
<span id="cb34-4"><a href="#cb34-4"></a>        <span class="bu">print</span>(<span class="st">&quot;batch index </span><span class="sc">{}</span><span class="st">, 0/1: </span><span class="sc">{}</span><span class="st">/</span><span class="sc">{}</span><span class="st">&quot;</span>.<span class="bu">format</span>(</span>
<span id="cb34-5"><a href="#cb34-5"></a>            i, (y <span class="op">==</span> <span class="dv">0</span>).<span class="bu">sum</span>(), (y <span class="op">==</span> <span class="dv">1</span>).<span class="bu">sum</span>()))</span></code></pre></div>
<pre><code>## batch index 0, 0/1: 45/35
## batch index 1, 0/1: 40/40
## batch index 2, 0/1: 36/44
## batch index 3, 0/1: 44/36
## batch index 4, 0/1: 43/37
## batch index 5, 0/1: 41/39
## batch index 6, 0/1: 46/34
## batch index 7, 0/1: 46/34
## batch index 8, 0/1: 37/43
## batch index 9, 0/1: 41/39</code></pre>
<p>Next, we build a Kim Yoon (2014) CNN designed to use GloVe embeddings.</p>
<div class="sourceCode" id="cb36"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb36-1"><a href="#cb36-1"></a><span class="co"># Build Kim Yoon CNN</span></span>
<span id="cb36-2"><a href="#cb36-2"></a><span class="kw">class</span> KimCNN(nn.Module):</span>
<span id="cb36-3"><a href="#cb36-3"></a></span>
<span id="cb36-4"><a href="#cb36-4"></a>    <span class="kw">def</span> <span class="fu">__init__</span>(<span class="va">self</span>, config):</span>
<span id="cb36-5"><a href="#cb36-5"></a>        <span class="bu">super</span>().<span class="fu">__init__</span>()</span>
<span id="cb36-6"><a href="#cb36-6"></a>        output_channel <span class="op">=</span> config.output_channel  <span class="co"># number of kernels</span></span>
<span id="cb36-7"><a href="#cb36-7"></a>        num_classes <span class="op">=</span> config.num_classes  <span class="co"># number of targets to predict</span></span>
<span id="cb36-8"><a href="#cb36-8"></a>        vocab_size <span class="op">=</span> config.vocab_size  <span class="co"># vocab size of corpus</span></span>
<span id="cb36-9"><a href="#cb36-9"></a>        embedding_dim <span class="op">=</span> config.embedding_dim  <span class="co"># GloVe embed dim size</span></span>
<span id="cb36-10"><a href="#cb36-10"></a>        pre_embed <span class="op">=</span> config.pre_embed  <span class="co"># GloVe coefs</span></span>
<span id="cb36-11"><a href="#cb36-11"></a>        <span class="va">self</span>.mode <span class="op">=</span> config.mode  <span class="co"># static, or not</span></span>
<span id="cb36-12"><a href="#cb36-12"></a>        ks <span class="op">=</span> <span class="dv">3</span>  <span class="co"># three conv nets here</span></span>
<span id="cb36-13"><a href="#cb36-13"></a>        dropout <span class="op">=</span> config.dropout  <span class="co"># dropout value</span></span>
<span id="cb36-14"><a href="#cb36-14"></a>        padding <span class="op">=</span> config.padding_idx  <span class="co"># padding indx value</span></span>
<span id="cb36-15"><a href="#cb36-15"></a></span>
<span id="cb36-16"><a href="#cb36-16"></a>        <span class="co"># for single embedding, input_channel = 1</span></span>
<span id="cb36-17"><a href="#cb36-17"></a>        input_channel <span class="op">=</span> <span class="dv">1</span></span>
<span id="cb36-18"><a href="#cb36-18"></a>        <span class="cf">if</span> config.mode <span class="op">==</span> <span class="st">&#39;rand&#39;</span>:</span>
<span id="cb36-19"><a href="#cb36-19"></a>            rand_embed_init <span class="op">=</span> torch.Tensor(vocab_size, embedding_dim).uniform_(<span class="op">-</span><span class="fl">0.25</span>, <span class="fl">0.25</span>)</span>
<span id="cb36-20"><a href="#cb36-20"></a>            <span class="va">self</span>.embed <span class="op">=</span> nn.Embedding.from_pretrained(rand_embed_init, freeze<span class="op">=</span><span class="va">False</span>)</span>
<span id="cb36-21"><a href="#cb36-21"></a></span>
<span id="cb36-22"><a href="#cb36-22"></a>        <span class="cf">elif</span> config.mode <span class="op">==</span> <span class="st">&#39;static&#39;</span>:</span>
<span id="cb36-23"><a href="#cb36-23"></a>            <span class="va">self</span>.static_embed <span class="op">=</span> nn.Embedding.from_pretrained(pre_embed,</span>
<span id="cb36-24"><a href="#cb36-24"></a>                                                             freeze<span class="op">=</span><span class="va">True</span>,</span>
<span id="cb36-25"><a href="#cb36-25"></a>                                                             padding_idx<span class="op">=</span>padding)</span>
<span id="cb36-26"><a href="#cb36-26"></a></span>
<span id="cb36-27"><a href="#cb36-27"></a>        <span class="cf">elif</span> config.mode <span class="op">==</span> <span class="st">&#39;non-static&#39;</span>:</span>
<span id="cb36-28"><a href="#cb36-28"></a>            <span class="va">self</span>.non_static_embed <span class="op">=</span> nn.Embedding.from_pretrained(pre_embed,</span>
<span id="cb36-29"><a href="#cb36-29"></a>                                                                 freeze<span class="op">=</span><span class="va">False</span>,</span>
<span id="cb36-30"><a href="#cb36-30"></a>                                                                 padding_idx<span class="op">=</span>padding)</span>
<span id="cb36-31"><a href="#cb36-31"></a></span>
<span id="cb36-32"><a href="#cb36-32"></a>        <span class="co"># input channel increases with trainable and untrainable embeddings</span></span>
<span id="cb36-33"><a href="#cb36-33"></a>        <span class="cf">elif</span> config.mode <span class="op">==</span> <span class="st">&#39;multichannel&#39;</span>:</span>
<span id="cb36-34"><a href="#cb36-34"></a>            <span class="va">self</span>.static_embed <span class="op">=</span> nn.Embedding.from_pretrained(pre_embed,</span>
<span id="cb36-35"><a href="#cb36-35"></a>                                                             freeze<span class="op">=</span><span class="va">True</span>,</span>
<span id="cb36-36"><a href="#cb36-36"></a>                                                             padding_idx<span class="op">=</span>padding)</span>
<span id="cb36-37"><a href="#cb36-37"></a>            <span class="va">self</span>.non_static_embed <span class="op">=</span> nn.Embedding.from_pretrained(pre_embed,</span>
<span id="cb36-38"><a href="#cb36-38"></a>                                                                 freeze<span class="op">=</span><span class="va">False</span>,</span>
<span id="cb36-39"><a href="#cb36-39"></a>                                                                 padding_idx<span class="op">=</span>padding)</span>
<span id="cb36-40"><a href="#cb36-40"></a>            input_channel <span class="op">=</span> <span class="dv">2</span></span>
<span id="cb36-41"><a href="#cb36-41"></a></span>
<span id="cb36-42"><a href="#cb36-42"></a>        <span class="cf">else</span>:</span>
<span id="cb36-43"><a href="#cb36-43"></a>            <span class="bu">print</span>(<span class="st">&quot;Unsupported Mode&quot;</span>)</span>
<span id="cb36-44"><a href="#cb36-44"></a>            <span class="cf">raise</span> <span class="pp">Exception</span></span>
<span id="cb36-45"><a href="#cb36-45"></a></span>
<span id="cb36-46"><a href="#cb36-46"></a>        <span class="co"># input_channel = word embeddings at a value of 1; 3 for RGB images</span></span>
<span id="cb36-47"><a href="#cb36-47"></a>        <span class="co"># output_channel = number of kernels</span></span>
<span id="cb36-48"><a href="#cb36-48"></a>        <span class="co"># [3, 4, 5] = window height</span></span>
<span id="cb36-49"><a href="#cb36-49"></a>        <span class="co"># embedding_dim = length of embedding dim; my GloVe is 202</span></span>
<span id="cb36-50"><a href="#cb36-50"></a>        <span class="co"># padding = padding to account for height of search window</span></span>
<span id="cb36-51"><a href="#cb36-51"></a>        <span class="va">self</span>.conv1 <span class="op">=</span> nn.Conv2d(input_channel, output_channel, (<span class="dv">3</span>, embedding_dim), padding<span class="op">=</span>(<span class="dv">2</span>, <span class="dv">0</span>))</span>
<span id="cb36-52"><a href="#cb36-52"></a>        <span class="va">self</span>.conv2 <span class="op">=</span> nn.Conv2d(input_channel, output_channel, (<span class="dv">4</span>, embedding_dim), padding<span class="op">=</span>(<span class="dv">3</span>, <span class="dv">0</span>))</span>
<span id="cb36-53"><a href="#cb36-53"></a>        <span class="va">self</span>.conv3 <span class="op">=</span> nn.Conv2d(input_channel, output_channel, (<span class="dv">5</span>, embedding_dim), padding<span class="op">=</span>(<span class="dv">4</span>, <span class="dv">0</span>))</span>
<span id="cb36-54"><a href="#cb36-54"></a>        <span class="co"># apply dropout</span></span>
<span id="cb36-55"><a href="#cb36-55"></a>        <span class="va">self</span>.dropout <span class="op">=</span> nn.Dropout(dropout)</span>
<span id="cb36-56"><a href="#cb36-56"></a>        <span class="co"># fully connected layer for classification</span></span>
<span id="cb36-57"><a href="#cb36-57"></a>        <span class="co"># 3x conv nets * output channel</span></span>
<span id="cb36-58"><a href="#cb36-58"></a>        <span class="va">self</span>.fc1 <span class="op">=</span> nn.Linear(ks <span class="op">*</span> output_channel, num_classes)</span>
<span id="cb36-59"><a href="#cb36-59"></a></span>
<span id="cb36-60"><a href="#cb36-60"></a>    <span class="kw">def</span> forward(<span class="va">self</span>, x, <span class="op">**</span>kwargs):</span>
<span id="cb36-61"><a href="#cb36-61"></a>        <span class="cf">if</span> <span class="va">self</span>.mode <span class="op">==</span> <span class="st">&#39;rand&#39;</span>:</span>
<span id="cb36-62"><a href="#cb36-62"></a>            word_input <span class="op">=</span> <span class="va">self</span>.embed(x)  <span class="co"># (batch, sent_len, embed_dim)</span></span>
<span id="cb36-63"><a href="#cb36-63"></a>            x <span class="op">=</span> word_input.unsqueeze(<span class="dv">1</span>)  <span class="co"># (batch, channel_input, sent_len, embed_dim)</span></span>
<span id="cb36-64"><a href="#cb36-64"></a></span>
<span id="cb36-65"><a href="#cb36-65"></a>        <span class="cf">elif</span> <span class="va">self</span>.mode <span class="op">==</span> <span class="st">&#39;static&#39;</span>:</span>
<span id="cb36-66"><a href="#cb36-66"></a>            static_input <span class="op">=</span> <span class="va">self</span>.static_embed(x)</span>
<span id="cb36-67"><a href="#cb36-67"></a>            x <span class="op">=</span> static_input.unsqueeze(<span class="dv">1</span>)  <span class="co"># (batch, channel_input, sent_len, embed_dim)</span></span>
<span id="cb36-68"><a href="#cb36-68"></a></span>
<span id="cb36-69"><a href="#cb36-69"></a>        <span class="cf">elif</span> <span class="va">self</span>.mode <span class="op">==</span> <span class="st">&#39;non-static&#39;</span>:</span>
<span id="cb36-70"><a href="#cb36-70"></a>            non_static_input <span class="op">=</span> <span class="va">self</span>.non_static_embed(x)</span>
<span id="cb36-71"><a href="#cb36-71"></a>            x <span class="op">=</span> non_static_input.unsqueeze(<span class="dv">1</span>)  <span class="co"># (batch, channel_input, sent_len, embed_dim)</span></span>
<span id="cb36-72"><a href="#cb36-72"></a></span>
<span id="cb36-73"><a href="#cb36-73"></a>        <span class="cf">elif</span> <span class="va">self</span>.mode <span class="op">==</span> <span class="st">&#39;multichannel&#39;</span>:</span>
<span id="cb36-74"><a href="#cb36-74"></a>            non_static_input <span class="op">=</span> <span class="va">self</span>.non_static_embed(x)</span>
<span id="cb36-75"><a href="#cb36-75"></a>            static_input <span class="op">=</span> <span class="va">self</span>.static_embed(x)</span>
<span id="cb36-76"><a href="#cb36-76"></a>            x <span class="op">=</span> torch.stack([non_static_input, static_input], dim<span class="op">=</span><span class="dv">1</span>)  <span class="co"># (batch, channel_input=2, sent_len, embed_dim)</span></span>
<span id="cb36-77"><a href="#cb36-77"></a></span>
<span id="cb36-78"><a href="#cb36-78"></a>        <span class="cf">else</span>:</span>
<span id="cb36-79"><a href="#cb36-79"></a>            <span class="bu">print</span>(<span class="st">&quot;Unsupported Mode&quot;</span>)</span>
<span id="cb36-80"><a href="#cb36-80"></a>            <span class="cf">raise</span> <span class="pp">Exception</span></span>
<span id="cb36-81"><a href="#cb36-81"></a></span>
<span id="cb36-82"><a href="#cb36-82"></a>        <span class="co"># squeeze to get size; (batch, channel_output, ~=sent_len) * ks</span></span>
<span id="cb36-83"><a href="#cb36-83"></a>        x <span class="op">=</span> [F.relu(<span class="va">self</span>.conv1(x)).squeeze(<span class="dv">3</span>), F.relu(<span class="va">self</span>.conv2(x)).squeeze(<span class="dv">3</span>), F.relu(<span class="va">self</span>.conv3(x)).squeeze(<span class="dv">3</span>)]</span>
<span id="cb36-84"><a href="#cb36-84"></a>        <span class="co"># max-over-time pooling; # (batch, channel_output) * ks</span></span>
<span id="cb36-85"><a href="#cb36-85"></a>        x <span class="op">=</span> [F.max_pool1d(i, i.size(<span class="dv">2</span>)).squeeze(<span class="dv">2</span>) <span class="cf">for</span> i <span class="kw">in</span> x]</span>
<span id="cb36-86"><a href="#cb36-86"></a>        <span class="co"># concat results; (batch, channel_output * ks)</span></span>
<span id="cb36-87"><a href="#cb36-87"></a>        x <span class="op">=</span> torch.cat(x, <span class="dv">1</span>)</span>
<span id="cb36-88"><a href="#cb36-88"></a>        <span class="co"># add dropout</span></span>
<span id="cb36-89"><a href="#cb36-89"></a>        x <span class="op">=</span> <span class="va">self</span>.dropout(x)</span>
<span id="cb36-90"><a href="#cb36-90"></a>        <span class="co"># generate logits (batch, target_size)</span></span>
<span id="cb36-91"><a href="#cb36-91"></a>        logit <span class="op">=</span> <span class="va">self</span>.fc1(x)</span>
<span id="cb36-92"><a href="#cb36-92"></a>        <span class="cf">return</span> logit</span></code></pre></div>
<p>Below we instantiate a helper function for time keeping.</p>
<div class="sourceCode" id="cb37"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb37-1"><a href="#cb37-1"></a><span class="co"># time function</span></span>
<span id="cb37-2"><a href="#cb37-2"></a><span class="kw">def</span> format_time(elapsed):</span>
<span id="cb37-3"><a href="#cb37-3"></a>    <span class="co">&#39;&#39;&#39;</span></span>
<span id="cb37-4"><a href="#cb37-4"></a><span class="co">    Takes a time in seconds and returns a string hh:mm:ss</span></span>
<span id="cb37-5"><a href="#cb37-5"></a><span class="co">    &#39;&#39;&#39;</span></span>
<span id="cb37-6"><a href="#cb37-6"></a>    <span class="co"># round to the nearest second.</span></span>
<span id="cb37-7"><a href="#cb37-7"></a>    elapsed_rounded <span class="op">=</span> <span class="bu">int</span>(<span class="bu">round</span>((elapsed)))</span>
<span id="cb37-8"><a href="#cb37-8"></a>    <span class="co"># format as hh:mm:ss</span></span>
<span id="cb37-9"><a href="#cb37-9"></a>    <span class="cf">return</span> <span class="bu">str</span>(datetime.timedelta(seconds<span class="op">=</span>elapsed_rounded))</span></code></pre></div>
<p>Now, we prepare functions to train, validate, and test our data.</p>
<div class="sourceCode" id="cb38"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb38-1"><a href="#cb38-1"></a><span class="kw">def</span> train(model, dataloader, optimizer, criterion):</span>
<span id="cb38-2"><a href="#cb38-2"></a></span>
<span id="cb38-3"><a href="#cb38-3"></a>    <span class="co"># capture time</span></span>
<span id="cb38-4"><a href="#cb38-4"></a>    total_t0 <span class="op">=</span> time.time()</span>
<span id="cb38-5"><a href="#cb38-5"></a></span>
<span id="cb38-6"><a href="#cb38-6"></a>    <span class="co"># Perform one full pass over the training set.</span></span>
<span id="cb38-7"><a href="#cb38-7"></a>    <span class="bu">print</span>(<span class="st">&quot;&quot;</span>)</span>
<span id="cb38-8"><a href="#cb38-8"></a>    <span class="bu">print</span>(<span class="st">&#39;======== Epoch </span><span class="sc">{:}</span><span class="st"> / </span><span class="sc">{:}</span><span class="st"> ========&#39;</span>.<span class="bu">format</span>(epoch <span class="op">+</span> <span class="dv">1</span>, epochs))</span>
<span id="cb38-9"><a href="#cb38-9"></a>    <span class="bu">print</span>(<span class="st">&#39;Training...&#39;</span>)</span>
<span id="cb38-10"><a href="#cb38-10"></a></span>
<span id="cb38-11"><a href="#cb38-11"></a>    <span class="co"># reset total loss for epoch</span></span>
<span id="cb38-12"><a href="#cb38-12"></a>    train_total_loss <span class="op">=</span> <span class="dv">0</span></span>
<span id="cb38-13"><a href="#cb38-13"></a>    total_train_f1 <span class="op">=</span> <span class="dv">0</span></span>
<span id="cb38-14"><a href="#cb38-14"></a></span>
<span id="cb38-15"><a href="#cb38-15"></a>    <span class="co"># put model into traning mode</span></span>
<span id="cb38-16"><a href="#cb38-16"></a>    model.train()</span>
<span id="cb38-17"><a href="#cb38-17"></a></span>
<span id="cb38-18"><a href="#cb38-18"></a>    <span class="co"># for each batch of training data...</span></span>
<span id="cb38-19"><a href="#cb38-19"></a>    <span class="cf">for</span> step, batch <span class="kw">in</span> <span class="bu">enumerate</span>(dataloader):</span>
<span id="cb38-20"><a href="#cb38-20"></a></span>
<span id="cb38-21"><a href="#cb38-21"></a>        <span class="co"># progress update every 40 batches.</span></span>
<span id="cb38-22"><a href="#cb38-22"></a>        <span class="cf">if</span> step <span class="op">%</span> <span class="dv">40</span> <span class="op">==</span> <span class="dv">0</span> <span class="kw">and</span> <span class="kw">not</span> step <span class="op">==</span> <span class="dv">0</span>:</span>
<span id="cb38-23"><a href="#cb38-23"></a></span>
<span id="cb38-24"><a href="#cb38-24"></a>            <span class="co"># Report progress.</span></span>
<span id="cb38-25"><a href="#cb38-25"></a>            <span class="bu">print</span>(<span class="st">&#39;  Batch {:&gt;5,}  of  {:&gt;5,}.&#39;</span>.<span class="bu">format</span>(step, <span class="bu">len</span>(dataloader)))</span>
<span id="cb38-26"><a href="#cb38-26"></a></span>
<span id="cb38-27"><a href="#cb38-27"></a>        <span class="co"># Unpack this training batch from our dataloader:</span></span>
<span id="cb38-28"><a href="#cb38-28"></a>        <span class="co">#</span></span>
<span id="cb38-29"><a href="#cb38-29"></a>        <span class="co"># As we unpack the batch, we&#39;ll also copy each tensor to the GPU</span></span>
<span id="cb38-30"><a href="#cb38-30"></a>        <span class="co">#</span></span>
<span id="cb38-31"><a href="#cb38-31"></a>        <span class="co"># `batch` contains two pytorch tensors:</span></span>
<span id="cb38-32"><a href="#cb38-32"></a>        <span class="co">#   [0]: input ids</span></span>
<span id="cb38-33"><a href="#cb38-33"></a>        <span class="co">#   [1]: labels</span></span>
<span id="cb38-34"><a href="#cb38-34"></a>        b_input_ids <span class="op">=</span> batch[<span class="dv">0</span>].cuda()</span>
<span id="cb38-35"><a href="#cb38-35"></a>        b_labels <span class="op">=</span> batch[<span class="dv">1</span>].cuda().<span class="bu">type</span>(torch.cuda.FloatTensor)</span>
<span id="cb38-36"><a href="#cb38-36"></a></span>
<span id="cb38-37"><a href="#cb38-37"></a>        <span class="co"># clear previously calculated gradients</span></span>
<span id="cb38-38"><a href="#cb38-38"></a>        optimizer.zero_grad()</span>
<span id="cb38-39"><a href="#cb38-39"></a></span>
<span id="cb38-40"><a href="#cb38-40"></a>        <span class="cf">with</span> autocast():</span>
<span id="cb38-41"><a href="#cb38-41"></a>            <span class="co"># forward propagation (evaluate model on training batch)</span></span>
<span id="cb38-42"><a href="#cb38-42"></a>            logits <span class="op">=</span> model(b_input_ids)</span>
<span id="cb38-43"><a href="#cb38-43"></a></span>
<span id="cb38-44"><a href="#cb38-44"></a>        <span class="co"># calculate cross entropy loss</span></span>
<span id="cb38-45"><a href="#cb38-45"></a>        loss <span class="op">=</span> criterion(logits, b_labels)</span>
<span id="cb38-46"><a href="#cb38-46"></a></span>
<span id="cb38-47"><a href="#cb38-47"></a>        <span class="co"># sum the training loss over all batches for average loss at end</span></span>
<span id="cb38-48"><a href="#cb38-48"></a>        <span class="co"># loss is a tensor containing a single value</span></span>
<span id="cb38-49"><a href="#cb38-49"></a>        train_total_loss <span class="op">+=</span> loss.item()</span>
<span id="cb38-50"><a href="#cb38-50"></a></span>
<span id="cb38-51"><a href="#cb38-51"></a>        <span class="co"># Scales loss.  Calls backward() on scaled loss to create scaled gradients.</span></span>
<span id="cb38-52"><a href="#cb38-52"></a>        <span class="co"># Backward passes under autocast are not recommended.</span></span>
<span id="cb38-53"><a href="#cb38-53"></a>        <span class="co"># Backward ops run in the same dtype autocast chose for corresponding forward ops.</span></span>
<span id="cb38-54"><a href="#cb38-54"></a>        scaler.scale(loss).backward()</span>
<span id="cb38-55"><a href="#cb38-55"></a></span>
<span id="cb38-56"><a href="#cb38-56"></a>        <span class="co"># scaler.step() first unscales the gradients of the optimizer&#39;s assigned params.</span></span>
<span id="cb38-57"><a href="#cb38-57"></a>        <span class="co"># If these gradients do not contain infs or NaNs, optimizer.step() is then called,</span></span>
<span id="cb38-58"><a href="#cb38-58"></a>        <span class="co"># otherwise, optimizer.step() is skipped.</span></span>
<span id="cb38-59"><a href="#cb38-59"></a>        scaler.step(optimizer)</span>
<span id="cb38-60"><a href="#cb38-60"></a></span>
<span id="cb38-61"><a href="#cb38-61"></a>        <span class="co"># Updates the scale for next iteration.</span></span>
<span id="cb38-62"><a href="#cb38-62"></a>        scaler.update()</span>
<span id="cb38-63"><a href="#cb38-63"></a></span>
<span id="cb38-64"><a href="#cb38-64"></a>        <span class="co"># update the learning rate</span></span>
<span id="cb38-65"><a href="#cb38-65"></a>        scheduler.step()</span>
<span id="cb38-66"><a href="#cb38-66"></a></span>
<span id="cb38-67"><a href="#cb38-67"></a>        <span class="co"># move logits and labels to CPU</span></span>
<span id="cb38-68"><a href="#cb38-68"></a>        logits <span class="op">=</span> logits.detach().cpu().numpy()</span>
<span id="cb38-69"><a href="#cb38-69"></a>        y_true <span class="op">=</span> b_labels.detach().cpu().numpy()</span>
<span id="cb38-70"><a href="#cb38-70"></a></span>
<span id="cb38-71"><a href="#cb38-71"></a>        <span class="co"># calculate preds</span></span>
<span id="cb38-72"><a href="#cb38-72"></a>        rounded_preds <span class="op">=</span> np.argmax(logits, axis<span class="op">=</span><span class="dv">1</span>).flatten()</span>
<span id="cb38-73"><a href="#cb38-73"></a></span>
<span id="cb38-74"><a href="#cb38-74"></a>        <span class="co"># calculate f1</span></span>
<span id="cb38-75"><a href="#cb38-75"></a>        total_train_f1 <span class="op">+=</span> f1_score(rounded_preds, y_true,</span>
<span id="cb38-76"><a href="#cb38-76"></a>                                   average<span class="op">=</span><span class="st">&#39;weighted&#39;</span>,</span>
<span id="cb38-77"><a href="#cb38-77"></a>                                   labels<span class="op">=</span>np.unique(rounded_preds))</span>
<span id="cb38-78"><a href="#cb38-78"></a></span>
<span id="cb38-79"><a href="#cb38-79"></a>    <span class="co"># calculate the average loss over all of the batches</span></span>
<span id="cb38-80"><a href="#cb38-80"></a>    avg_train_loss <span class="op">=</span> train_total_loss <span class="op">/</span> <span class="bu">len</span>(dataloader)</span>
<span id="cb38-81"><a href="#cb38-81"></a></span>
<span id="cb38-82"><a href="#cb38-82"></a>    <span class="co"># calculate the average f1 over all of the batches</span></span>
<span id="cb38-83"><a href="#cb38-83"></a>    avg_train_f1 <span class="op">=</span> total_train_f1 <span class="op">/</span> <span class="bu">len</span>(dataloader)</span>
<span id="cb38-84"><a href="#cb38-84"></a></span>
<span id="cb38-85"><a href="#cb38-85"></a>    <span class="co"># Record all statistics from this epoch.</span></span>
<span id="cb38-86"><a href="#cb38-86"></a>    training_stats.append(</span>
<span id="cb38-87"><a href="#cb38-87"></a>        {</span>
<span id="cb38-88"><a href="#cb38-88"></a>            <span class="st">&#39;Train Loss&#39;</span>: avg_train_loss,</span>
<span id="cb38-89"><a href="#cb38-89"></a>            <span class="st">&#39;Train F1&#39;</span>: avg_train_f1</span>
<span id="cb38-90"><a href="#cb38-90"></a>        }</span>
<span id="cb38-91"><a href="#cb38-91"></a>    )</span>
<span id="cb38-92"><a href="#cb38-92"></a></span>
<span id="cb38-93"><a href="#cb38-93"></a>    <span class="co"># training time end</span></span>
<span id="cb38-94"><a href="#cb38-94"></a>    training_time <span class="op">=</span> format_time(time.time() <span class="op">-</span> total_t0)</span>
<span id="cb38-95"><a href="#cb38-95"></a></span>
<span id="cb38-96"><a href="#cb38-96"></a>    <span class="co"># print result summaries</span></span>
<span id="cb38-97"><a href="#cb38-97"></a>    <span class="bu">print</span>(<span class="st">&quot;&quot;</span>)</span>
<span id="cb38-98"><a href="#cb38-98"></a>    <span class="bu">print</span>(<span class="st">&quot;summary results&quot;</span>)</span>
<span id="cb38-99"><a href="#cb38-99"></a>    <span class="bu">print</span>(<span class="st">&quot;epoch | trn loss | trn f1 | trn time &quot;</span>)</span>
<span id="cb38-100"><a href="#cb38-100"></a>    <span class="bu">print</span>(<span class="ss">f&quot;</span><span class="sc">{</span>epoch<span class="op">+</span><span class="dv">1</span><span class="sc">:5d}</span><span class="ss"> | </span><span class="sc">{</span>avg_train_loss<span class="sc">:.5f}</span><span class="ss"> | </span><span class="sc">{</span>avg_train_f1<span class="sc">:.5f}</span><span class="ss"> | </span><span class="sc">{</span>training_time<span class="sc">:}</span><span class="ss">&quot;</span>)</span>
<span id="cb38-101"><a href="#cb38-101"></a></span>
<span id="cb38-102"><a href="#cb38-102"></a>    torch.cuda.empty_cache()</span>
<span id="cb38-103"><a href="#cb38-103"></a></span>
<span id="cb38-104"><a href="#cb38-104"></a>    <span class="cf">return</span> <span class="va">None</span></span>
<span id="cb38-105"><a href="#cb38-105"></a></span>
<span id="cb38-106"><a href="#cb38-106"></a></span>
<span id="cb38-107"><a href="#cb38-107"></a><span class="kw">def</span> validating(model, dataloader, criterion):</span>
<span id="cb38-108"><a href="#cb38-108"></a></span>
<span id="cb38-109"><a href="#cb38-109"></a>    <span class="co"># capture validation time</span></span>
<span id="cb38-110"><a href="#cb38-110"></a>    total_t0 <span class="op">=</span> time.time()</span>
<span id="cb38-111"><a href="#cb38-111"></a></span>
<span id="cb38-112"><a href="#cb38-112"></a>    <span class="co"># After the completion of each training epoch, measure our performance on</span></span>
<span id="cb38-113"><a href="#cb38-113"></a>    <span class="co"># our validation set.</span></span>
<span id="cb38-114"><a href="#cb38-114"></a>    <span class="bu">print</span>(<span class="st">&quot;&quot;</span>)</span>
<span id="cb38-115"><a href="#cb38-115"></a>    <span class="bu">print</span>(<span class="st">&quot;Running Validation...&quot;</span>)</span>
<span id="cb38-116"><a href="#cb38-116"></a></span>
<span id="cb38-117"><a href="#cb38-117"></a>    <span class="co"># put the model in evaluation mode</span></span>
<span id="cb38-118"><a href="#cb38-118"></a>    model.<span class="bu">eval</span>()</span>
<span id="cb38-119"><a href="#cb38-119"></a></span>
<span id="cb38-120"><a href="#cb38-120"></a>    <span class="co"># track variables</span></span>
<span id="cb38-121"><a href="#cb38-121"></a>    total_valid_accuracy <span class="op">=</span> <span class="dv">0</span></span>
<span id="cb38-122"><a href="#cb38-122"></a>    total_valid_loss <span class="op">=</span> <span class="dv">0</span></span>
<span id="cb38-123"><a href="#cb38-123"></a>    total_valid_f1 <span class="op">=</span> <span class="dv">0</span></span>
<span id="cb38-124"><a href="#cb38-124"></a>    total_valid_recall <span class="op">=</span> <span class="dv">0</span></span>
<span id="cb38-125"><a href="#cb38-125"></a>    total_valid_precision <span class="op">=</span> <span class="dv">0</span></span>
<span id="cb38-126"><a href="#cb38-126"></a></span>
<span id="cb38-127"><a href="#cb38-127"></a>    <span class="co"># evaluate data for one epoch</span></span>
<span id="cb38-128"><a href="#cb38-128"></a>    <span class="cf">for</span> batch <span class="kw">in</span> dataloader:</span>
<span id="cb38-129"><a href="#cb38-129"></a></span>
<span id="cb38-130"><a href="#cb38-130"></a>        <span class="co"># unpack batch from dataloader</span></span>
<span id="cb38-131"><a href="#cb38-131"></a>        b_input_ids <span class="op">=</span> batch[<span class="dv">0</span>].cuda()</span>
<span id="cb38-132"><a href="#cb38-132"></a>        b_labels <span class="op">=</span> batch[<span class="dv">1</span>].cuda().<span class="bu">type</span>(torch.cuda.FloatTensor)</span>
<span id="cb38-133"><a href="#cb38-133"></a></span>
<span id="cb38-134"><a href="#cb38-134"></a>        <span class="co"># tell pytorch not to bother calculating gradients</span></span>
<span id="cb38-135"><a href="#cb38-135"></a>        <span class="co"># as its only necessary for training</span></span>
<span id="cb38-136"><a href="#cb38-136"></a>        <span class="cf">with</span> torch.no_grad():</span>
<span id="cb38-137"><a href="#cb38-137"></a></span>
<span id="cb38-138"><a href="#cb38-138"></a>            <span class="co"># forward propagation (evaluate model on training batch)</span></span>
<span id="cb38-139"><a href="#cb38-139"></a>            logits <span class="op">=</span> model(b_input_ids)</span>
<span id="cb38-140"><a href="#cb38-140"></a></span>
<span id="cb38-141"><a href="#cb38-141"></a>            <span class="co"># calculate BCEWithLogitsLoss</span></span>
<span id="cb38-142"><a href="#cb38-142"></a>            loss <span class="op">=</span> criterion(logits, b_labels)</span>
<span id="cb38-143"><a href="#cb38-143"></a></span>
<span id="cb38-144"><a href="#cb38-144"></a>        <span class="co"># accumulate validation loss</span></span>
<span id="cb38-145"><a href="#cb38-145"></a>        total_valid_loss <span class="op">+=</span> loss.item()</span>
<span id="cb38-146"><a href="#cb38-146"></a></span>
<span id="cb38-147"><a href="#cb38-147"></a>        <span class="co"># move logits and labels to CPU</span></span>
<span id="cb38-148"><a href="#cb38-148"></a>        logits <span class="op">=</span> logits.detach().cpu().numpy()</span>
<span id="cb38-149"><a href="#cb38-149"></a>        y_true <span class="op">=</span> b_labels.detach().cpu().numpy()</span>
<span id="cb38-150"><a href="#cb38-150"></a></span>
<span id="cb38-151"><a href="#cb38-151"></a>        <span class="co"># calculate preds</span></span>
<span id="cb38-152"><a href="#cb38-152"></a>        rounded_preds <span class="op">=</span> np.argmax(logits, axis<span class="op">=</span><span class="dv">1</span>).flatten()</span>
<span id="cb38-153"><a href="#cb38-153"></a></span>
<span id="cb38-154"><a href="#cb38-154"></a>        <span class="co"># calculate f1</span></span>
<span id="cb38-155"><a href="#cb38-155"></a>        total_valid_f1 <span class="op">+=</span> f1_score(rounded_preds, y_true,</span>
<span id="cb38-156"><a href="#cb38-156"></a>                                   average<span class="op">=</span><span class="st">&#39;weighted&#39;</span>,</span>
<span id="cb38-157"><a href="#cb38-157"></a>                                   labels<span class="op">=</span>np.unique(rounded_preds))</span>
<span id="cb38-158"><a href="#cb38-158"></a></span>
<span id="cb38-159"><a href="#cb38-159"></a>        <span class="co"># calculate accuracy</span></span>
<span id="cb38-160"><a href="#cb38-160"></a>        total_valid_accuracy <span class="op">+=</span> accuracy_score(rounded_preds, y_true)</span>
<span id="cb38-161"><a href="#cb38-161"></a></span>
<span id="cb38-162"><a href="#cb38-162"></a>        <span class="co"># calculate precision</span></span>
<span id="cb38-163"><a href="#cb38-163"></a>        total_valid_precision <span class="op">+=</span> precision_score(rounded_preds, y_true,</span>
<span id="cb38-164"><a href="#cb38-164"></a>                                                 average<span class="op">=</span><span class="st">&#39;weighted&#39;</span>,</span>
<span id="cb38-165"><a href="#cb38-165"></a>                                                 labels<span class="op">=</span>np.unique(rounded_preds))</span>
<span id="cb38-166"><a href="#cb38-166"></a></span>
<span id="cb38-167"><a href="#cb38-167"></a>        <span class="co"># calculate recall</span></span>
<span id="cb38-168"><a href="#cb38-168"></a>        total_valid_recall <span class="op">+=</span> recall_score(rounded_preds, y_true,</span>
<span id="cb38-169"><a href="#cb38-169"></a>                                                 average<span class="op">=</span><span class="st">&#39;weighted&#39;</span>,</span>
<span id="cb38-170"><a href="#cb38-170"></a>                                                 labels<span class="op">=</span>np.unique(rounded_preds))</span>
<span id="cb38-171"><a href="#cb38-171"></a></span>
<span id="cb38-172"><a href="#cb38-172"></a>    <span class="co"># report final accuracy of validation run</span></span>
<span id="cb38-173"><a href="#cb38-173"></a>    avg_accuracy <span class="op">=</span> total_valid_accuracy <span class="op">/</span> <span class="bu">len</span>(dataloader)</span>
<span id="cb38-174"><a href="#cb38-174"></a></span>
<span id="cb38-175"><a href="#cb38-175"></a>    <span class="co"># report final f1 of validation run</span></span>
<span id="cb38-176"><a href="#cb38-176"></a>    <span class="kw">global</span> avg_val_f1</span>
<span id="cb38-177"><a href="#cb38-177"></a>    avg_val_f1 <span class="op">=</span> total_valid_f1 <span class="op">/</span> <span class="bu">len</span>(dataloader)</span>
<span id="cb38-178"><a href="#cb38-178"></a></span>
<span id="cb38-179"><a href="#cb38-179"></a>    <span class="co"># report final f1 of validation run</span></span>
<span id="cb38-180"><a href="#cb38-180"></a>    avg_precision <span class="op">=</span> total_valid_precision <span class="op">/</span> <span class="bu">len</span>(dataloader)</span>
<span id="cb38-181"><a href="#cb38-181"></a></span>
<span id="cb38-182"><a href="#cb38-182"></a>    <span class="co"># report final f1 of validation run</span></span>
<span id="cb38-183"><a href="#cb38-183"></a>    avg_recall <span class="op">=</span> total_valid_recall <span class="op">/</span> <span class="bu">len</span>(dataloader)</span>
<span id="cb38-184"><a href="#cb38-184"></a></span>
<span id="cb38-185"><a href="#cb38-185"></a>    <span class="co"># calculate the average loss over all of the batches.</span></span>
<span id="cb38-186"><a href="#cb38-186"></a>    avg_val_loss <span class="op">=</span> total_valid_loss <span class="op">/</span> <span class="bu">len</span>(dataloader)</span>
<span id="cb38-187"><a href="#cb38-187"></a></span>
<span id="cb38-188"><a href="#cb38-188"></a>    <span class="co"># Record all statistics from this epoch.</span></span>
<span id="cb38-189"><a href="#cb38-189"></a>    valid_stats.append(</span>
<span id="cb38-190"><a href="#cb38-190"></a>        {</span>
<span id="cb38-191"><a href="#cb38-191"></a>            <span class="st">&#39;Val Loss&#39;</span>: avg_val_loss,</span>
<span id="cb38-192"><a href="#cb38-192"></a>            <span class="st">&#39;Val Accur.&#39;</span>: avg_accuracy,</span>
<span id="cb38-193"><a href="#cb38-193"></a>            <span class="st">&#39;Val precision&#39;</span>: avg_precision,</span>
<span id="cb38-194"><a href="#cb38-194"></a>            <span class="st">&#39;Val recall&#39;</span>: avg_recall,</span>
<span id="cb38-195"><a href="#cb38-195"></a>            <span class="st">&#39;Val F1&#39;</span>: avg_val_f1</span>
<span id="cb38-196"><a href="#cb38-196"></a>        }</span>
<span id="cb38-197"><a href="#cb38-197"></a>    )</span>
<span id="cb38-198"><a href="#cb38-198"></a></span>
<span id="cb38-199"><a href="#cb38-199"></a>    <span class="co"># capture end validation time</span></span>
<span id="cb38-200"><a href="#cb38-200"></a>    training_time <span class="op">=</span> format_time(time.time() <span class="op">-</span> total_t0)</span>
<span id="cb38-201"><a href="#cb38-201"></a></span>
<span id="cb38-202"><a href="#cb38-202"></a>    <span class="co"># print result summaries</span></span>
<span id="cb38-203"><a href="#cb38-203"></a>    <span class="bu">print</span>(<span class="st">&quot;&quot;</span>)</span>
<span id="cb38-204"><a href="#cb38-204"></a>    <span class="bu">print</span>(<span class="st">&quot;summary results&quot;</span>)</span>
<span id="cb38-205"><a href="#cb38-205"></a>    <span class="bu">print</span>(<span class="st">&quot;epoch | val loss | val f1 | val time&quot;</span>)</span>
<span id="cb38-206"><a href="#cb38-206"></a>    <span class="bu">print</span>(<span class="ss">f&quot;</span><span class="sc">{</span>epoch<span class="op">+</span><span class="dv">1</span><span class="sc">:5d}</span><span class="ss"> | </span><span class="sc">{</span>avg_val_loss<span class="sc">:.5f}</span><span class="ss"> | </span><span class="sc">{</span>avg_val_f1<span class="sc">:.5f}</span><span class="ss"> | </span><span class="sc">{</span>training_time<span class="sc">:}</span><span class="ss">&quot;</span>)</span>
<span id="cb38-207"><a href="#cb38-207"></a></span>
<span id="cb38-208"><a href="#cb38-208"></a>    <span class="cf">return</span> <span class="va">None</span></span>
<span id="cb38-209"><a href="#cb38-209"></a></span>
<span id="cb38-210"><a href="#cb38-210"></a></span>
<span id="cb38-211"><a href="#cb38-211"></a><span class="kw">def</span> testing(model, dataloader, criterion):</span>
<span id="cb38-212"><a href="#cb38-212"></a></span>
<span id="cb38-213"><a href="#cb38-213"></a>    <span class="bu">print</span>(<span class="st">&quot;&quot;</span>)</span>
<span id="cb38-214"><a href="#cb38-214"></a>    <span class="bu">print</span>(<span class="st">&quot;Running Testing...&quot;</span>)</span>
<span id="cb38-215"><a href="#cb38-215"></a></span>
<span id="cb38-216"><a href="#cb38-216"></a>    <span class="co"># put the model in evaluation mode</span></span>
<span id="cb38-217"><a href="#cb38-217"></a>    model.<span class="bu">eval</span>()</span>
<span id="cb38-218"><a href="#cb38-218"></a></span>
<span id="cb38-219"><a href="#cb38-219"></a>    <span class="co"># track variables</span></span>
<span id="cb38-220"><a href="#cb38-220"></a>    total_test_accuracy <span class="op">=</span> <span class="dv">0</span></span>
<span id="cb38-221"><a href="#cb38-221"></a>    total_test_loss <span class="op">=</span> <span class="dv">0</span></span>
<span id="cb38-222"><a href="#cb38-222"></a>    total_test_f1 <span class="op">=</span> <span class="dv">0</span></span>
<span id="cb38-223"><a href="#cb38-223"></a>    total_test_recall <span class="op">=</span> <span class="dv">0</span></span>
<span id="cb38-224"><a href="#cb38-224"></a>    total_test_precision <span class="op">=</span> <span class="dv">0</span></span>
<span id="cb38-225"><a href="#cb38-225"></a></span>
<span id="cb38-226"><a href="#cb38-226"></a>    <span class="co"># evaluate data for one epoch</span></span>
<span id="cb38-227"><a href="#cb38-227"></a>    <span class="cf">for</span> step, batch <span class="kw">in</span> <span class="bu">enumerate</span>(dataloader):</span>
<span id="cb38-228"><a href="#cb38-228"></a>        <span class="co"># progress update every 40 batches.</span></span>
<span id="cb38-229"><a href="#cb38-229"></a>        <span class="cf">if</span> step <span class="op">%</span> <span class="dv">40</span> <span class="op">==</span> <span class="dv">0</span> <span class="kw">and</span> <span class="kw">not</span> step <span class="op">==</span> <span class="dv">0</span>:</span>
<span id="cb38-230"><a href="#cb38-230"></a></span>
<span id="cb38-231"><a href="#cb38-231"></a>            <span class="co"># Report progress.</span></span>
<span id="cb38-232"><a href="#cb38-232"></a>            <span class="bu">print</span>(<span class="st">&#39;  Batch {:&gt;5,}  of  {:&gt;5,}.&#39;</span>.<span class="bu">format</span>(step, <span class="bu">len</span>(dataloader)))</span>
<span id="cb38-233"><a href="#cb38-233"></a></span>
<span id="cb38-234"><a href="#cb38-234"></a>        <span class="co"># unpack batch from dataloader</span></span>
<span id="cb38-235"><a href="#cb38-235"></a>        b_input_ids <span class="op">=</span> batch[<span class="dv">0</span>].cuda()</span>
<span id="cb38-236"><a href="#cb38-236"></a>        b_labels <span class="op">=</span> batch[<span class="dv">1</span>].cuda().<span class="bu">type</span>(torch.cuda.FloatTensor)</span>
<span id="cb38-237"><a href="#cb38-237"></a></span>
<span id="cb38-238"><a href="#cb38-238"></a>        <span class="co"># tell pytorch not to bother calculating gradients</span></span>
<span id="cb38-239"><a href="#cb38-239"></a>        <span class="co"># only necessary for training</span></span>
<span id="cb38-240"><a href="#cb38-240"></a>        <span class="cf">with</span> torch.no_grad():</span>
<span id="cb38-241"><a href="#cb38-241"></a></span>
<span id="cb38-242"><a href="#cb38-242"></a>            <span class="co"># forward propagation (evaluate model on training batch)</span></span>
<span id="cb38-243"><a href="#cb38-243"></a>            logits <span class="op">=</span> model(b_input_ids)</span>
<span id="cb38-244"><a href="#cb38-244"></a></span>
<span id="cb38-245"><a href="#cb38-245"></a>            <span class="co"># calculate cross entropy loss</span></span>
<span id="cb38-246"><a href="#cb38-246"></a>            loss <span class="op">=</span> criterion(logits, b_labels)</span>
<span id="cb38-247"><a href="#cb38-247"></a></span>
<span id="cb38-248"><a href="#cb38-248"></a>            <span class="co"># accumulate validation loss</span></span>
<span id="cb38-249"><a href="#cb38-249"></a>            total_test_loss <span class="op">+=</span> loss.item()</span>
<span id="cb38-250"><a href="#cb38-250"></a></span>
<span id="cb38-251"><a href="#cb38-251"></a>        <span class="co"># move logits and labels to CPU</span></span>
<span id="cb38-252"><a href="#cb38-252"></a>        logits <span class="op">=</span> logits.detach().cpu().numpy()</span>
<span id="cb38-253"><a href="#cb38-253"></a>        y_true <span class="op">=</span> b_labels.detach().cpu().numpy()</span>
<span id="cb38-254"><a href="#cb38-254"></a></span>
<span id="cb38-255"><a href="#cb38-255"></a>        <span class="co"># calculate preds</span></span>
<span id="cb38-256"><a href="#cb38-256"></a>        rounded_preds <span class="op">=</span> np.argmax(logits, axis<span class="op">=</span><span class="dv">1</span>).flatten()</span>
<span id="cb38-257"><a href="#cb38-257"></a></span>
<span id="cb38-258"><a href="#cb38-258"></a>        <span class="co"># calculate f1</span></span>
<span id="cb38-259"><a href="#cb38-259"></a>        total_test_f1 <span class="op">+=</span> f1_score(rounded_preds, y_true,</span>
<span id="cb38-260"><a href="#cb38-260"></a>                                   average<span class="op">=</span><span class="st">&#39;weighted&#39;</span>,</span>
<span id="cb38-261"><a href="#cb38-261"></a>                                   labels<span class="op">=</span>np.unique(rounded_preds))</span>
<span id="cb38-262"><a href="#cb38-262"></a></span>
<span id="cb38-263"><a href="#cb38-263"></a>        <span class="co"># calculate accuracy</span></span>
<span id="cb38-264"><a href="#cb38-264"></a>        total_test_accuracy <span class="op">+=</span> accuracy_score(rounded_preds, y_true)</span>
<span id="cb38-265"><a href="#cb38-265"></a></span>
<span id="cb38-266"><a href="#cb38-266"></a>        <span class="co"># calculate precision</span></span>
<span id="cb38-267"><a href="#cb38-267"></a>        total_test_precision <span class="op">+=</span> precision_score(rounded_preds, y_true,</span>
<span id="cb38-268"><a href="#cb38-268"></a>                                                 average<span class="op">=</span><span class="st">&#39;weighted&#39;</span>,</span>
<span id="cb38-269"><a href="#cb38-269"></a>                                                 labels<span class="op">=</span>np.unique(rounded_preds))</span>
<span id="cb38-270"><a href="#cb38-270"></a></span>
<span id="cb38-271"><a href="#cb38-271"></a>        <span class="co"># calculate recall</span></span>
<span id="cb38-272"><a href="#cb38-272"></a>        total_test_recall <span class="op">+=</span> recall_score(rounded_preds, y_true,</span>
<span id="cb38-273"><a href="#cb38-273"></a>                                                 average<span class="op">=</span><span class="st">&#39;weighted&#39;</span>,</span>
<span id="cb38-274"><a href="#cb38-274"></a>                                                 labels<span class="op">=</span>np.unique(rounded_preds))</span>
<span id="cb38-275"><a href="#cb38-275"></a></span>
<span id="cb38-276"><a href="#cb38-276"></a>    <span class="co"># report final accuracy of validation run</span></span>
<span id="cb38-277"><a href="#cb38-277"></a>    avg_accuracy <span class="op">=</span> total_test_accuracy <span class="op">/</span> <span class="bu">len</span>(dataloader)</span>
<span id="cb38-278"><a href="#cb38-278"></a></span>
<span id="cb38-279"><a href="#cb38-279"></a>    <span class="co"># report final f1 of validation run</span></span>
<span id="cb38-280"><a href="#cb38-280"></a>    avg_test_f1 <span class="op">=</span> total_test_f1 <span class="op">/</span> <span class="bu">len</span>(dataloader)</span>
<span id="cb38-281"><a href="#cb38-281"></a></span>
<span id="cb38-282"><a href="#cb38-282"></a>    <span class="co"># report final f1 of validation run</span></span>
<span id="cb38-283"><a href="#cb38-283"></a>    avg_precision <span class="op">=</span> total_test_precision <span class="op">/</span> <span class="bu">len</span>(dataloader)</span>
<span id="cb38-284"><a href="#cb38-284"></a></span>
<span id="cb38-285"><a href="#cb38-285"></a>    <span class="co"># report final f1 of validation run</span></span>
<span id="cb38-286"><a href="#cb38-286"></a>    avg_recall <span class="op">=</span> total_test_recall <span class="op">/</span> <span class="bu">len</span>(dataloader)</span>
<span id="cb38-287"><a href="#cb38-287"></a></span>
<span id="cb38-288"><a href="#cb38-288"></a>    <span class="co"># calculate the average loss over all of the batches.</span></span>
<span id="cb38-289"><a href="#cb38-289"></a>    avg_test_loss <span class="op">=</span> total_test_loss <span class="op">/</span> <span class="bu">len</span>(dataloader)</span>
<span id="cb38-290"><a href="#cb38-290"></a></span>
<span id="cb38-291"><a href="#cb38-291"></a>    <span class="co"># Record all statistics from this epoch.</span></span>
<span id="cb38-292"><a href="#cb38-292"></a>    test_stats.append(</span>
<span id="cb38-293"><a href="#cb38-293"></a>        {</span>
<span id="cb38-294"><a href="#cb38-294"></a>            <span class="st">&#39;Test Loss&#39;</span>: avg_test_loss,</span>
<span id="cb38-295"><a href="#cb38-295"></a>            <span class="st">&#39;Test Accur.&#39;</span>: avg_accuracy,</span>
<span id="cb38-296"><a href="#cb38-296"></a>            <span class="st">&#39;Test precision&#39;</span>: avg_precision,</span>
<span id="cb38-297"><a href="#cb38-297"></a>            <span class="st">&#39;Test recall&#39;</span>: avg_recall,</span>
<span id="cb38-298"><a href="#cb38-298"></a>            <span class="st">&#39;Test F1&#39;</span>: avg_test_f1</span>
<span id="cb38-299"><a href="#cb38-299"></a>        }</span>
<span id="cb38-300"><a href="#cb38-300"></a>    )</span>
<span id="cb38-301"><a href="#cb38-301"></a>    <span class="cf">return</span> <span class="va">None</span></span></code></pre></div>
<p>In order to use our CNN, we need to specify a config class that sets a number of hyperparameters that the class is expecting.</p>
<div class="sourceCode" id="cb39"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb39-1"><a href="#cb39-1"></a><span class="co"># instantiate model config -- set ex-post from optuna search</span></span>
<span id="cb39-2"><a href="#cb39-2"></a><span class="kw">class</span> config:</span>
<span id="cb39-3"><a href="#cb39-3"></a>    <span class="kw">def</span> <span class="fu">__init__</span>(<span class="va">self</span>):</span>
<span id="cb39-4"><a href="#cb39-4"></a>        config.pre_embed <span class="op">=</span> embeddings_tensor  <span class="co"># GloVe vectors</span></span>
<span id="cb39-5"><a href="#cb39-5"></a>        config.mode <span class="op">=</span> <span class="st">&#39;static&#39;</span>  <span class="co"># dont train embedding</span></span>
<span id="cb39-6"><a href="#cb39-6"></a>        config.num_classes <span class="op">=</span> <span class="dv">1</span>  <span class="co"># binary</span></span>
<span id="cb39-7"><a href="#cb39-7"></a>        config.output_channel <span class="op">=</span> <span class="dv">300</span>  <span class="co"># number of kernels</span></span>
<span id="cb39-8"><a href="#cb39-8"></a>        config.embedding_dim <span class="op">=</span> <span class="dv">201</span>  <span class="co"># GloVe embed dimension (202)</span></span>
<span id="cb39-9"><a href="#cb39-9"></a>        config.vocab_size <span class="op">=</span> <span class="bu">len</span>(vocab)<span class="op">+</span><span class="dv">2</span>  <span class="co"># vocab size of corpus plus unknown/padding</span></span>
<span id="cb39-10"><a href="#cb39-10"></a>        config.dropout <span class="op">=</span> <span class="fl">0.1</span>  <span class="co"># dropout value</span></span>
<span id="cb39-11"><a href="#cb39-11"></a>        config.padding_idx <span class="op">=</span> <span class="dv">400001</span>  <span class="co"># padding token index</span></span>
<span id="cb39-12"><a href="#cb39-12"></a>        <span class="cf">return</span> <span class="va">None</span></span>
<span id="cb39-13"><a href="#cb39-13"></a></span>
<span id="cb39-14"><a href="#cb39-14"></a><span class="co"># create config</span></span>
<span id="cb39-15"><a href="#cb39-15"></a>config1 <span class="op">=</span> config()</span>
<span id="cb39-16"><a href="#cb39-16"></a></span>
<span id="cb39-17"><a href="#cb39-17"></a><span class="co"># instantiate model - attach to GPU</span></span>
<span id="cb39-18"><a href="#cb39-18"></a>model <span class="op">=</span> KimCNN(config1).cuda()</span></code></pre></div>
<p>Now we are almost ready to train. A few other preparatory objects are created like the loss criteria, epochs, the optimizer, and our optimizer scheduler.</p>
<div class="sourceCode" id="cb40"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb40-1"><a href="#cb40-1"></a><span class="co"># set loss</span></span>
<span id="cb40-2"><a href="#cb40-2"></a>criterion <span class="op">=</span> nn.BCEWithLogitsLoss()</span>
<span id="cb40-3"><a href="#cb40-3"></a></span>
<span id="cb40-4"><a href="#cb40-4"></a><span class="co"># set number of epochs</span></span>
<span id="cb40-5"><a href="#cb40-5"></a>epochs <span class="op">=</span> <span class="dv">5</span></span>
<span id="cb40-6"><a href="#cb40-6"></a></span>
<span id="cb40-7"><a href="#cb40-7"></a><span class="co"># set optimizer</span></span>
<span id="cb40-8"><a href="#cb40-8"></a>optimizer <span class="op">=</span> AdamW(model.parameters(),</span>
<span id="cb40-9"><a href="#cb40-9"></a>                  lr<span class="op">=</span><span class="fl">0.0009978734977728082</span>,</span>
<span id="cb40-10"><a href="#cb40-10"></a>                  weight_decay<span class="op">=</span><span class="fl">0.5</span></span>
<span id="cb40-11"><a href="#cb40-11"></a>                )</span>
<span id="cb40-12"><a href="#cb40-12"></a></span>
<span id="cb40-13"><a href="#cb40-13"></a><span class="co"># set LR scheduler</span></span>
<span id="cb40-14"><a href="#cb40-14"></a>total_steps <span class="op">=</span> <span class="bu">len</span>(train_dataloader) <span class="op">*</span> epochs</span>
<span id="cb40-15"><a href="#cb40-15"></a>scheduler <span class="op">=</span> get_linear_schedule_with_warmup(optimizer,</span>
<span id="cb40-16"><a href="#cb40-16"></a>                                            num_warmup_steps<span class="op">=</span><span class="dv">0</span>,</span>
<span id="cb40-17"><a href="#cb40-17"></a>                                            num_training_steps<span class="op">=</span>total_steps)</span>
<span id="cb40-18"><a href="#cb40-18"></a>                                            </span>
<span id="cb40-19"><a href="#cb40-19"></a><span class="co"># create gradient scaler for mixed precision</span></span>
<span id="cb40-20"><a href="#cb40-20"></a>scaler <span class="op">=</span> GradScaler()</span></code></pre></div>
<p>Finally we are ready to train. Two containers are created to store the results of each training and validation epoch</p>
<div class="sourceCode" id="cb41"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb41-1"><a href="#cb41-1"></a><span class="co"># create training result storage</span></span>
<span id="cb41-2"><a href="#cb41-2"></a>training_stats <span class="op">=</span> []</span>
<span id="cb41-3"><a href="#cb41-3"></a>valid_stats <span class="op">=</span> []</span>
<span id="cb41-4"><a href="#cb41-4"></a>best_valid_loss <span class="op">=</span> <span class="bu">float</span>(<span class="st">&#39;inf&#39;</span>)</span>
<span id="cb41-5"><a href="#cb41-5"></a></span>
<span id="cb41-6"><a href="#cb41-6"></a><span class="co"># for each epoch</span></span>
<span id="cb41-7"><a href="#cb41-7"></a><span class="cf">for</span> epoch <span class="kw">in</span> <span class="bu">range</span>(epochs):</span>
<span id="cb41-8"><a href="#cb41-8"></a>    <span class="co"># train</span></span>
<span id="cb41-9"><a href="#cb41-9"></a>    train(model, train_dataloader, optimizer, criterion)</span>
<span id="cb41-10"><a href="#cb41-10"></a>    <span class="co"># validate</span></span>
<span id="cb41-11"><a href="#cb41-11"></a>    validating(model, valid_dataloader, criterion)</span>
<span id="cb41-12"><a href="#cb41-12"></a>    <span class="co"># check validation loss</span></span>
<span id="cb41-13"><a href="#cb41-13"></a>    <span class="cf">if</span> valid_stats[epoch][<span class="st">&#39;Val Loss&#39;</span>] <span class="op">&lt;</span> best_valid_loss:</span>
<span id="cb41-14"><a href="#cb41-14"></a>        best_valid_loss <span class="op">=</span> valid_stats[epoch][<span class="st">&#39;Val Loss&#39;</span>]</span>
<span id="cb41-15"><a href="#cb41-15"></a>        <span class="co"># save best model for use later</span></span>
<span id="cb41-16"><a href="#cb41-16"></a>        torch.save(model.state_dict(), <span class="st">&#39;cnn-model1.pt&#39;</span>)</span></code></pre></div>
<pre><code>## 
## ======== Epoch 1 / 5 ========
## Training...
##   Batch    40  of    101.
##   Batch    80  of    101.
## 
## summary results
## epoch | trn loss | trn f1 | trn time 
##     1 | 0.36336 | 0.66291 | 0:00:07
## 
## Running Validation...
## 
## summary results
## epoch | val loss | val f1 | val time
##     1 | 0.38138 | 0.86569 | 0:00:00
## 
## ======== Epoch 2 / 5 ========
## Training...
##   Batch    40  of    101.
##   Batch    80  of    101.
## 
## summary results
## epoch | trn loss | trn f1 | trn time 
##     2 | 0.26760 | 0.66448 | 0:00:05
## 
## Running Validation...
## 
## summary results
## epoch | val loss | val f1 | val time
##     2 | 0.25522 | 0.86175 | 0:00:00
## 
## ======== Epoch 3 / 5 ========
## Training...
##   Batch    40  of    101.
##   Batch    80  of    101.
## 
## summary results
## epoch | trn loss | trn f1 | trn time 
##     3 | 0.20433 | 0.66856 | 0:00:05
## 
## Running Validation...
## 
## summary results
## epoch | val loss | val f1 | val time
##     3 | 0.30003 | 0.86516 | 0:00:00
## 
## ======== Epoch 4 / 5 ========
## Training...
##   Batch    40  of    101.
##   Batch    80  of    101.
## 
## summary results
## epoch | trn loss | trn f1 | trn time 
##     4 | 0.15845 | 0.66335 | 0:00:05
## 
## Running Validation...
## 
## summary results
## epoch | val loss | val f1 | val time
##     4 | 0.27516 | 0.86401 | 0:00:00
## 
## ======== Epoch 5 / 5 ========
## Training...
##   Batch    40  of    101.
##   Batch    80  of    101.
## 
## summary results
## epoch | trn loss | trn f1 | trn time 
##     5 | 0.13775 | 0.66508 | 0:00:05
## 
## Running Validation...
## 
## summary results
## epoch | val loss | val f1 | val time
##     5 | 0.27949 | 0.86093 | 0:00:00</code></pre>
<p>After training, we organize the results nicely in <code>pandas</code>.</p>
<div class="sourceCode" id="cb43"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb43-1"><a href="#cb43-1"></a><span class="co"># organize results</span></span>
<span id="cb43-2"><a href="#cb43-2"></a>pd.set_option(<span class="st">&#39;precision&#39;</span>, <span class="dv">3</span>)</span>
<span id="cb43-3"><a href="#cb43-3"></a>df_train_stats <span class="op">=</span> pd.DataFrame(data<span class="op">=</span>training_stats)</span>
<span id="cb43-4"><a href="#cb43-4"></a>df_valid_stats <span class="op">=</span> pd.DataFrame(data<span class="op">=</span>valid_stats)</span>
<span id="cb43-5"><a href="#cb43-5"></a>df_stats <span class="op">=</span> pd.concat([df_train_stats, df_valid_stats], axis<span class="op">=</span><span class="dv">1</span>)</span>
<span id="cb43-6"><a href="#cb43-6"></a>df_stats.insert(<span class="dv">0</span>, <span class="st">&#39;Epoch&#39;</span>, <span class="bu">range</span>(<span class="dv">1</span>, <span class="bu">len</span>(df_stats)<span class="op">+</span><span class="dv">1</span>))</span>
<span id="cb43-7"><a href="#cb43-7"></a>df_stats <span class="op">=</span> df_stats.set_index(<span class="st">&#39;Epoch&#39;</span>)</span>
<span id="cb43-8"><a href="#cb43-8"></a>df_stats</span></code></pre></div>
<pre><code>##        Train Loss  Train F1  Val Loss  ...  Val precision  Val recall  Val F1
## Epoch                                  ...                                   
## 1           0.363     0.663     0.381  ...            1.0       0.764   0.866
## 2           0.268     0.664     0.255  ...            1.0       0.758   0.862
## 3           0.204     0.669     0.300  ...            1.0       0.763   0.865
## 4           0.158     0.663     0.275  ...            1.0       0.762   0.864
## 5           0.138     0.665     0.279  ...            1.0       0.758   0.861
## 
## [5 rows x 7 columns]</code></pre>
<p>Then we plot our results like so:</p>
<div class="sourceCode" id="cb45"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb45-1"><a href="#cb45-1"></a><span class="kw">def</span> plot_results(df):</span>
<span id="cb45-2"><a href="#cb45-2"></a>    <span class="co"># styling from seaborn.</span></span>
<span id="cb45-3"><a href="#cb45-3"></a>    sns.<span class="bu">set</span>(style<span class="op">=</span><span class="st">&#39;darkgrid&#39;</span>)</span>
<span id="cb45-4"><a href="#cb45-4"></a>    <span class="co"># uncrease the plot size and font size.</span></span>
<span id="cb45-5"><a href="#cb45-5"></a>    sns.<span class="bu">set</span>(font_scale<span class="op">=</span><span class="fl">1.5</span>)</span>
<span id="cb45-6"><a href="#cb45-6"></a>    plt.rcParams[<span class="st">&quot;figure.figsize&quot;</span>] <span class="op">=</span> (<span class="dv">12</span>,<span class="dv">6</span>)</span>
<span id="cb45-7"><a href="#cb45-7"></a></span>
<span id="cb45-8"><a href="#cb45-8"></a>    <span class="co"># plot the learning curve.</span></span>
<span id="cb45-9"><a href="#cb45-9"></a>    plt.plot(df_stats[<span class="st">&#39;Train Loss&#39;</span>], <span class="st">&#39;b-o&#39;</span>, label<span class="op">=</span><span class="st">&quot;Training&quot;</span>)</span>
<span id="cb45-10"><a href="#cb45-10"></a>    plt.plot(df_stats[<span class="st">&#39;Val Loss&#39;</span>], <span class="st">&#39;g-o&#39;</span>, label<span class="op">=</span><span class="st">&quot;Validation&quot;</span>)</span>
<span id="cb45-11"><a href="#cb45-11"></a></span>
<span id="cb45-12"><a href="#cb45-12"></a>    <span class="co"># Label the plot.</span></span>
<span id="cb45-13"><a href="#cb45-13"></a>    plt.title(<span class="st">&quot;Training &amp; Validation Loss&quot;</span>)</span>
<span id="cb45-14"><a href="#cb45-14"></a>    plt.xlabel(<span class="st">&quot;Epoch&quot;</span>)</span>
<span id="cb45-15"><a href="#cb45-15"></a>    plt.ylabel(<span class="st">&quot;Loss&quot;</span>)</span>
<span id="cb45-16"><a href="#cb45-16"></a>    plt.legend()</span>
<span id="cb45-17"><a href="#cb45-17"></a>    plt.xticks([<span class="dv">1</span>, <span class="dv">2</span>, <span class="dv">3</span>, <span class="dv">4</span>])</span>
<span id="cb45-18"><a href="#cb45-18"></a>    <span class="cf">return</span> plt.show()</span>
<span id="cb45-19"><a href="#cb45-19"></a></span>
<span id="cb45-20"><a href="#cb45-20"></a></span>
<span id="cb45-21"><a href="#cb45-21"></a>plot_results(df_stats)</span></code></pre></div>
<div class="figure">
<img src="data:image/png;base64,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" style="width:75.0%" alt />
<p class="caption">Training Results</p>
</div>
<p>And lastly run our final test:</p>
<div class="sourceCode" id="cb46"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb46-1"><a href="#cb46-1"></a><span class="co"># test the model</span></span>
<span id="cb46-2"><a href="#cb46-2"></a>test_stats <span class="op">=</span> []</span>
<span id="cb46-3"><a href="#cb46-3"></a>model.load_state_dict(torch.load(<span class="st">&#39;cnn-model1.pt&#39;</span>))</span></code></pre></div>
<pre><code>## &lt;All keys matched successfully&gt;</code></pre>
<div class="sourceCode" id="cb48"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb48-1"><a href="#cb48-1"></a>testing(model, test_dataloader, criterion)</span></code></pre></div>
<pre><code>## 
## Running Testing...</code></pre>
<div class="sourceCode" id="cb50"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb50-1"><a href="#cb50-1"></a>df_test_stats <span class="op">=</span> pd.DataFrame(data<span class="op">=</span>test_stats)</span>
<span id="cb50-2"><a href="#cb50-2"></a>df_test_stats</span></code></pre></div>
<pre><code>##    Test Loss  Test Accur.  Test precision  Test recall  Test F1
## 0       0.26         0.77             1.0         0.77    0.869</code></pre>
<p>Pretty good results for a novel data set made from scratch with an “outdated” model.</p>
</div>
<div id="cnn-inference" class="section level1" number="4">
<h1 number="4"><span class="header-section-number">4</span> CNN: Inference</h1>
<p>There are some other tasks that might want to do like inference which is using what we know to predict what we do not. So let’s say that we have two new messages but no labels (see below). We can tokenize these strings like all of our other data and generate on-the-fly predictions about their inferred label.</p>
<div class="sourceCode" id="cb52"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb52-1"><a href="#cb52-1"></a><span class="co"># inference</span></span>
<span id="cb52-2"><a href="#cb52-2"></a><span class="kw">def</span> infer_class(model, string_df, min_len<span class="op">=</span>percentile_95):</span>
<span id="cb52-3"><a href="#cb52-3"></a>    <span class="co"># tokenize the string into GloVe</span></span>
<span id="cb52-4"><a href="#cb52-4"></a>    no_matches, glove_tokenized_data <span class="op">=</span> text_to_GloVe_tokens(string_df, embeddings_dictionary)</span>
<span id="cb52-5"><a href="#cb52-5"></a>    <span class="co"># check length</span></span>
<span id="cb52-6"><a href="#cb52-6"></a>    <span class="cf">if</span> <span class="bu">len</span>(glove_tokenized_data[<span class="dv">0</span>]) <span class="op">&lt;</span> min_len:</span>
<span id="cb52-7"><a href="#cb52-7"></a>        glove_tokenized_data <span class="op">=</span> pad_GloVe(glove_tokenized_data, percentile_95)</span>
<span id="cb52-8"><a href="#cb52-8"></a>    tensor <span class="op">=</span> torch.LongTensor(glove_tokenized_data[<span class="dv">0</span>]).cuda()</span>
<span id="cb52-9"><a href="#cb52-9"></a>    tensor <span class="op">=</span> tensor.unsqueeze(<span class="dv">0</span>)</span>
<span id="cb52-10"><a href="#cb52-10"></a>    logits <span class="op">=</span> model(tensor)</span>
<span id="cb52-11"><a href="#cb52-11"></a>    rounded_preds <span class="op">=</span> torch.<span class="bu">round</span>(torch.sigmoid(logits))</span>
<span id="cb52-12"><a href="#cb52-12"></a>    <span class="cf">return</span> <span class="bu">print</span>(rounded_preds.item())</span></code></pre></div>
<div class="sourceCode" id="cb53"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb53-1"><a href="#cb53-1"></a>str_US <span class="op">=</span> [<span class="st">&#39;You will no longer be sent to an eternal war, President Donald Trump told a gathering marking the graduation of the US military academy. You will no longer fight in countries whose names are not known to most Americans. You will no longer be involved in the wars of the ancient nations. Clearly, Trump is referring to the long-running war in Afghanistan. The United States has been fighting the for the past two decades; it suffered a high number of casualties along with enormous financial losses. Many times, senior US officials have acknowledged that they cannot win the war in Afghanistan. Trump has told the truth, that his troops will no longer be involved in the wars of the ancient nations, because the never-ending war in Afghanistan has severely damaged America is reputation on the international level and caused the country extreme economic hardships. Recent surveys show that the support in the United States for this lost war has plummeted, and the people have now realized that the American leaders made false promises about this war. Nearly 20 years ago, the founder of the Islamic Emirate, the late Amir al- Mu aminin Mullah Mohammad Omar, warned the Americans to give up the intention of occupying Afghanistan.&#39;</span>]</span>
<span id="cb53-2"><a href="#cb53-2"></a></span>
<span id="cb53-3"><a href="#cb53-3"></a>str_AF <span class="op">=</span> [<span class="st">&#39;On 15 June, the soldiers of the puppet regime came to carry out operations in Sheikhano area , Tagab District, Kapisa Province. The mujahideen retaliated severely: 17 offensive soldiers of the puppet were killed in the operation; many of their corpses are lying on the battlefield; and many others were wounded.&#39;</span>]</span>
<span id="cb53-4"><a href="#cb53-4"></a></span>
<span id="cb53-5"><a href="#cb53-5"></a></span>
<span id="cb53-6"><a href="#cb53-6"></a>temp_df_US <span class="op">=</span> pd.DataFrame({<span class="st">&#39;body&#39;</span>: str_US})</span>
<span id="cb53-7"><a href="#cb53-7"></a>temp_df_US <span class="op">=</span> clean_df(temp_df_US)</span>
<span id="cb53-8"><a href="#cb53-8"></a><span class="bu">print</span>(infer_class(model, temp_df_US))  <span class="co"># 1 = US = Correct</span></span></code></pre></div>
<pre><code>## 1.0
## None</code></pre>
<div class="sourceCode" id="cb55"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb55-1"><a href="#cb55-1"></a>temp_df_AF <span class="op">=</span> pd.DataFrame({<span class="st">&#39;body&#39;</span>: str_AF})</span>
<span id="cb55-2"><a href="#cb55-2"></a>temp_df_AF <span class="op">=</span> clean_df(temp_df_AF)</span>
<span id="cb55-3"><a href="#cb55-3"></a><span class="bu">print</span>(infer_class(model, temp_df_AF))  <span class="co"># 0 = Kabul = Correct</span></span></code></pre></div>
<pre><code>## 0.0
## None</code></pre>
</div>
<div id="cnn-hyperband-and-asha-hyperparameter-search-with-optuna" class="section level1" number="5">
<h1 number="5"><span class="header-section-number">5</span> CNN: Hyperband and ASHA Hyperparameter Search with Optuna</h1>
<p>The code below shows how we can use state-of-the-art pruning and search algorithms to improve our model’s performance through hyperparameter selection.</p>
<div class="sourceCode" id="cb57"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb57-1"><a href="#cb57-1"></a><span class="co"># optuna -- tune hyperparameters</span></span>
<span id="cb57-2"><a href="#cb57-2"></a><span class="co"># create gradient scaler for mixed precision</span></span>
<span id="cb57-3"><a href="#cb57-3"></a>scaler <span class="op">=</span> GradScaler()</span>
<span id="cb57-4"><a href="#cb57-4"></a></span>
<span id="cb57-5"><a href="#cb57-5"></a>training_stats <span class="op">=</span> []</span>
<span id="cb57-6"><a href="#cb57-6"></a>valid_stats <span class="op">=</span> []</span>
<span id="cb57-7"><a href="#cb57-7"></a>epochs <span class="op">=</span> <span class="dv">5</span></span>
<span id="cb57-8"><a href="#cb57-8"></a><span class="kw">def</span> objective(trial):</span>
<span id="cb57-9"><a href="#cb57-9"></a></span>
<span id="cb57-10"><a href="#cb57-10"></a>    <span class="co"># alter hyperparameters</span></span>
<span id="cb57-11"><a href="#cb57-11"></a>    kernel_num <span class="op">=</span> trial.suggest_int(<span class="st">&#39;output_channel&#39;</span>, low<span class="op">=</span><span class="dv">600</span>, high<span class="op">=</span><span class="dv">1500</span>, step<span class="op">=</span><span class="dv">50</span>)</span>
<span id="cb57-12"><a href="#cb57-12"></a>    dropout_num <span class="op">=</span> trial.suggest_float(<span class="st">&#39;dropout&#39;</span>, low<span class="op">=</span><span class="fl">0.1</span>, high<span class="op">=</span><span class="fl">0.5</span>, step<span class="op">=</span><span class="fl">0.05</span>)</span>
<span id="cb57-13"><a href="#cb57-13"></a>    learning_rate <span class="op">=</span> trial.suggest_loguniform(<span class="st">&#39;lr&#39;</span>, <span class="fl">1e-5</span>, <span class="fl">1e-3</span>)</span>
<span id="cb57-14"><a href="#cb57-14"></a>    config1 <span class="op">=</span> config()</span>
<span id="cb57-15"><a href="#cb57-15"></a>    config1.output_channel <span class="op">=</span> kernel_num</span>
<span id="cb57-16"><a href="#cb57-16"></a>    config1.dropout <span class="op">=</span> dropout_num</span>
<span id="cb57-17"><a href="#cb57-17"></a></span>
<span id="cb57-18"><a href="#cb57-18"></a>    <span class="co"># data loaders</span></span>
<span id="cb57-19"><a href="#cb57-19"></a>    train_dataloader <span class="op">=</span> DataLoader(train_dataset,</span>
<span id="cb57-20"><a href="#cb57-20"></a>                                  batch_size<span class="op">=</span><span class="dv">80</span>,</span>
<span id="cb57-21"><a href="#cb57-21"></a>                                  sampler<span class="op">=</span>train_sampler,</span>
<span id="cb57-22"><a href="#cb57-22"></a>                                  shuffle<span class="op">=</span><span class="va">False</span>)</span>
<span id="cb57-23"><a href="#cb57-23"></a></span>
<span id="cb57-24"><a href="#cb57-24"></a>    valid_dataloader <span class="op">=</span> DataLoader(val_dataset,</span>
<span id="cb57-25"><a href="#cb57-25"></a>                                  batch_size<span class="op">=</span><span class="dv">80</span>,</span>
<span id="cb57-26"><a href="#cb57-26"></a>                                  shuffle<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb57-27"><a href="#cb57-27"></a></span>
<span id="cb57-28"><a href="#cb57-28"></a>    <span class="co"># instantiate model</span></span>
<span id="cb57-29"><a href="#cb57-29"></a>    model <span class="op">=</span> KimCNN(config1).cuda()</span>
<span id="cb57-30"><a href="#cb57-30"></a>    <span class="co"># set optimizer</span></span>
<span id="cb57-31"><a href="#cb57-31"></a>    optimizer <span class="op">=</span> AdamW(model.parameters(),</span>
<span id="cb57-32"><a href="#cb57-32"></a>                      lr<span class="op">=</span>learning_rate)</span>
<span id="cb57-33"><a href="#cb57-33"></a></span>
<span id="cb57-34"><a href="#cb57-34"></a>    criterion <span class="op">=</span> nn.BCEWithLogitsLoss()</span>
<span id="cb57-35"><a href="#cb57-35"></a></span>
<span id="cb57-36"><a href="#cb57-36"></a>    <span class="co"># set LR scheduler</span></span>
<span id="cb57-37"><a href="#cb57-37"></a>    total_steps <span class="op">=</span> <span class="bu">len</span>(train_dataloader) <span class="op">*</span> epochs</span>
<span id="cb57-38"><a href="#cb57-38"></a>    <span class="kw">global</span> scheduler</span>
<span id="cb57-39"><a href="#cb57-39"></a>    scheduler <span class="op">=</span> get_linear_schedule_with_warmup(optimizer,</span>
<span id="cb57-40"><a href="#cb57-40"></a>                                                num_warmup_steps<span class="op">=</span><span class="dv">0</span>,</span>
<span id="cb57-41"><a href="#cb57-41"></a>                                                num_training_steps<span class="op">=</span>total_steps)</span>
<span id="cb57-42"><a href="#cb57-42"></a></span>
<span id="cb57-43"><a href="#cb57-43"></a>    <span class="kw">global</span> epoch</span>
<span id="cb57-44"><a href="#cb57-44"></a>    <span class="cf">for</span> epoch <span class="kw">in</span> <span class="bu">range</span>(epochs):</span>
<span id="cb57-45"><a href="#cb57-45"></a>        <span class="co"># set containers</span></span>
<span id="cb57-46"><a href="#cb57-46"></a>        train_total_loss <span class="op">=</span> <span class="dv">0</span></span>
<span id="cb57-47"><a href="#cb57-47"></a>        total_train_f1 <span class="op">=</span> <span class="dv">0</span></span>
<span id="cb57-48"><a href="#cb57-48"></a></span>
<span id="cb57-49"><a href="#cb57-49"></a>        <span class="co"># put model into traning mode</span></span>
<span id="cb57-50"><a href="#cb57-50"></a>        model.train()</span>
<span id="cb57-51"><a href="#cb57-51"></a></span>
<span id="cb57-52"><a href="#cb57-52"></a>        <span class="co"># for each batch of training data...</span></span>
<span id="cb57-53"><a href="#cb57-53"></a>        <span class="cf">for</span> step, batch <span class="kw">in</span> <span class="bu">enumerate</span>(train_dataloader):</span>
<span id="cb57-54"><a href="#cb57-54"></a>            b_input_ids <span class="op">=</span> batch[<span class="dv">0</span>].cuda()</span>
<span id="cb57-55"><a href="#cb57-55"></a>            b_labels <span class="op">=</span> batch[<span class="dv">1</span>].cuda().<span class="bu">type</span>(torch.cuda.FloatTensor)</span>
<span id="cb57-56"><a href="#cb57-56"></a></span>
<span id="cb57-57"><a href="#cb57-57"></a>            optimizer.zero_grad()</span>
<span id="cb57-58"><a href="#cb57-58"></a></span>
<span id="cb57-59"><a href="#cb57-59"></a>            <span class="cf">with</span> autocast():</span>
<span id="cb57-60"><a href="#cb57-60"></a>                logits <span class="op">=</span> model(b_input_ids)</span>
<span id="cb57-61"><a href="#cb57-61"></a>                loss <span class="op">=</span> criterion(logits, b_labels)</span>
<span id="cb57-62"><a href="#cb57-62"></a></span>
<span id="cb57-63"><a href="#cb57-63"></a>            train_total_loss <span class="op">+=</span> loss.item()</span>
<span id="cb57-64"><a href="#cb57-64"></a></span>
<span id="cb57-65"><a href="#cb57-65"></a>            scaler.scale(loss).backward()</span>
<span id="cb57-66"><a href="#cb57-66"></a>            scaler.step(optimizer)</span>
<span id="cb57-67"><a href="#cb57-67"></a>            scaler.update()</span>
<span id="cb57-68"><a href="#cb57-68"></a>            scheduler.step()</span>
<span id="cb57-69"><a href="#cb57-69"></a></span>
<span id="cb57-70"><a href="#cb57-70"></a>        <span class="co"># validation</span></span>
<span id="cb57-71"><a href="#cb57-71"></a>        model.<span class="bu">eval</span>()</span>
<span id="cb57-72"><a href="#cb57-72"></a></span>
<span id="cb57-73"><a href="#cb57-73"></a>        total_valid_loss <span class="op">=</span> <span class="dv">0</span></span>
<span id="cb57-74"><a href="#cb57-74"></a>        total_valid_f1 <span class="op">=</span> <span class="dv">0</span></span>
<span id="cb57-75"><a href="#cb57-75"></a></span>
<span id="cb57-76"><a href="#cb57-76"></a>        <span class="co"># evaluate data for one epoch</span></span>
<span id="cb57-77"><a href="#cb57-77"></a>        <span class="cf">for</span> batch <span class="kw">in</span> valid_dataloader:</span>
<span id="cb57-78"><a href="#cb57-78"></a></span>
<span id="cb57-79"><a href="#cb57-79"></a>            b_input_ids <span class="op">=</span> batch[<span class="dv">0</span>].cuda()</span>
<span id="cb57-80"><a href="#cb57-80"></a>            b_labels <span class="op">=</span> batch[<span class="dv">1</span>].cuda().<span class="bu">type</span>(torch.cuda.FloatTensor)</span>
<span id="cb57-81"><a href="#cb57-81"></a></span>
<span id="cb57-82"><a href="#cb57-82"></a>            <span class="cf">with</span> torch.no_grad():</span>
<span id="cb57-83"><a href="#cb57-83"></a>                logits <span class="op">=</span> model(b_input_ids)</span>
<span id="cb57-84"><a href="#cb57-84"></a>                loss <span class="op">=</span> criterion(logits, b_labels)</span>
<span id="cb57-85"><a href="#cb57-85"></a></span>
<span id="cb57-86"><a href="#cb57-86"></a>            total_valid_loss <span class="op">+=</span> loss.item()</span>
<span id="cb57-87"><a href="#cb57-87"></a></span>
<span id="cb57-88"><a href="#cb57-88"></a>        <span class="co"># generate predictions</span></span>
<span id="cb57-89"><a href="#cb57-89"></a>        rounded_preds <span class="op">=</span> torch.<span class="bu">round</span>(torch.sigmoid(logits))</span>
<span id="cb57-90"><a href="#cb57-90"></a></span>
<span id="cb57-91"><a href="#cb57-91"></a>        <span class="co"># move logits and labels to CPU</span></span>
<span id="cb57-92"><a href="#cb57-92"></a>        rounded_preds <span class="op">=</span> rounded_preds.detach().cpu().numpy()</span>
<span id="cb57-93"><a href="#cb57-93"></a>        y_true <span class="op">=</span> b_labels.detach().cpu().numpy()</span>
<span id="cb57-94"><a href="#cb57-94"></a></span>
<span id="cb57-95"><a href="#cb57-95"></a>        <span class="co"># calculate f1</span></span>
<span id="cb57-96"><a href="#cb57-96"></a>        total_valid_f1 <span class="op">+=</span> f1_score(rounded_preds, y_true,</span>
<span id="cb57-97"><a href="#cb57-97"></a>                                   average<span class="op">=</span><span class="st">&#39;weighted&#39;</span>,</span>
<span id="cb57-98"><a href="#cb57-98"></a>                                   labels<span class="op">=</span>np.unique(rounded_preds))</span>
<span id="cb57-99"><a href="#cb57-99"></a></span>
<span id="cb57-100"><a href="#cb57-100"></a>        avg_val_f1 <span class="op">=</span> total_valid_f1 <span class="op">/</span> <span class="bu">len</span>(valid_dataloader)</span>
<span id="cb57-101"><a href="#cb57-101"></a></span>
<span id="cb57-102"><a href="#cb57-102"></a>        avg_val_loss <span class="op">=</span> total_valid_loss <span class="op">/</span> <span class="bu">len</span>(valid_dataloader)</span>
<span id="cb57-103"><a href="#cb57-103"></a></span>
<span id="cb57-104"><a href="#cb57-104"></a>    trial.report(avg_val_loss, epoch)</span>
<span id="cb57-105"><a href="#cb57-105"></a></span>
<span id="cb57-106"><a href="#cb57-106"></a>    <span class="co"># Handle pruning based on the intermediate value.</span></span>
<span id="cb57-107"><a href="#cb57-107"></a>    <span class="cf">if</span> trial.should_prune():</span>
<span id="cb57-108"><a href="#cb57-108"></a>        <span class="cf">raise</span> optuna.exceptions.TrialPruned()</span>
<span id="cb57-109"><a href="#cb57-109"></a></span>
<span id="cb57-110"><a href="#cb57-110"></a>    <span class="cf">return</span> avg_val_loss</span>
<span id="cb57-111"><a href="#cb57-111"></a></span>
<span id="cb57-112"><a href="#cb57-112"></a></span>
<span id="cb57-113"><a href="#cb57-113"></a></span>
<span id="cb57-114"><a href="#cb57-114"></a>study <span class="op">=</span> optuna.create_study(direction<span class="op">=</span><span class="st">&quot;minimize&quot;</span>,</span>
<span id="cb57-115"><a href="#cb57-115"></a>                            pruner<span class="op">=</span>optuna.pruners.HyperbandPruner(min_resource<span class="op">=</span><span class="dv">1</span>,</span>
<span id="cb57-116"><a href="#cb57-116"></a>                                                                  max_resource<span class="op">=</span><span class="dv">5</span>,</span>
<span id="cb57-117"><a href="#cb57-117"></a>                                                                  reduction_factor<span class="op">=</span><span class="dv">3</span>,</span>
<span id="cb57-118"><a href="#cb57-118"></a>                                                                  ))</span>
<span id="cb57-119"><a href="#cb57-119"></a>study.optimize(objective, n_trials<span class="op">=</span><span class="dv">35</span>)</span>
<span id="cb57-120"><a href="#cb57-120"></a></span>
<span id="cb57-121"><a href="#cb57-121"></a></span>
<span id="cb57-122"><a href="#cb57-122"></a>pruned_trials <span class="op">=</span> [t <span class="cf">for</span> t <span class="kw">in</span> study.trials <span class="cf">if</span> t.state <span class="op">==</span> optuna.trial.TrialState.PRUNED]</span>
<span id="cb57-123"><a href="#cb57-123"></a>complete_trials <span class="op">=</span> [t <span class="cf">for</span> t <span class="kw">in</span> study.trials <span class="cf">if</span> t.state <span class="op">==</span> optuna.trial.TrialState.COMPLETE]</span>
<span id="cb57-124"><a href="#cb57-124"></a></span>
<span id="cb57-125"><a href="#cb57-125"></a><span class="bu">print</span>(<span class="st">&quot;Study statistics: &quot;</span>)</span>
<span id="cb57-126"><a href="#cb57-126"></a><span class="bu">print</span>(<span class="st">&quot;  Number of finished trials: &quot;</span>, <span class="bu">len</span>(study.trials))</span>
<span id="cb57-127"><a href="#cb57-127"></a><span class="bu">print</span>(<span class="st">&quot;  Number of pruned trials: &quot;</span>, <span class="bu">len</span>(pruned_trials))</span>
<span id="cb57-128"><a href="#cb57-128"></a><span class="bu">print</span>(<span class="st">&quot;  Number of complete trials: &quot;</span>, <span class="bu">len</span>(complete_trials))</span>
<span id="cb57-129"><a href="#cb57-129"></a></span>
<span id="cb57-130"><a href="#cb57-130"></a><span class="bu">print</span>(<span class="st">&quot;Best trial:&quot;</span>)</span>
<span id="cb57-131"><a href="#cb57-131"></a>trial <span class="op">=</span> study.best_trial</span>
<span id="cb57-132"><a href="#cb57-132"></a></span>
<span id="cb57-133"><a href="#cb57-133"></a><span class="bu">print</span>(<span class="st">&quot;  Value: &quot;</span>, trial.value)</span>
<span id="cb57-134"><a href="#cb57-134"></a></span>
<span id="cb57-135"><a href="#cb57-135"></a><span class="bu">print</span>(<span class="st">&quot;  Params: &quot;</span>)</span>
<span id="cb57-136"><a href="#cb57-136"></a><span class="cf">for</span> key, value <span class="kw">in</span> trial.params.items():</span>
<span id="cb57-137"><a href="#cb57-137"></a>    <span class="bu">print</span>(<span class="st">&quot;    </span><span class="sc">{}</span><span class="st">: </span><span class="sc">{}</span><span class="st">&quot;</span>.<span class="bu">format</span>(key, value))</span></code></pre></div>
</div>
<div id="sources" class="section level1" number="6">
<h1 number="6"><span class="header-section-number">6</span> Sources</h1>
<ul>
<li><p>Pennington, Jeffrey, Richard Socher, and Christopher D. Manning. “Glove: Global vectors for word representation.” In Proceedings of the 2014 conference on empirical methods in natural language processing (EMNLP), pp. 1532-1543. 2014. GloVe <a href="https://nlp.stanford.edu/projects/glove/" class="uri">https://nlp.stanford.edu/projects/glove/</a></p></li>
<li><p>Kim, Yoon. “Convolutional neural networks for sentence classification.” arXiv preprint arXiv:1408.5882 (2014).</p></li>
</ul>
</div>



<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    script.src  = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML";
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>

</body>
</html>
