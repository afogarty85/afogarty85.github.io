<!DOCTYPE html>

<html xmlns="http://www.w3.org/1999/xhtml">

<head>

<meta charset="utf-8" />
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="generator" content="pandoc" />

<meta name="viewport" content="width=device-width, initial-scale=1">

<meta name="author" content="Andrew Fogarty" />


<title>Text Classification: CNN</title>



<style type="text/css">code{white-space: pre;}</style>
<style type="text/css" data-origin="pandoc">
a.sourceLine { display: inline-block; line-height: 1.25; }
a.sourceLine { pointer-events: none; color: inherit; text-decoration: inherit; }
a.sourceLine:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode { white-space: pre; position: relative; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
code.sourceCode { white-space: pre-wrap; }
a.sourceLine { text-indent: -1em; padding-left: 1em; }
}
pre.numberSource a.sourceLine
  { position: relative; left: -4em; }
pre.numberSource a.sourceLine::before
  { content: attr(title);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; pointer-events: all; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {  }
@media screen {
a.sourceLine::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */

</style>
<script>
// apply pandoc div.sourceCode style to pre.sourceCode instead
(function() {
  var sheets = document.styleSheets;
  for (var i = 0; i < sheets.length; i++) {
    if (sheets[i].ownerNode.dataset["origin"] !== "pandoc") continue;
    try { var rules = sheets[i].cssRules; } catch (e) { continue; }
    for (var j = 0; j < rules.length; j++) {
      var rule = rules[j];
      // check if there is a div.sourceCode rule
      if (rule.type !== rule.STYLE_RULE || rule.selectorText !== "div.sourceCode") continue;
      var style = rule.style.cssText;
      // check if color or background-color is set
      if (rule.style.color === '' || rule.style.backgroundColor === '') continue;
      // replace div.sourceCode by a pre.sourceCode rule
      sheets[i].deleteRule(j);
      sheets[i].insertRule('pre.sourceCode{' + style + '}', j);
    }
  }
})();
</script>



<style type="text/css">body {
background-color: #fff;
margin: 1em auto;
max-width: 700px;
overflow: visible;
padding-left: 2em;
padding-right: 2em;
font-family: "Open Sans", "Helvetica Neue", Helvetica, Arial, sans-serif;
font-size: 14px;
line-height: 1.35;
}
#header {
text-align: center;
}
#TOC {
clear: both;
margin: 0 0 10px 10px;
padding: 4px;
width: 400px;
border: 1px solid #CCCCCC;
border-radius: 5px;
background-color: #f6f6f6;
font-size: 13px;
line-height: 1.3;
}
#TOC .toctitle {
font-weight: bold;
font-size: 15px;
margin-left: 5px;
}
#TOC ul {
padding-left: 40px;
margin-left: -1.5em;
margin-top: 5px;
margin-bottom: 5px;
}
#TOC ul ul {
margin-left: -2em;
}
#TOC li {
line-height: 16px;
}
table {
margin: 1em auto;
border-width: 1px;
border-color: #DDDDDD;
border-style: outset;
border-collapse: collapse;
}
table th {
border-width: 2px;
padding: 5px;
border-style: inset;
}
table td {
border-width: 1px;
border-style: inset;
line-height: 18px;
padding: 5px 5px;
}
table, table th, table td {
border-left-style: none;
border-right-style: none;
}
table thead, table tr.even {
background-color: #f7f7f7;
}
p {
margin: 0.5em 0;
}
blockquote {
background-color: #f6f6f6;
padding: 0.25em 0.75em;
}
hr {
border-style: solid;
border: none;
border-top: 1px solid #777;
margin: 28px 0;
}
dl {
margin-left: 0;
}
dl dd {
margin-bottom: 13px;
margin-left: 13px;
}
dl dt {
font-weight: bold;
}
ul {
margin-top: 0;
}
ul li {
list-style: circle outside;
}
ul ul {
margin-bottom: 0;
}
pre, code {
background-color: #f7f7f7;
border-radius: 3px;
color: #333;
white-space: pre-wrap; 
}
pre {
border-radius: 3px;
margin: 5px 0px 10px 0px;
padding: 10px;
}
pre:not([class]) {
background-color: #f7f7f7;
}
code {
font-family: Consolas, Monaco, 'Courier New', monospace;
font-size: 85%;
}
p > code, li > code {
padding: 2px 0px;
}
div.figure {
text-align: center;
}
img {
background-color: #FFFFFF;
padding: 2px;
border: 1px solid #DDDDDD;
border-radius: 3px;
border: 1px solid #CCCCCC;
margin: 0 5px;
}
h1 {
margin-top: 0;
font-size: 35px;
line-height: 40px;
}
h2 {
border-bottom: 4px solid #f7f7f7;
padding-top: 10px;
padding-bottom: 2px;
font-size: 145%;
}
h3 {
border-bottom: 2px solid #f7f7f7;
padding-top: 10px;
font-size: 120%;
}
h4 {
border-bottom: 1px solid #f7f7f7;
margin-left: 8px;
font-size: 105%;
}
h5, h6 {
border-bottom: 1px solid #ccc;
font-size: 105%;
}
a {
color: #0033dd;
text-decoration: none;
}
a:hover {
color: #6666ff; }
a:visited {
color: #800080; }
a:visited:hover {
color: #BB00BB; }
a[href^="http:"] {
text-decoration: underline; }
a[href^="https:"] {
text-decoration: underline; }

code > span.kw { color: #555; font-weight: bold; } 
code > span.dt { color: #902000; } 
code > span.dv { color: #40a070; } 
code > span.bn { color: #d14; } 
code > span.fl { color: #d14; } 
code > span.ch { color: #d14; } 
code > span.st { color: #d14; } 
code > span.co { color: #888888; font-style: italic; } 
code > span.ot { color: #007020; } 
code > span.al { color: #ff0000; font-weight: bold; } 
code > span.fu { color: #900; font-weight: bold; }  code > span.er { color: #a61717; background-color: #e3d2d2; } 
</style>




</head>

<body>




<h1 class="title toc-ignore">Text Classification: CNN</h1>
<h4 class="author">Andrew Fogarty</h4>
<h4 class="date">7/14/2020</h4>


<div id="TOC">
<ul>
<li><a href="#introduction"><span class="toc-section-number">1</span> Introduction</a></li>
<li><a href="#convolutional-neural-networks"><span class="toc-section-number">2</span> Convolutional Neural Networks</a></li>
<li><a href="#cnns-using-glove-embeddings"><span class="toc-section-number">3</span> CNNs using GloVe Embeddings</a></li>
<li><a href="#cnn-inference"><span class="toc-section-number">4</span> CNN: Inference</a></li>
<li><a href="#cnn-hyperband-and-asha-hyperparameter-search-with-optuna"><span class="toc-section-number">5</span> CNN: Hyperband and ASHA Hyperparameter Search with Optuna</a></li>
<li><a href="#sources"><span class="toc-section-number">6</span> Sources</a></li>
</ul>
</div>

<div class="sourceCode" id="cb1"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb1-1" title="1"><span class="co"># load python</span></a>
<a class="sourceLine" id="cb1-2" title="2"><span class="kw">library</span>(reticulate)</a>
<a class="sourceLine" id="cb1-3" title="3"><span class="kw">use_condaenv</span>(<span class="st">&quot;my_ml&quot;</span>)</a></code></pre></div>
<div class="sourceCode" id="cb2"><pre class="sourceCode python"><code class="sourceCode python"><a class="sourceLine" id="cb2-1" title="1"><span class="co"># load packages</span></a>
<a class="sourceLine" id="cb2-2" title="2"><span class="im">import</span> torch</a>
<a class="sourceLine" id="cb2-3" title="3"><span class="im">import</span> torch.nn <span class="im">as</span> nn</a>
<a class="sourceLine" id="cb2-4" title="4"><span class="im">import</span> torch.nn.functional <span class="im">as</span> F</a>
<a class="sourceLine" id="cb2-5" title="5"><span class="im">import</span> numpy <span class="im">as</span> np</a>
<a class="sourceLine" id="cb2-6" title="6"><span class="im">import</span> pandas <span class="im">as</span> pd</a>
<a class="sourceLine" id="cb2-7" title="7"><span class="im">from</span> sklearn.model_selection <span class="im">import</span> train_test_split</a>
<a class="sourceLine" id="cb2-8" title="8"><span class="im">import</span> torch.optim <span class="im">as</span> optim</a>
<a class="sourceLine" id="cb2-9" title="9"><span class="im">from</span> torchvision <span class="im">import</span> datasets, transforms</a>
<a class="sourceLine" id="cb2-10" title="10"><span class="im">from</span> torch.utils.data <span class="im">import</span> TensorDataset, random_split, DataLoader, RandomSampler, SequentialSampler</a>
<a class="sourceLine" id="cb2-11" title="11"><span class="im">import</span> time</a>
<a class="sourceLine" id="cb2-12" title="12"><span class="im">import</span> datetime</a>
<a class="sourceLine" id="cb2-13" title="13"><span class="im">from</span> sklearn.metrics <span class="im">import</span> accuracy_score, f1_score, precision_score, recall_score</a>
<a class="sourceLine" id="cb2-14" title="14"><span class="im">import</span> string</a>
<a class="sourceLine" id="cb2-15" title="15"><span class="im">from</span> collections <span class="im">import</span> Counter</a>
<a class="sourceLine" id="cb2-16" title="16"><span class="im">from</span> transformers <span class="im">import</span> get_linear_schedule_with_warmup</a>
<a class="sourceLine" id="cb2-17" title="17"><span class="im">from</span> itertools <span class="im">import</span> repeat</a>
<a class="sourceLine" id="cb2-18" title="18"><span class="im">import</span> optuna</a>
<a class="sourceLine" id="cb2-19" title="19"><span class="im">from</span> optuna.pruners <span class="im">import</span> SuccessiveHalvingPruner</a>
<a class="sourceLine" id="cb2-20" title="20"><span class="im">from</span> optuna.samplers <span class="im">import</span> TPESampler</a>
<a class="sourceLine" id="cb2-21" title="21"><span class="im">import</span> matplotlib.pyplot <span class="im">as</span> plt</a>
<a class="sourceLine" id="cb2-22" title="22"><span class="im">import</span> seaborn <span class="im">as</span> sns</a>
<a class="sourceLine" id="cb2-23" title="23"><span class="im">import</span> re</a>
<a class="sourceLine" id="cb2-24" title="24"><span class="im">import</span> random</a>
<a class="sourceLine" id="cb2-25" title="25"></a>
<a class="sourceLine" id="cb2-26" title="26">SEED <span class="op">=</span> <span class="dv">15</span></a>
<a class="sourceLine" id="cb2-27" title="27">random.seed(SEED)</a>
<a class="sourceLine" id="cb2-28" title="28">np.random.seed(SEED)</a>
<a class="sourceLine" id="cb2-29" title="29">torch.manual_seed(SEED)</a></code></pre></div>
<pre><code>## &lt;torch._C.Generator object at 0x000000001F76E050&gt;</code></pre>
<div class="sourceCode" id="cb4"><pre class="sourceCode python"><code class="sourceCode python"><a class="sourceLine" id="cb4-1" title="1">torch.backends.cudnn.deterministic <span class="op">=</span> <span class="va">True</span></a>
<a class="sourceLine" id="cb4-2" title="2"></a>
<a class="sourceLine" id="cb4-3" title="3"><span class="co"># tell pytorch to use cuda</span></a>
<a class="sourceLine" id="cb4-4" title="4">device <span class="op">=</span> torch.device(<span class="st">&quot;cuda&quot;</span>)</a></code></pre></div>
<div id="introduction" class="section level1">
<h1><span class="header-section-number">1</span> Introduction</h1>
<p>Text or sequence classification aims to label a sentence or document based on its content. In this post, we use Convolutional Neural Networks to classify a novel data set that I created based on insurgent propaganda messages. This guide stands in contrast to other walk-throughs on the model in that it: (1) offers a full treatment of data preparation and PyTorch, (2) uses GloVe embeddings correctly by taking into account unknown or padding tokens by generating unique vectors for them, and (3) specifically tells the <code>embedding</code> layer which look-up index is the padding token.</p>
</div>
<div id="convolutional-neural-networks" class="section level1">
<h1><span class="header-section-number">2</span> Convolutional Neural Networks</h1>
<p>In this section, we run a CNN with GloVe embeddings after addressing some of the high points about CNNs. Convolutional layers aim to find spatial patterns, predominantly in images, through the use of <em>kernels</em>. Kernels can be thought of as small windows that slide across the pixels of an image - calculating the respective weight by multiplying the pixel values with the kernel weight. These values are then summed to get a filtered pixel value which in turn are representative of local features.</p>
<p>In Natural Language Processing, text is one-dimensional but we often represent each word (or character) with an embedding vector, thereby giving our text a two-dimensional representation. The convolutional kernel slides over the embeddings (features) of multiple words rather than pixels. Instead of three input channels like Red Green Blue for images, text processing has just 1 (akin to gray scale) because a single sentence/document will be associated with a single list of embeddings. To slide a kernel over sequences of word embeddings, the sliding window needs to be allowed to look at multiple word embeddings in a sequence. Instead of a square, kernels take on shapes associated with the number of words (<span class="math inline">\(n\)</span>) to look at in a sequence and the length of the embedding sequence (<span class="math inline">\(m\)</span>). This <span class="math inline">\(n\times m\)</span> kernel tells us how many word embeddings it will view at once, like n-grams, while also the length of the word embedding that it will take it account, say 200 or 300 for GLoVe or 768 for BERT.</p>
<p>CNNs tend to include multiple kernel heights, typically 3, each representing a different n-gram range. As a CNN trains, kernel weights are learned for words and surrounding words in a sequential window, yielding local features. CNNs then use max-pooling which aims to retain only the most important (highest value) local feature while discarding less important features.</p>
</div>
<div id="cnns-using-glove-embeddings" class="section level1">
<h1><span class="header-section-number">3</span> CNNs using GloVe Embeddings</h1>
<p>GloVe is a common set of embeddings used by practitioners and academics in text analysis containing features for 400,000 words. Embeddings capture the similarities between words (e.g., they have high cosine similarities) and are the basis of NLP. Word embedding methods represent words as continuous vectors in a low dimensional space which capture lexical and semantic properties of words. Embeddings can be obtained from the internal representations from neural network models of text or by low rank approximation of co-occurrence statistics.</p>
<p>In this section, I will describe how to set up, correctly, a CNN in PyTorch that relies on GloVe. I begin by loading and preparing my data, sub-setting it to yield only two classes.</p>
<div class="sourceCode" id="cb5"><pre class="sourceCode python"><code class="sourceCode python"><a class="sourceLine" id="cb5-1" title="1"><span class="co"># prepare and load data</span></a>
<a class="sourceLine" id="cb5-2" title="2"><span class="kw">def</span> prepare_df(pkl_location):</a>
<a class="sourceLine" id="cb5-3" title="3">    <span class="co"># read pkl as pandas</span></a>
<a class="sourceLine" id="cb5-4" title="4">    df <span class="op">=</span> pd.read_pickle(pkl_location)</a>
<a class="sourceLine" id="cb5-5" title="5">    <span class="co"># just keep us/kabul labels</span></a>
<a class="sourceLine" id="cb5-6" title="6">    df <span class="op">=</span> df.loc[(df[<span class="st">&#39;target&#39;</span>] <span class="op">==</span> <span class="st">&#39;US&#39;</span>) <span class="op">|</span> (df[<span class="st">&#39;target&#39;</span>] <span class="op">==</span> <span class="st">&#39;Kabul&#39;</span>)]</a>
<a class="sourceLine" id="cb5-7" title="7">    <span class="co"># mask DV to recode</span></a>
<a class="sourceLine" id="cb5-8" title="8">    us <span class="op">=</span> df[<span class="st">&#39;target&#39;</span>] <span class="op">==</span> <span class="st">&#39;US&#39;</span></a>
<a class="sourceLine" id="cb5-9" title="9">    kabul <span class="op">=</span> df[<span class="st">&#39;target&#39;</span>] <span class="op">==</span> <span class="st">&#39;Kabul&#39;</span></a>
<a class="sourceLine" id="cb5-10" title="10">    <span class="co"># apply mask</span></a>
<a class="sourceLine" id="cb5-11" title="11">    df.loc[us, <span class="st">&#39;target&#39;</span>] <span class="op">=</span> <span class="dv">1</span></a>
<a class="sourceLine" id="cb5-12" title="12">    df.loc[kabul, <span class="st">&#39;target&#39;</span>] <span class="op">=</span> <span class="dv">0</span></a>
<a class="sourceLine" id="cb5-13" title="13">    <span class="co"># reset index</span></a>
<a class="sourceLine" id="cb5-14" title="14">    df <span class="op">=</span> df.reset_index(drop<span class="op">=</span><span class="va">True</span>)</a>
<a class="sourceLine" id="cb5-15" title="15">    <span class="cf">return</span> df</a>
<a class="sourceLine" id="cb5-16" title="16"></a>
<a class="sourceLine" id="cb5-17" title="17"></a>
<a class="sourceLine" id="cb5-18" title="18">df <span class="op">=</span> prepare_df(<span class="st">&#39;C:</span><span class="ch">\\</span><span class="st">Users</span><span class="ch">\\</span><span class="st">Andrew</span><span class="ch">\\</span><span class="st">Desktop</span><span class="ch">\\</span><span class="st">df.pkl&#39;</span>)</a></code></pre></div>
<p>Next, I do a small amount of additional data cleaning to my text, as described below.</p>
<div class="sourceCode" id="cb6"><pre class="sourceCode python"><code class="sourceCode python"><a class="sourceLine" id="cb6-1" title="1"><span class="co"># prepare data</span></a>
<a class="sourceLine" id="cb6-2" title="2"><span class="kw">def</span> clean_df(df):</a>
<a class="sourceLine" id="cb6-3" title="3">    <span class="co"># strip dash but keep a space</span></a>
<a class="sourceLine" id="cb6-4" title="4">    df[<span class="st">&#39;body&#39;</span>] <span class="op">=</span> df[<span class="st">&#39;body&#39;</span>].<span class="bu">str</span>.replace(<span class="st">&#39;-&#39;</span>, <span class="st">&#39; &#39;</span>)</a>
<a class="sourceLine" id="cb6-5" title="5">    <span class="co"># prepare keys for punctuation removal</span></a>
<a class="sourceLine" id="cb6-6" title="6">    translator <span class="op">=</span> <span class="bu">str</span>.maketrans(<span class="bu">dict</span>.fromkeys(string.punctuation))</a>
<a class="sourceLine" id="cb6-7" title="7">    <span class="co"># lower case the data</span></a>
<a class="sourceLine" id="cb6-8" title="8">    df[<span class="st">&#39;body&#39;</span>] <span class="op">=</span> df[<span class="st">&#39;body&#39;</span>].<span class="bu">apply</span>(<span class="kw">lambda</span> x: x.lower())</a>
<a class="sourceLine" id="cb6-9" title="9">    <span class="co"># remove excess spaces near punctuation</span></a>
<a class="sourceLine" id="cb6-10" title="10">    df[<span class="st">&#39;body&#39;</span>] <span class="op">=</span> df[<span class="st">&#39;body&#39;</span>].<span class="bu">apply</span>(<span class="kw">lambda</span> x: re.sub(<span class="vs">r&#39;\s([?.!&quot;](?:\s|$))&#39;</span>, <span class="vs">r&#39;\1&#39;</span>, x))</a>
<a class="sourceLine" id="cb6-11" title="11">    <span class="co"># remove punctuation  -- f1 improves by .05 by disabling this</span></a>
<a class="sourceLine" id="cb6-12" title="12">    df[<span class="st">&#39;body&#39;</span>] <span class="op">=</span> df[<span class="st">&#39;body&#39;</span>].<span class="bu">apply</span>(<span class="kw">lambda</span> x: x.translate(translator))</a>
<a class="sourceLine" id="cb6-13" title="13">    <span class="co"># generate a word count</span></a>
<a class="sourceLine" id="cb6-14" title="14">    df[<span class="st">&#39;word_count&#39;</span>] <span class="op">=</span> df[<span class="st">&#39;body&#39;</span>].<span class="bu">apply</span>(<span class="kw">lambda</span> x: <span class="bu">len</span>(x.split()))</a>
<a class="sourceLine" id="cb6-15" title="15">    <span class="co"># remove excess white spaces</span></a>
<a class="sourceLine" id="cb6-16" title="16">    df[<span class="st">&#39;body&#39;</span>] <span class="op">=</span> df[<span class="st">&#39;body&#39;</span>].<span class="bu">apply</span>(<span class="kw">lambda</span> x: <span class="st">&quot; &quot;</span>.join(x.split()))</a>
<a class="sourceLine" id="cb6-17" title="17"></a>
<a class="sourceLine" id="cb6-18" title="18">    <span class="cf">return</span> df</a>
<a class="sourceLine" id="cb6-19" title="19">    </a>
<a class="sourceLine" id="cb6-20" title="20">df <span class="op">=</span> clean_df(df)</a></code></pre></div>
<p>Since my corpus includes transliterations of Afghan words, there are a sizable amount of words that are not in the GloVe embedding and are otherwise probably not very helpful to helping us understand important local features through the lens of a CNN even if we were to give them coefficients for an unknown word. As such, I remove rare words from my corpus by:</p>
<ol style="list-style-type: decimal">
<li>collecting counts of each word in a key:value pair dictionary</li>
<li>removing keys from the dictionary if used less than twice</li>
<li>using <code>filter</code> to drop the rare words from the list</li>
</ol>
<div class="sourceCode" id="cb7"><pre class="sourceCode python"><code class="sourceCode python"><a class="sourceLine" id="cb7-1" title="1"><span class="co"># lets remove rare words</span></a>
<a class="sourceLine" id="cb7-2" title="2"><span class="kw">def</span> remove_rare_words(df):</a>
<a class="sourceLine" id="cb7-3" title="3">    <span class="co"># get counts of each word -- necessary for vocab</span></a>
<a class="sourceLine" id="cb7-4" title="4">    counts <span class="op">=</span> Counter(<span class="st">&quot; &quot;</span>.join(df[<span class="st">&#39;body&#39;</span>].values.tolist()).split(<span class="st">&quot; &quot;</span>))</a>
<a class="sourceLine" id="cb7-5" title="5">    <span class="co"># remove low counts -- keep those above 2</span></a>
<a class="sourceLine" id="cb7-6" title="6">    counts <span class="op">=</span> {key: value <span class="cf">for</span> key, value <span class="kw">in</span> counts.items() <span class="cf">if</span> value <span class="op">&gt;</span> <span class="dv">2</span>}</a>
<a class="sourceLine" id="cb7-7" title="7"></a>
<a class="sourceLine" id="cb7-8" title="8">    <span class="co"># remove rare words from corpus</span></a>
<a class="sourceLine" id="cb7-9" title="9">    <span class="kw">def</span> remove_rare(x):</a>
<a class="sourceLine" id="cb7-10" title="10">        <span class="cf">return</span> <span class="st">&#39; &#39;</span>.join(<span class="bu">list</span>(<span class="bu">filter</span>(<span class="kw">lambda</span> x: x <span class="kw">in</span> counts.keys(), x.split())))</a>
<a class="sourceLine" id="cb7-11" title="11"></a>
<a class="sourceLine" id="cb7-12" title="12">    <span class="co"># apply funx</span></a>
<a class="sourceLine" id="cb7-13" title="13">    df[<span class="st">&#39;body&#39;</span>] <span class="op">=</span> df[<span class="st">&#39;body&#39;</span>].<span class="bu">apply</span>(remove_rare)</a>
<a class="sourceLine" id="cb7-14" title="14">    <span class="cf">return</span> df</a>
<a class="sourceLine" id="cb7-15" title="15"></a>
<a class="sourceLine" id="cb7-16" title="16"></a>
<a class="sourceLine" id="cb7-17" title="17">df <span class="op">=</span> remove_rare_words(df)</a></code></pre></div>
<p>Next, I execute a few functions to clean up the data set further and to learn a bit more about my corpus in its entirety.</p>
<div class="sourceCode" id="cb8"><pre class="sourceCode python"><code class="sourceCode python"><a class="sourceLine" id="cb8-1" title="1"><span class="co"># find min/max word count</span></a>
<a class="sourceLine" id="cb8-2" title="2"><span class="bu">max</span>(df[<span class="st">&#39;word_count&#39;</span>])</a></code></pre></div>
<pre><code>## 5472</code></pre>
<div class="sourceCode" id="cb10"><pre class="sourceCode python"><code class="sourceCode python"><a class="sourceLine" id="cb10-1" title="1"><span class="bu">min</span>(df[<span class="st">&#39;word_count&#39;</span>])</a>
<a class="sourceLine" id="cb10-2" title="2"></a>
<a class="sourceLine" id="cb10-3" title="3"><span class="co"># trim the corpus of really small messages</span></a></code></pre></div>
<pre><code>## 0</code></pre>
<div class="sourceCode" id="cb12"><pre class="sourceCode python"><code class="sourceCode python"><a class="sourceLine" id="cb12-1" title="1">df <span class="op">=</span> df.loc[df[<span class="st">&#39;word_count&#39;</span>] <span class="op">&gt;</span> <span class="dv">20</span>]</a>
<a class="sourceLine" id="cb12-2" title="2"></a>
<a class="sourceLine" id="cb12-3" title="3"><span class="co"># what is 95th percentile of word count?</span></a>
<a class="sourceLine" id="cb12-4" title="4">percentile_95 <span class="op">=</span> <span class="bu">int</span>(df[<span class="st">&#39;word_count&#39;</span>].quantile(<span class="fl">0.95</span>))</a>
<a class="sourceLine" id="cb12-5" title="5"><span class="bu">print</span>(percentile_95)</a>
<a class="sourceLine" id="cb12-6" title="6"></a>
<a class="sourceLine" id="cb12-7" title="7"><span class="co"># whats the length of the vocab?</span></a></code></pre></div>
<pre><code>## 974</code></pre>
<div class="sourceCode" id="cb14"><pre class="sourceCode python"><code class="sourceCode python"><a class="sourceLine" id="cb14-1" title="1">counts <span class="op">=</span> Counter(<span class="st">&quot; &quot;</span>.join(df[<span class="st">&#39;body&#39;</span>].values.tolist()).split(<span class="st">&quot; &quot;</span>))</a>
<a class="sourceLine" id="cb14-2" title="2">vocab <span class="op">=</span> <span class="bu">sorted</span>(counts, key<span class="op">=</span>counts.get, reverse<span class="op">=</span><span class="va">True</span>)</a>
<a class="sourceLine" id="cb14-3" title="3"><span class="bu">print</span>(<span class="bu">len</span>(vocab))</a></code></pre></div>
<pre><code>## 16354</code></pre>
<p>Now I am ready to load my GloVe embeddings.</p>
<div class="sourceCode" id="cb16"><pre class="sourceCode python"><code class="sourceCode python"><a class="sourceLine" id="cb16-1" title="1"><span class="co"># load GloVe embeddings</span></a>
<a class="sourceLine" id="cb16-2" title="2"><span class="kw">def</span> load_GloVe(file_path):</a>
<a class="sourceLine" id="cb16-3" title="3">    <span class="co"># create empty dict to store data</span></a>
<a class="sourceLine" id="cb16-4" title="4">    embeddings_dictionary <span class="op">=</span> <span class="bu">dict</span>()</a>
<a class="sourceLine" id="cb16-5" title="5">    <span class="co"># load the file</span></a>
<a class="sourceLine" id="cb16-6" title="6">    glove_file <span class="op">=</span> <span class="bu">open</span>(file_path, encoding<span class="op">=</span><span class="st">&quot;utf8&quot;</span>)</a>
<a class="sourceLine" id="cb16-7" title="7">    <span class="co"># for each entry</span></a>
<a class="sourceLine" id="cb16-8" title="8">    <span class="cf">for</span> line <span class="kw">in</span> glove_file:</a>
<a class="sourceLine" id="cb16-9" title="9">        <span class="co"># split on spaces</span></a>
<a class="sourceLine" id="cb16-10" title="10">        records <span class="op">=</span> line.split()</a>
<a class="sourceLine" id="cb16-11" title="11">        <span class="co"># get the word located in position 0</span></a>
<a class="sourceLine" id="cb16-12" title="12">        word <span class="op">=</span> records[<span class="dv">0</span>]</a>
<a class="sourceLine" id="cb16-13" title="13">        <span class="co"># get the embeddings which is the remainder</span></a>
<a class="sourceLine" id="cb16-14" title="14">        vector_dimensions <span class="op">=</span> np.asarray(records[<span class="dv">1</span>:], dtype<span class="op">=</span><span class="st">&#39;float32&#39;</span>)</a>
<a class="sourceLine" id="cb16-15" title="15">        <span class="co"># add to dictionary</span></a>
<a class="sourceLine" id="cb16-16" title="16">        embeddings_dictionary[word] <span class="op">=</span> vector_dimensions</a>
<a class="sourceLine" id="cb16-17" title="17">    <span class="co"># close the file</span></a>
<a class="sourceLine" id="cb16-18" title="18">    glove_file.close()</a>
<a class="sourceLine" id="cb16-19" title="19">    <span class="cf">return</span> embeddings_dictionary</a>
<a class="sourceLine" id="cb16-20" title="20"></a>
<a class="sourceLine" id="cb16-21" title="21"></a>
<a class="sourceLine" id="cb16-22" title="22"><span class="co"># load GloVe</span></a>
<a class="sourceLine" id="cb16-23" title="23">file_path <span class="op">=</span> <span class="st">&#39;C:</span><span class="ch">\\</span><span class="st">Users</span><span class="ch">\\</span><span class="st">Andrew</span><span class="ch">\\</span><span class="st">Desktop</span><span class="ch">\\</span><span class="st">glove.6B.200d.txt&#39;</span></a>
<a class="sourceLine" id="cb16-24" title="24">embeddings_dictionary <span class="op">=</span> load_GloVe(file_path)</a>
<a class="sourceLine" id="cb16-25" title="25"></a>
<a class="sourceLine" id="cb16-26" title="26"><span class="co"># useful computing to check vector values and indices</span></a>
<a class="sourceLine" id="cb16-27" title="27">embeddings_dictionary.get(<span class="st">&#39;.&#39;</span>)  <span class="co"># get key value</span></a></code></pre></div>
<pre><code>## array([ 1.2289e-01,  5.8037e-01, -6.9635e-02, -5.0288e-01,  1.0503e-01,
##         3.9945e-01, -3.8635e-01, -8.4279e-02,  1.2219e-01,  8.0312e-02,
##         3.2337e-01,  4.7579e-01, -3.8375e-02, -7.0900e-03,  4.1524e-01,
##         3.2121e-01, -2.1185e-01,  3.6144e-01, -5.5623e-02, -3.0512e-02,
##         4.2854e-01,  2.8547e+00, -1.4623e-01, -1.7557e-01,  3.1197e-01,
##        -1.3118e-01,  3.3298e-02,  1.3093e-01,  8.9889e-02, -1.2417e-01,
##         2.3396e-03, -6.8954e-02, -1.0754e-01, -1.1551e-01, -3.1052e-01,
##        -1.2097e-01, -4.6691e-01, -8.3600e-02, -3.7664e-02, -7.1779e-02,
##        -1.1899e-01, -2.0381e-01, -1.2424e-01,  4.6339e-01, -1.9828e-01,
##        -8.0365e-03,  5.3718e-01,  3.1739e-02,  3.4331e-01,  7.9704e-03,
##         4.8744e-03,  3.0592e-02, -1.7615e-01,  8.2342e-01, -1.3793e-01,
##        -1.0075e-01, -1.2686e-01,  7.4735e-02, -8.8719e-02, -4.2719e-02,
##         7.6624e-02,  8.9263e-02,  6.4445e-02, -3.1958e-02,  1.5254e-01,
##        -1.0384e-01,  7.6604e-02,  3.4099e-01,  2.4331e-01, -1.0452e-01,
##         4.0714e-01, -1.8260e-01, -4.0667e-02,  5.0878e-01,  8.0760e-02,
##         2.2759e-01, -4.2162e-02, -1.8171e-01, -9.5025e-02,  3.0334e-02,
##         8.8202e-02, -3.9843e-06, -3.9877e-03,  1.5724e-01,  3.3167e-01,
##         8.4710e-02, -2.5919e-01, -4.1384e-01,  2.9920e-01, -5.4255e-01,
##         3.2129e-02,  1.0030e-01,  4.4202e-01,  4.4682e-02, -9.0681e-02,
##        -1.0481e-01, -1.1860e-01, -3.1972e-01, -2.0790e-01, -4.0203e-02,
##        -2.2988e-02,  2.2824e-01,  5.5238e-03,  1.2568e-01, -1.4640e-01,
##        -1.4904e-01, -1.1561e-01,  1.0517e+00, -1.9498e-01,  8.3958e-02,
##         4.4812e-02, -1.2965e-01, -9.3468e-02,  2.1237e-01, -8.8332e-02,
##        -1.8680e-01,  2.6521e-01,  1.3097e-01, -4.8102e-02, -2.2467e-01,
##         2.8412e-01,  3.4907e-01,  3.4833e-01,  1.7877e-02,  3.0504e-01,
##        -8.3453e-01,  4.8856e-02, -1.9330e-01,  2.0764e-01, -4.9701e-01,
##        -1.8747e-01, -7.6801e-02,  1.5558e-01, -4.6844e-01,  4.0944e-01,
##         2.1386e-01,  8.2392e-02, -2.6491e-01, -2.1224e-01, -1.3293e-01,
##         1.4738e-01, -1.4192e-01,  1.8994e-01, -1.5587e-01,  1.0738e+00,
##         4.0789e-01, -2.7452e-01, -1.8431e-01,  6.8679e-04, -8.7115e-02,
##         1.9672e-01,  4.0918e-01, -3.5462e-01, -6.3260e-02,  4.4920e-01,
##        -6.0568e-02, -4.1636e-02,  2.0531e-01,  1.7025e-02, -5.8448e-01,
##         7.5441e-02,  8.2116e-02, -4.6008e-01,  1.2393e-02, -2.5310e-02,
##         1.4177e-01, -9.2192e-02,  3.4505e-01, -5.2136e-01,  5.7304e-01,
##         1.1973e-02,  3.3196e-02,  2.9672e-01, -2.7899e-01,  1.9979e-01,
##         2.5666e-01,  8.2079e-02, -7.8436e-02,  9.3719e-02,  2.4202e-01,
##         1.3495e+00, -3.0434e-01, -3.0936e-01,  4.2047e-01, -7.9068e-02,
##        -1.4819e-01, -8.9404e-02,  6.6800e-02,  2.2405e-01,  2.7226e-01,
##        -3.5236e-02,  1.7688e-01, -5.3600e-02,  7.0031e-03, -3.3006e-02,
##        -8.0021e-02, -2.4451e-01, -3.9174e-02, -1.6236e-01, -9.6652e-02],
##       dtype=float32)</code></pre>
<div class="sourceCode" id="cb18"><pre class="sourceCode python"><code class="sourceCode python"><a class="sourceLine" id="cb18-1" title="1"><span class="bu">list</span>(embeddings_dictionary.keys()).index(<span class="st">&#39;.&#39;</span>)  <span class="co"># get key index</span></a></code></pre></div>
<pre><code>## 2</code></pre>
<p>One issue I see with many guides that use GloVe is that they do not do anything to account for padding tokens nor for unknown words. The function remedies that in several ways:</p>
<ol style="list-style-type: decimal">
<li>It creates one nearly empty vector for the <em>padding</em> tokens.</li>
<li>It creates a randomly initialized vector between <span class="math inline">\([-0.14, 0.14]\)</span> (mimicking the variance of 200d GLoVe) to account for <em>unknown</em> tokens.</li>
<li>It extends the GloVe dimensions from 200 to 201 to account for this variation.</li>
</ol>
<div class="sourceCode" id="cb20"><pre class="sourceCode python"><code class="sourceCode python"><a class="sourceLine" id="cb20-1" title="1"><span class="co"># create vectors for &quot;unknown&quot; and &quot;padding&quot; and add to GloVe</span></a>
<a class="sourceLine" id="cb20-2" title="2"><span class="kw">def</span> modify_GloVe(embeddings_dictionary):</a>
<a class="sourceLine" id="cb20-3" title="3">    <span class="co"># create key values for unknown</span></a>
<a class="sourceLine" id="cb20-4" title="4">    unknown_vector <span class="op">=</span> np.random.uniform(<span class="op">-</span><span class="fl">0.14</span>, <span class="fl">0.14</span>, <span class="dv">201</span>)  <span class="co"># var of GloVe 200d</span></a>
<a class="sourceLine" id="cb20-5" title="5">    <span class="co"># create key values for padding</span></a>
<a class="sourceLine" id="cb20-6" title="6">    pad_vector <span class="op">=</span> np.repeat(<span class="dv">0</span>, <span class="dv">200</span>)</a>
<a class="sourceLine" id="cb20-7" title="7">    pad_vector <span class="op">=</span> np.append(pad_vector, <span class="dv">1</span>)</a>
<a class="sourceLine" id="cb20-8" title="8">    <span class="co"># turn dict into list to append easily</span></a>
<a class="sourceLine" id="cb20-9" title="9">    embeddings_tensor <span class="op">=</span> <span class="bu">list</span>(embeddings_dictionary.values())</a>
<a class="sourceLine" id="cb20-10" title="10">    <span class="co"># extend GloVe dimension by 2</span></a>
<a class="sourceLine" id="cb20-11" title="11">    embeddings_tensor <span class="op">=</span> [np.append(i, <span class="dv">0</span>) <span class="cf">for</span> i <span class="kw">in</span> embeddings_tensor]</a>
<a class="sourceLine" id="cb20-12" title="12">    <span class="co"># add unknown and pad vectors via vstack</span></a>
<a class="sourceLine" id="cb20-13" title="13">    embeddings_tensor <span class="op">=</span> np.vstack([embeddings_tensor, unknown_vector])</a>
<a class="sourceLine" id="cb20-14" title="14">    embeddings_tensor <span class="op">=</span> np.vstack([embeddings_tensor, pad_vector])</a>
<a class="sourceLine" id="cb20-15" title="15">    <span class="co"># finalize transform into tensor</span></a>
<a class="sourceLine" id="cb20-16" title="16">    embeddings_tensor <span class="op">=</span> torch.Tensor(embeddings_tensor)</a>
<a class="sourceLine" id="cb20-17" title="17">    <span class="cf">return</span> embeddings_tensor</a>
<a class="sourceLine" id="cb20-18" title="18">    </a>
<a class="sourceLine" id="cb20-19" title="19"><span class="co"># modify GloVe and turn into torch tensor</span></a>
<a class="sourceLine" id="cb20-20" title="20">embeddings_tensor <span class="op">=</span> modify_GloVe(embeddings_dictionary)</a>
<a class="sourceLine" id="cb20-21" title="21"><span class="co"># check shape</span></a>
<a class="sourceLine" id="cb20-22" title="22"><span class="bu">print</span>(embeddings_tensor.shape)</a></code></pre></div>
<pre><code>## torch.Size([400002, 201])</code></pre>
<p>With GloVe loaded, we need to tokenize our corpus into GloVe tokens. This is because when we feed our tokens into the model, it uses an <code>embedding</code> layer that acts as a look-up table. We will eventually specify that this look-up table be the object we just created, <code>embeddings_tensor</code>, so that when a token is fed into our model, the <code>embedding</code> layer will “look-up” the 200 dimension feature for that word inside the <code>embeddings_tensor</code> object and append the features to our batch undergoing forward propagation.</p>
<div class="sourceCode" id="cb22"><pre class="sourceCode python"><code class="sourceCode python"><a class="sourceLine" id="cb22-1" title="1"><span class="co"># convert strings to GloVe familiar tokens</span></a>
<a class="sourceLine" id="cb22-2" title="2"><span class="kw">def</span> text_to_GloVe_tokens(df, embeddings_dictionary):</a>
<a class="sourceLine" id="cb22-3" title="3">    <span class="co"># create container for words that do not match</span></a>
<a class="sourceLine" id="cb22-4" title="4">    no_matches <span class="op">=</span> []</a>
<a class="sourceLine" id="cb22-5" title="5">    <span class="co"># create container for tokenized strings</span></a>
<a class="sourceLine" id="cb22-6" title="6">    glove_tokenized_data <span class="op">=</span> []</a>
<a class="sourceLine" id="cb22-7" title="7">    <span class="co"># create lookup for token ids</span></a>
<a class="sourceLine" id="cb22-8" title="8">    word_map <span class="op">=</span> <span class="bu">dict</span>(<span class="bu">zip</span>(embeddings_dictionary.keys(), <span class="bu">range</span>(<span class="bu">len</span>(embeddings_dictionary))))</a>
<a class="sourceLine" id="cb22-9" title="9">    <span class="co"># for each document</span></a>
<a class="sourceLine" id="cb22-10" title="10">    <span class="cf">for</span> doc <span class="kw">in</span> df[<span class="st">&#39;body&#39;</span>]:</a>
<a class="sourceLine" id="cb22-11" title="11">        <span class="co"># split each string</span></a>
<a class="sourceLine" id="cb22-12" title="12">        doc <span class="op">=</span> doc.split()</a>
<a class="sourceLine" id="cb22-13" title="13">        <span class="co"># create token container</span></a>
<a class="sourceLine" id="cb22-14" title="14">        tokens <span class="op">=</span> []</a>
<a class="sourceLine" id="cb22-15" title="15">        <span class="co"># for each word in the document</span></a>
<a class="sourceLine" id="cb22-16" title="16">        <span class="cf">for</span> word <span class="kw">in</span> doc:</a>
<a class="sourceLine" id="cb22-17" title="17">            <span class="co"># if word is a GloVE word</span></a>
<a class="sourceLine" id="cb22-18" title="18">            <span class="cf">if</span> word <span class="kw">in</span> word_map:</a>
<a class="sourceLine" id="cb22-19" title="19">                <span class="co"># get its GloVe index</span></a>
<a class="sourceLine" id="cb22-20" title="20">                idx <span class="op">=</span> word_map.get(word)</a>
<a class="sourceLine" id="cb22-21" title="21">                <span class="co"># save its token</span></a>
<a class="sourceLine" id="cb22-22" title="22">                tokens.append(idx)</a>
<a class="sourceLine" id="cb22-23" title="23">            <span class="co"># otherwise</span></a>
<a class="sourceLine" id="cb22-24" title="24">            <span class="cf">else</span>:</a>
<a class="sourceLine" id="cb22-25" title="25">                <span class="co"># it must be an unknown word to GloVe</span></a>
<a class="sourceLine" id="cb22-26" title="26">                idx <span class="op">=</span> <span class="dv">400000</span>  <span class="co"># unknown word</span></a>
<a class="sourceLine" id="cb22-27" title="27">                <span class="co"># so append that word to no matches</span></a>
<a class="sourceLine" id="cb22-28" title="28">                no_matches.append(word)</a>
<a class="sourceLine" id="cb22-29" title="29">                <span class="co"># but also give it a vector lookup</span></a>
<a class="sourceLine" id="cb22-30" title="30">                tokens.append(idx)</a>
<a class="sourceLine" id="cb22-31" title="31">        <span class="co"># combine the tokens</span></a>
<a class="sourceLine" id="cb22-32" title="32">        glove_tokenized_data.append(tokens)</a>
<a class="sourceLine" id="cb22-33" title="33">    <span class="cf">return</span> no_matches, glove_tokenized_data</a></code></pre></div>
<p>With our corpus tokenized to match GloVe, it is in our interest to know just how many words in our corpus have no embedding features. The code below determines that for us.</p>
<div class="sourceCode" id="cb23"><pre class="sourceCode python"><code class="sourceCode python"><a class="sourceLine" id="cb23-1" title="1"><span class="co"># get a list of no matches and our GloVe tokens</span></a>
<a class="sourceLine" id="cb23-2" title="2">no_matches, glove_tokenized_data <span class="op">=</span> text_to_GloVe_tokens(df, embeddings_dictionary)</a>
<a class="sourceLine" id="cb23-3" title="3"></a>
<a class="sourceLine" id="cb23-4" title="4"><span class="co"># after removing rare words, how many words are we not accounting for now?</span></a>
<a class="sourceLine" id="cb23-5" title="5"><span class="bu">print</span>(<span class="bu">len</span>(<span class="bu">set</span>(no_matches)))</a></code></pre></div>
<pre><code>## 1495</code></pre>
<p>Our next challenge is managing the lengths of our messages as they all need to be equal. The function below receives the GloVe tokenized data and a specified max length. It then proceeds to check the size of each item in the corpus and then either truncates or adds our new specialized padding token to the end of the message.</p>
<p><code>max_len</code> is a hyperparameter that we can experiment with, however, I have chosen the 95th percentile of my corpus’ <code>word_count</code> as my desired max length.</p>
<div class="sourceCode" id="cb25"><pre class="sourceCode python"><code class="sourceCode python"><a class="sourceLine" id="cb25-1" title="1"><span class="co"># post pad GloVe</span></a>
<a class="sourceLine" id="cb25-2" title="2"><span class="kw">def</span> pad_GloVe(tokenized_data, max_len):</a>
<a class="sourceLine" id="cb25-3" title="3">    padded_tokens <span class="op">=</span> []</a>
<a class="sourceLine" id="cb25-4" title="4">    max_len <span class="op">=</span> max_len</a>
<a class="sourceLine" id="cb25-5" title="5">    <span class="co"># for each tokenized document</span></a>
<a class="sourceLine" id="cb25-6" title="6">    <span class="cf">for</span> tokenized_sent <span class="kw">in</span> tokenized_data:</a>
<a class="sourceLine" id="cb25-7" title="7">        <span class="co"># if current doc length is greater than max length</span></a>
<a class="sourceLine" id="cb25-8" title="8">        <span class="cf">if</span> <span class="bu">len</span>(tokenized_sent) <span class="op">&gt;</span> max_len:</a>
<a class="sourceLine" id="cb25-9" title="9">            <span class="co"># trim it to max length</span></a>
<a class="sourceLine" id="cb25-10" title="10">            current_sent <span class="op">=</span> tokenized_sent[:max_len]</a>
<a class="sourceLine" id="cb25-11" title="11">            <span class="co"># append</span></a>
<a class="sourceLine" id="cb25-12" title="12">            padded_tokens.append(current_sent)</a>
<a class="sourceLine" id="cb25-13" title="13"></a>
<a class="sourceLine" id="cb25-14" title="14">        <span class="co"># if current doc length is less than max length</span></a>
<a class="sourceLine" id="cb25-15" title="15">        <span class="cf">if</span> <span class="bu">len</span>(tokenized_sent) <span class="op">&lt;</span> max_len:</a>
<a class="sourceLine" id="cb25-16" title="16">            <span class="co"># find the difference in length</span></a>
<a class="sourceLine" id="cb25-17" title="17">            extension <span class="op">=</span> max_len <span class="op">-</span> <span class="bu">len</span>(tokenized_sent)</a>
<a class="sourceLine" id="cb25-18" title="18">            <span class="co"># pad sentences to max_len</span></a>
<a class="sourceLine" id="cb25-19" title="19">            tokenized_sent.extend(repeat(<span class="dv">400001</span>, extension))</a>
<a class="sourceLine" id="cb25-20" title="20">            <span class="co"># append new padded token</span></a>
<a class="sourceLine" id="cb25-21" title="21">            padded_tokens.append(tokenized_sent)</a>
<a class="sourceLine" id="cb25-22" title="22"></a>
<a class="sourceLine" id="cb25-23" title="23">        <span class="cf">elif</span> <span class="bu">len</span>(tokenized_sent) <span class="op">==</span> max_len:</a>
<a class="sourceLine" id="cb25-24" title="24">            padded_tokens.append(tokenized_sent)</a>
<a class="sourceLine" id="cb25-25" title="25"></a>
<a class="sourceLine" id="cb25-26" title="26">    <span class="cf">return</span> np.array(padded_tokens, dtype<span class="op">=</span>np.int64)</a>
<a class="sourceLine" id="cb25-27" title="27"></a>
<a class="sourceLine" id="cb25-28" title="28"><span class="co"># get new padded tokens</span></a>
<a class="sourceLine" id="cb25-29" title="29">padded_GloVe <span class="op">=</span> pad_GloVe(glove_tokenized_data, percentile_95)</a>
<a class="sourceLine" id="cb25-30" title="30"><span class="co"># check shape; 9994 documents, 974 length</span></a>
<a class="sourceLine" id="cb25-31" title="31"><span class="bu">print</span>(padded_GloVe.shape)</a>
<a class="sourceLine" id="cb25-32" title="32"></a>
<a class="sourceLine" id="cb25-33" title="33"><span class="co"># check to make sure padding done right</span></a></code></pre></div>
<pre><code>## (10041, 974)</code></pre>
<div class="sourceCode" id="cb27"><pre class="sourceCode python"><code class="sourceCode python"><a class="sourceLine" id="cb27-1" title="1"><span class="bu">print</span>([i <span class="cf">for</span> i, x <span class="kw">in</span> <span class="bu">enumerate</span>(padded_GloVe) <span class="cf">if</span> <span class="bu">len</span>(x) <span class="op">!=</span> percentile_95])    </a></code></pre></div>
<pre><code>## []</code></pre>
<p>With the corpus work out of the way, we now proceed to prepare our data for analysis in PyTorch. The code below creates a <code>TensorDataset</code> comprised of our features, padded GloVe tokens, and our labels. It then proceeds to spit the data sets into train, validation, and test sets.</p>
<div class="sourceCode" id="cb29"><pre class="sourceCode python"><code class="sourceCode python"><a class="sourceLine" id="cb29-1" title="1"><span class="co"># prepare tensor data sets</span></a>
<a class="sourceLine" id="cb29-2" title="2"><span class="kw">def</span> prepare_dataset(padded_tokens, target):</a>
<a class="sourceLine" id="cb29-3" title="3">    <span class="co"># prepare target into np array</span></a>
<a class="sourceLine" id="cb29-4" title="4">    target <span class="op">=</span> np.array(target.values, dtype<span class="op">=</span>np.int64).reshape(<span class="op">-</span><span class="dv">1</span>, <span class="dv">1</span>)</a>
<a class="sourceLine" id="cb29-5" title="5">    <span class="co"># create tensor data sets</span></a>
<a class="sourceLine" id="cb29-6" title="6">    tensor_df <span class="op">=</span> TensorDataset(torch.from_numpy(padded_tokens), torch.from_numpy(target))</a>
<a class="sourceLine" id="cb29-7" title="7">    <span class="co"># 80% of df</span></a>
<a class="sourceLine" id="cb29-8" title="8">    train_size <span class="op">=</span> <span class="bu">int</span>(<span class="fl">0.8</span> <span class="op">*</span> <span class="bu">len</span>(df))</a>
<a class="sourceLine" id="cb29-9" title="9">    <span class="co"># 20% of df</span></a>
<a class="sourceLine" id="cb29-10" title="10">    val_size <span class="op">=</span> <span class="bu">len</span>(df) <span class="op">-</span> train_size</a>
<a class="sourceLine" id="cb29-11" title="11">    <span class="co"># 50% of validation</span></a>
<a class="sourceLine" id="cb29-12" title="12">    test_size <span class="op">=</span> <span class="bu">int</span>(val_size <span class="op">-</span> <span class="fl">0.5</span><span class="op">*</span>val_size)</a>
<a class="sourceLine" id="cb29-13" title="13">    <span class="co"># divide the dataset by randomly selecting samples</span></a>
<a class="sourceLine" id="cb29-14" title="14">    train_dataset, val_dataset <span class="op">=</span> random_split(tensor_df, [train_size, val_size])</a>
<a class="sourceLine" id="cb29-15" title="15">    <span class="co"># divide validation by randomly selecting samples</span></a>
<a class="sourceLine" id="cb29-16" title="16">    val_dataset, test_dataset <span class="op">=</span> random_split(val_dataset, [test_size, test_size<span class="op">+</span><span class="dv">1</span>])</a>
<a class="sourceLine" id="cb29-17" title="17"></a>
<a class="sourceLine" id="cb29-18" title="18">    <span class="cf">return</span> train_dataset, val_dataset, test_dataset</a>
<a class="sourceLine" id="cb29-19" title="19"></a>
<a class="sourceLine" id="cb29-20" title="20"><span class="co"># create tenor data sets</span></a>
<a class="sourceLine" id="cb29-21" title="21">train_dataset, val_dataset, test_dataset <span class="op">=</span> prepare_dataset(padded_GloVe, df[<span class="st">&#39;target&#39;</span>])</a></code></pre></div>
<p>Since my corpus is imbalanced, I produce weighted samplers to help balance the distribution of data as it is fed outside of my data loaders.</p>
<div class="sourceCode" id="cb30"><pre class="sourceCode python"><code class="sourceCode python"><a class="sourceLine" id="cb30-1" title="1"><span class="co"># helper function to count target distribution inside tensor data sets</span></a>
<a class="sourceLine" id="cb30-2" title="2"><span class="kw">def</span> target_count(tensor_dataset):</a>
<a class="sourceLine" id="cb30-3" title="3">    <span class="co"># set empty count containers</span></a>
<a class="sourceLine" id="cb30-4" title="4">    count0 <span class="op">=</span> <span class="dv">0</span></a>
<a class="sourceLine" id="cb30-5" title="5">    count1 <span class="op">=</span> <span class="dv">0</span></a>
<a class="sourceLine" id="cb30-6" title="6">    <span class="co"># set total container to turn into torch tensor</span></a>
<a class="sourceLine" id="cb30-7" title="7">    total <span class="op">=</span> []</a>
<a class="sourceLine" id="cb30-8" title="8">    <span class="co"># for every item in the tensor data set</span></a>
<a class="sourceLine" id="cb30-9" title="9">    <span class="cf">for</span> i <span class="kw">in</span> tensor_dataset:</a>
<a class="sourceLine" id="cb30-10" title="10">        <span class="co"># if the target is equal to 0</span></a>
<a class="sourceLine" id="cb30-11" title="11">        <span class="cf">if</span> i[<span class="dv">1</span>].item() <span class="op">==</span> <span class="dv">0</span>:</a>
<a class="sourceLine" id="cb30-12" title="12">            count0 <span class="op">+=</span> <span class="dv">1</span></a>
<a class="sourceLine" id="cb30-13" title="13">        <span class="co"># if the target is equal to 1</span></a>
<a class="sourceLine" id="cb30-14" title="14">        <span class="cf">elif</span> i[<span class="dv">1</span>].item() <span class="op">==</span> <span class="dv">1</span>:</a>
<a class="sourceLine" id="cb30-15" title="15">            count1 <span class="op">+=</span> <span class="dv">1</span></a>
<a class="sourceLine" id="cb30-16" title="16">    total.append(count0)</a>
<a class="sourceLine" id="cb30-17" title="17">    total.append(count1)</a>
<a class="sourceLine" id="cb30-18" title="18">    <span class="cf">return</span> torch.tensor(total)</a>
<a class="sourceLine" id="cb30-19" title="19"></a>
<a class="sourceLine" id="cb30-20" title="20"></a>
<a class="sourceLine" id="cb30-21" title="21"><span class="co"># prepare weighted sampling for imbalanced classification</span></a>
<a class="sourceLine" id="cb30-22" title="22"><span class="kw">def</span> create_sampler(target_tensor, tensor_dataset):</a>
<a class="sourceLine" id="cb30-23" title="23">    <span class="co"># generate class distributions [x, y]</span></a>
<a class="sourceLine" id="cb30-24" title="24">    class_sample_count <span class="op">=</span> target_count(tensor_dataset)</a>
<a class="sourceLine" id="cb30-25" title="25">    <span class="co"># weight</span></a>
<a class="sourceLine" id="cb30-26" title="26">    weight <span class="op">=</span> <span class="fl">1.</span> <span class="op">/</span> class_sample_count.<span class="bu">float</span>()</a>
<a class="sourceLine" id="cb30-27" title="27">    <span class="co"># produce weights for each observation in the data set</span></a>
<a class="sourceLine" id="cb30-28" title="28">    samples_weight <span class="op">=</span> torch.tensor([weight[t[<span class="dv">1</span>]] <span class="cf">for</span> t <span class="kw">in</span> tensor_dataset])</a>
<a class="sourceLine" id="cb30-29" title="29">    <span class="co"># prepare sampler</span></a>
<a class="sourceLine" id="cb30-30" title="30">    sampler <span class="op">=</span> torch.utils.data.WeightedRandomSampler(weights<span class="op">=</span>samples_weight,</a>
<a class="sourceLine" id="cb30-31" title="31">                                                     num_samples<span class="op">=</span><span class="bu">len</span>(samples_weight),</a>
<a class="sourceLine" id="cb30-32" title="32">                                                     replacement<span class="op">=</span><span class="va">True</span>)</a>
<a class="sourceLine" id="cb30-33" title="33">    <span class="cf">return</span> sampler</a>
<a class="sourceLine" id="cb30-34" title="34"></a>
<a class="sourceLine" id="cb30-35" title="35"></a>
<a class="sourceLine" id="cb30-36" title="36"><span class="co"># create samplers for just training</span></a>
<a class="sourceLine" id="cb30-37" title="37">train_sampler <span class="op">=</span> create_sampler(target_count(train_dataset), train_dataset)</a></code></pre></div>
<p>As you might have guessed, preparing data loaders for each of our train, dev, and test data sets is our next task.</p>
<div class="sourceCode" id="cb31"><pre class="sourceCode python"><code class="sourceCode python"><a class="sourceLine" id="cb31-1" title="1"><span class="co"># prepare data loaders</span></a>
<a class="sourceLine" id="cb31-2" title="2"><span class="kw">def</span> data_loading(batch_size, data_set, <span class="op">**</span>kwargs):</a>
<a class="sourceLine" id="cb31-3" title="3">    <span class="co"># instantiate sampler and don&#39;t use last batch if uneven</span></a>
<a class="sourceLine" id="cb31-4" title="4">    temp_dataloader <span class="op">=</span> DataLoader(data_set,</a>
<a class="sourceLine" id="cb31-5" title="5">                                 batch_size<span class="op">=</span>batch_size,</a>
<a class="sourceLine" id="cb31-6" title="6">                                 drop_last<span class="op">=</span><span class="va">True</span>)</a>
<a class="sourceLine" id="cb31-7" title="7">    <span class="cf">return</span> temp_dataloader</a>
<a class="sourceLine" id="cb31-8" title="8"></a>
<a class="sourceLine" id="cb31-9" title="9"></a>
<a class="sourceLine" id="cb31-10" title="10"><span class="co"># create DataLoaders with samplers</span></a>
<a class="sourceLine" id="cb31-11" title="11">train_dataloader <span class="op">=</span> data_loading(batch_size<span class="op">=</span><span class="dv">64</span>,</a>
<a class="sourceLine" id="cb31-12" title="12">                                data_set<span class="op">=</span>train_dataset,</a>
<a class="sourceLine" id="cb31-13" title="13">                                sampler<span class="op">=</span>train_sampler)</a>
<a class="sourceLine" id="cb31-14" title="14"></a>
<a class="sourceLine" id="cb31-15" title="15">valid_dataloader <span class="op">=</span> data_loading(batch_size<span class="op">=</span><span class="dv">64</span>,</a>
<a class="sourceLine" id="cb31-16" title="16">                                data_set<span class="op">=</span>val_dataset)</a>
<a class="sourceLine" id="cb31-17" title="17"></a>
<a class="sourceLine" id="cb31-18" title="18">test_dataloader <span class="op">=</span> data_loading(batch_size<span class="op">=</span><span class="dv">64</span>,</a>
<a class="sourceLine" id="cb31-19" title="19">                               data_set<span class="op">=</span>test_dataset)</a></code></pre></div>
<p>We can check to see how our sampler is working by running the loop below. As we can see, the data loader is outputting relatively balanced data into each batch.</p>
<div class="sourceCode" id="cb32"><pre class="sourceCode python"><code class="sourceCode python"><a class="sourceLine" id="cb32-1" title="1"><span class="co"># lets check class balance for each batch to see how the sampler is working</span></a>
<a class="sourceLine" id="cb32-2" title="2"><span class="cf">for</span> i, (x, y) <span class="kw">in</span> <span class="bu">enumerate</span>(valid_dataloader):</a>
<a class="sourceLine" id="cb32-3" title="3">    <span class="bu">print</span>(<span class="st">&quot;batch index </span><span class="sc">{}</span><span class="st">, 0/1: </span><span class="sc">{}</span><span class="st">/</span><span class="sc">{}</span><span class="st">&quot;</span>.<span class="bu">format</span>(</a>
<a class="sourceLine" id="cb32-4" title="4">        i, (y <span class="op">==</span> <span class="dv">0</span>).<span class="bu">sum</span>(), (y <span class="op">==</span> <span class="dv">1</span>).<span class="bu">sum</span>()))</a>
<a class="sourceLine" id="cb32-5" title="5">    <span class="bu">print</span>(<span class="st">&quot;x.shape </span><span class="sc">{}</span><span class="st">, y.shape </span><span class="sc">{}</span><span class="st">&quot;</span>.<span class="bu">format</span>(x.shape, y.shape))</a></code></pre></div>
<pre><code>## batch index 0, 0/1: 49/15
## x.shape torch.Size([64, 974]), y.shape torch.Size([64, 1])
## batch index 1, 0/1: 55/9
## x.shape torch.Size([64, 974]), y.shape torch.Size([64, 1])
## batch index 2, 0/1: 49/15
## x.shape torch.Size([64, 974]), y.shape torch.Size([64, 1])
## batch index 3, 0/1: 51/13
## x.shape torch.Size([64, 974]), y.shape torch.Size([64, 1])
## batch index 4, 0/1: 54/10
## x.shape torch.Size([64, 974]), y.shape torch.Size([64, 1])
## batch index 5, 0/1: 50/14
## x.shape torch.Size([64, 974]), y.shape torch.Size([64, 1])
## batch index 6, 0/1: 50/14
## x.shape torch.Size([64, 974]), y.shape torch.Size([64, 1])
## batch index 7, 0/1: 46/18
## x.shape torch.Size([64, 974]), y.shape torch.Size([64, 1])
## batch index 8, 0/1: 48/16
## x.shape torch.Size([64, 974]), y.shape torch.Size([64, 1])
## batch index 9, 0/1: 45/19
## x.shape torch.Size([64, 974]), y.shape torch.Size([64, 1])
## batch index 10, 0/1: 52/12
## x.shape torch.Size([64, 974]), y.shape torch.Size([64, 1])
## batch index 11, 0/1: 42/22
## x.shape torch.Size([64, 974]), y.shape torch.Size([64, 1])
## batch index 12, 0/1: 47/17
## x.shape torch.Size([64, 974]), y.shape torch.Size([64, 1])
## batch index 13, 0/1: 49/15
## x.shape torch.Size([64, 974]), y.shape torch.Size([64, 1])
## batch index 14, 0/1: 44/20
## x.shape torch.Size([64, 974]), y.shape torch.Size([64, 1])</code></pre>
<p>Next, we build a Kim Yoon (2014) CNN designed to use GloVe embeddings. Later, we will simplify this in order to use embeddings from a Transformer.</p>
<div class="sourceCode" id="cb34"><pre class="sourceCode python"><code class="sourceCode python"><a class="sourceLine" id="cb34-1" title="1"><span class="co"># Build Kim Yoon CNN</span></a>
<a class="sourceLine" id="cb34-2" title="2"><span class="kw">class</span> KimCNN(nn.Module):</a>
<a class="sourceLine" id="cb34-3" title="3"></a>
<a class="sourceLine" id="cb34-4" title="4">    <span class="kw">def</span> <span class="fu">__init__</span>(<span class="va">self</span>, config):</a>
<a class="sourceLine" id="cb34-5" title="5">        <span class="bu">super</span>().<span class="fu">__init__</span>()</a>
<a class="sourceLine" id="cb34-6" title="6">        output_channel <span class="op">=</span> config.output_channel  <span class="co"># number of kernels</span></a>
<a class="sourceLine" id="cb34-7" title="7">        num_classes <span class="op">=</span> config.num_classes  <span class="co"># number of targets to predict</span></a>
<a class="sourceLine" id="cb34-8" title="8">        vocab_size <span class="op">=</span> config.vocab_size  <span class="co"># vocab size of corpus</span></a>
<a class="sourceLine" id="cb34-9" title="9">        embedding_dim <span class="op">=</span> config.embedding_dim  <span class="co"># GloVe embed dim size</span></a>
<a class="sourceLine" id="cb34-10" title="10">        pre_embed <span class="op">=</span> config.pre_embed  <span class="co"># GloVe coefs</span></a>
<a class="sourceLine" id="cb34-11" title="11">        <span class="va">self</span>.mode <span class="op">=</span> config.mode  <span class="co"># static, or not</span></a>
<a class="sourceLine" id="cb34-12" title="12">        ks <span class="op">=</span> <span class="dv">3</span>  <span class="co"># three conv nets here</span></a>
<a class="sourceLine" id="cb34-13" title="13">        dropout <span class="op">=</span> config.dropout  <span class="co"># dropout value</span></a>
<a class="sourceLine" id="cb34-14" title="14">        padding <span class="op">=</span> config.padding_idx  <span class="co"># padding indx value</span></a>
<a class="sourceLine" id="cb34-15" title="15"></a>
<a class="sourceLine" id="cb34-16" title="16">        <span class="co"># for single embedding, input_channel = 1</span></a>
<a class="sourceLine" id="cb34-17" title="17">        input_channel <span class="op">=</span> <span class="dv">1</span></a>
<a class="sourceLine" id="cb34-18" title="18">        <span class="cf">if</span> config.mode <span class="op">==</span> <span class="st">&#39;rand&#39;</span>:</a>
<a class="sourceLine" id="cb34-19" title="19">            rand_embed_init <span class="op">=</span> torch.Tensor(vocab_size, embedding_dim).uniform_(<span class="op">-</span><span class="fl">0.25</span>, <span class="fl">0.25</span>)</a>
<a class="sourceLine" id="cb34-20" title="20">            <span class="va">self</span>.embed <span class="op">=</span> nn.Embedding.from_pretrained(rand_embed_init, freeze<span class="op">=</span><span class="va">False</span>)</a>
<a class="sourceLine" id="cb34-21" title="21"></a>
<a class="sourceLine" id="cb34-22" title="22">        <span class="cf">elif</span> config.mode <span class="op">==</span> <span class="st">&#39;static&#39;</span>:</a>
<a class="sourceLine" id="cb34-23" title="23">            <span class="va">self</span>.static_embed <span class="op">=</span> nn.Embedding.from_pretrained(pre_embed,</a>
<a class="sourceLine" id="cb34-24" title="24">                                                             freeze<span class="op">=</span><span class="va">True</span>,</a>
<a class="sourceLine" id="cb34-25" title="25">                                                             padding_idx<span class="op">=</span>padding)</a>
<a class="sourceLine" id="cb34-26" title="26"></a>
<a class="sourceLine" id="cb34-27" title="27">        <span class="cf">elif</span> config.mode <span class="op">==</span> <span class="st">&#39;non-static&#39;</span>:</a>
<a class="sourceLine" id="cb34-28" title="28">            <span class="va">self</span>.non_static_embed <span class="op">=</span> nn.Embedding.from_pretrained(pre_embed,</a>
<a class="sourceLine" id="cb34-29" title="29">                                                                 freeze<span class="op">=</span><span class="va">False</span>,</a>
<a class="sourceLine" id="cb34-30" title="30">                                                                 padding_idx<span class="op">=</span>padding)</a>
<a class="sourceLine" id="cb34-31" title="31"></a>
<a class="sourceLine" id="cb34-32" title="32">        <span class="co"># input channel increases with trainable and untrainable embeddings</span></a>
<a class="sourceLine" id="cb34-33" title="33">        <span class="cf">elif</span> config.mode <span class="op">==</span> <span class="st">&#39;multichannel&#39;</span>:</a>
<a class="sourceLine" id="cb34-34" title="34">            <span class="va">self</span>.static_embed <span class="op">=</span> nn.Embedding.from_pretrained(pre_embed,</a>
<a class="sourceLine" id="cb34-35" title="35">                                                             freeze<span class="op">=</span><span class="va">True</span>,</a>
<a class="sourceLine" id="cb34-36" title="36">                                                             padding_idx<span class="op">=</span>padding)</a>
<a class="sourceLine" id="cb34-37" title="37">            <span class="va">self</span>.non_static_embed <span class="op">=</span> nn.Embedding.from_pretrained(pre_embed,</a>
<a class="sourceLine" id="cb34-38" title="38">                                                                 freeze<span class="op">=</span><span class="va">False</span>,</a>
<a class="sourceLine" id="cb34-39" title="39">                                                                 padding_idx<span class="op">=</span>padding)</a>
<a class="sourceLine" id="cb34-40" title="40">            input_channel <span class="op">=</span> <span class="dv">2</span></a>
<a class="sourceLine" id="cb34-41" title="41"></a>
<a class="sourceLine" id="cb34-42" title="42">        <span class="cf">else</span>:</a>
<a class="sourceLine" id="cb34-43" title="43">            <span class="bu">print</span>(<span class="st">&quot;Unsupported Mode&quot;</span>)</a>
<a class="sourceLine" id="cb34-44" title="44">            <span class="cf">raise</span> <span class="pp">Exception</span></a>
<a class="sourceLine" id="cb34-45" title="45"></a>
<a class="sourceLine" id="cb34-46" title="46">        <span class="co"># input_channel = word embeddings at a value of 1; 3 for RGB images</span></a>
<a class="sourceLine" id="cb34-47" title="47">        <span class="co"># output_channel = number of kernels</span></a>
<a class="sourceLine" id="cb34-48" title="48">        <span class="co"># [3, 4, 5] = window height</span></a>
<a class="sourceLine" id="cb34-49" title="49">        <span class="co"># embedding_dim = length of embedding dim; my GloVe is 202</span></a>
<a class="sourceLine" id="cb34-50" title="50">        <span class="co"># padding = padding to account for height of search window</span></a>
<a class="sourceLine" id="cb34-51" title="51">        <span class="va">self</span>.conv1 <span class="op">=</span> nn.Conv2d(input_channel, output_channel, (<span class="dv">3</span>, embedding_dim), padding<span class="op">=</span>(<span class="dv">2</span>, <span class="dv">0</span>))</a>
<a class="sourceLine" id="cb34-52" title="52">        <span class="va">self</span>.conv2 <span class="op">=</span> nn.Conv2d(input_channel, output_channel, (<span class="dv">4</span>, embedding_dim), padding<span class="op">=</span>(<span class="dv">3</span>, <span class="dv">0</span>))</a>
<a class="sourceLine" id="cb34-53" title="53">        <span class="va">self</span>.conv3 <span class="op">=</span> nn.Conv2d(input_channel, output_channel, (<span class="dv">5</span>, embedding_dim), padding<span class="op">=</span>(<span class="dv">4</span>, <span class="dv">0</span>))</a>
<a class="sourceLine" id="cb34-54" title="54">        <span class="co"># apply dropout</span></a>
<a class="sourceLine" id="cb34-55" title="55">        <span class="va">self</span>.dropout <span class="op">=</span> nn.Dropout(dropout)</a>
<a class="sourceLine" id="cb34-56" title="56">        <span class="co"># fully connected layer for classification</span></a>
<a class="sourceLine" id="cb34-57" title="57">        <span class="co"># 3x conv nets * output channel</span></a>
<a class="sourceLine" id="cb34-58" title="58">        <span class="va">self</span>.fc1 <span class="op">=</span> nn.Linear(ks <span class="op">*</span> output_channel, num_classes)</a>
<a class="sourceLine" id="cb34-59" title="59"></a>
<a class="sourceLine" id="cb34-60" title="60">    <span class="kw">def</span> forward(<span class="va">self</span>, x, <span class="op">**</span>kwargs):</a>
<a class="sourceLine" id="cb34-61" title="61">        <span class="cf">if</span> <span class="va">self</span>.mode <span class="op">==</span> <span class="st">&#39;rand&#39;</span>:</a>
<a class="sourceLine" id="cb34-62" title="62">            word_input <span class="op">=</span> <span class="va">self</span>.embed(x)  <span class="co"># (batch, sent_len, embed_dim)</span></a>
<a class="sourceLine" id="cb34-63" title="63">            x <span class="op">=</span> word_input.unsqueeze(<span class="dv">1</span>)  <span class="co"># (batch, channel_input, sent_len, embed_dim)</span></a>
<a class="sourceLine" id="cb34-64" title="64"></a>
<a class="sourceLine" id="cb34-65" title="65">        <span class="cf">elif</span> <span class="va">self</span>.mode <span class="op">==</span> <span class="st">&#39;static&#39;</span>:</a>
<a class="sourceLine" id="cb34-66" title="66">            static_input <span class="op">=</span> <span class="va">self</span>.static_embed(x)</a>
<a class="sourceLine" id="cb34-67" title="67">            x <span class="op">=</span> static_input.unsqueeze(<span class="dv">1</span>)  <span class="co"># (batch, channel_input, sent_len, embed_dim)</span></a>
<a class="sourceLine" id="cb34-68" title="68"></a>
<a class="sourceLine" id="cb34-69" title="69">        <span class="cf">elif</span> <span class="va">self</span>.mode <span class="op">==</span> <span class="st">&#39;non-static&#39;</span>:</a>
<a class="sourceLine" id="cb34-70" title="70">            non_static_input <span class="op">=</span> <span class="va">self</span>.non_static_embed(x)</a>
<a class="sourceLine" id="cb34-71" title="71">            x <span class="op">=</span> non_static_input.unsqueeze(<span class="dv">1</span>)  <span class="co"># (batch, channel_input, sent_len, embed_dim)</span></a>
<a class="sourceLine" id="cb34-72" title="72"></a>
<a class="sourceLine" id="cb34-73" title="73">        <span class="cf">elif</span> <span class="va">self</span>.mode <span class="op">==</span> <span class="st">&#39;multichannel&#39;</span>:</a>
<a class="sourceLine" id="cb34-74" title="74">            non_static_input <span class="op">=</span> <span class="va">self</span>.non_static_embed(x)</a>
<a class="sourceLine" id="cb34-75" title="75">            static_input <span class="op">=</span> <span class="va">self</span>.static_embed(x)</a>
<a class="sourceLine" id="cb34-76" title="76">            x <span class="op">=</span> torch.stack([non_static_input, static_input], dim<span class="op">=</span><span class="dv">1</span>)  <span class="co"># (batch, channel_input=2, sent_len, embed_dim)</span></a>
<a class="sourceLine" id="cb34-77" title="77"></a>
<a class="sourceLine" id="cb34-78" title="78">        <span class="cf">else</span>:</a>
<a class="sourceLine" id="cb34-79" title="79">            <span class="bu">print</span>(<span class="st">&quot;Unsupported Mode&quot;</span>)</a>
<a class="sourceLine" id="cb34-80" title="80">            <span class="cf">raise</span> <span class="pp">Exception</span></a>
<a class="sourceLine" id="cb34-81" title="81"></a>
<a class="sourceLine" id="cb34-82" title="82">        <span class="co"># squeeze to get size; (batch, channel_output, ~=sent_len) * ks</span></a>
<a class="sourceLine" id="cb34-83" title="83">        x <span class="op">=</span> [F.relu(<span class="va">self</span>.conv1(x)).squeeze(<span class="dv">3</span>), F.relu(<span class="va">self</span>.conv2(x)).squeeze(<span class="dv">3</span>), F.relu(<span class="va">self</span>.conv3(x)).squeeze(<span class="dv">3</span>)]</a>
<a class="sourceLine" id="cb34-84" title="84">        <span class="co"># max-over-time pooling; # (batch, channel_output) * ks</span></a>
<a class="sourceLine" id="cb34-85" title="85">        x <span class="op">=</span> [F.max_pool1d(i, i.size(<span class="dv">2</span>)).squeeze(<span class="dv">2</span>) <span class="cf">for</span> i <span class="kw">in</span> x]</a>
<a class="sourceLine" id="cb34-86" title="86">        <span class="co"># concat results; (batch, channel_output * ks)</span></a>
<a class="sourceLine" id="cb34-87" title="87">        x <span class="op">=</span> torch.cat(x, <span class="dv">1</span>)</a>
<a class="sourceLine" id="cb34-88" title="88">        <span class="co"># add dropout</span></a>
<a class="sourceLine" id="cb34-89" title="89">        x <span class="op">=</span> <span class="va">self</span>.dropout(x)</a>
<a class="sourceLine" id="cb34-90" title="90">        <span class="co"># generate logits (batch, target_size)</span></a>
<a class="sourceLine" id="cb34-91" title="91">        logit <span class="op">=</span> <span class="va">self</span>.fc1(x)</a>
<a class="sourceLine" id="cb34-92" title="92">        <span class="cf">return</span> logit</a></code></pre></div>
<p>Below we instantiate some helper functions for time keeping and reviewing the amount of trainable parameters.</p>
<div class="sourceCode" id="cb35"><pre class="sourceCode python"><code class="sourceCode python"><a class="sourceLine" id="cb35-1" title="1"><span class="co"># time function</span></a>
<a class="sourceLine" id="cb35-2" title="2"><span class="kw">def</span> format_time(elapsed):</a>
<a class="sourceLine" id="cb35-3" title="3">    <span class="co">&#39;&#39;&#39;</span></a>
<a class="sourceLine" id="cb35-4" title="4"><span class="co">    Takes a time in seconds and returns a string hh:mm:ss</span></a>
<a class="sourceLine" id="cb35-5" title="5"><span class="co">    &#39;&#39;&#39;</span></a>
<a class="sourceLine" id="cb35-6" title="6">    <span class="co"># round to the nearest second.</span></a>
<a class="sourceLine" id="cb35-7" title="7">    elapsed_rounded <span class="op">=</span> <span class="bu">int</span>(<span class="bu">round</span>((elapsed)))</a>
<a class="sourceLine" id="cb35-8" title="8">    <span class="co"># format as hh:mm:ss</span></a>
<a class="sourceLine" id="cb35-9" title="9">    <span class="cf">return</span> <span class="bu">str</span>(datetime.timedelta(seconds<span class="op">=</span>elapsed_rounded))</a>
<a class="sourceLine" id="cb35-10" title="10">    </a>
<a class="sourceLine" id="cb35-11" title="11"><span class="kw">def</span> review_model_params(model):</a>
<a class="sourceLine" id="cb35-12" title="12">    pytorch_total_params <span class="op">=</span> <span class="bu">sum</span>(p.numel() <span class="cf">for</span> p <span class="kw">in</span> model.parameters())</a>
<a class="sourceLine" id="cb35-13" title="13">    <span class="bu">print</span>(<span class="st">&#39;Total params:&#39;</span>, pytorch_total_params)</a>
<a class="sourceLine" id="cb35-14" title="14">    pytorch_total_params <span class="op">=</span> <span class="bu">sum</span>(p.numel() <span class="cf">for</span> p <span class="kw">in</span> model.parameters() <span class="cf">if</span> p.requires_grad)</a>
<a class="sourceLine" id="cb35-15" title="15">    <span class="bu">print</span>(<span class="st">&#39;Total trainable params&#39;</span>, pytorch_total_params)</a>
<a class="sourceLine" id="cb35-16" title="16">    <span class="cf">return</span> <span class="va">None</span></a></code></pre></div>
<p>Now, we prepare functions to train, validate, and test our data.</p>
<div class="sourceCode" id="cb36"><pre class="sourceCode python"><code class="sourceCode python"><a class="sourceLine" id="cb36-1" title="1"><span class="kw">def</span> train(model, dataloader, optimizer, criterion):</a>
<a class="sourceLine" id="cb36-2" title="2"></a>
<a class="sourceLine" id="cb36-3" title="3">    <span class="co"># capture time</span></a>
<a class="sourceLine" id="cb36-4" title="4">    total_t0 <span class="op">=</span> time.time()</a>
<a class="sourceLine" id="cb36-5" title="5"></a>
<a class="sourceLine" id="cb36-6" title="6">    <span class="co"># Perform one full pass over the training set.</span></a>
<a class="sourceLine" id="cb36-7" title="7">    <span class="bu">print</span>(<span class="st">&quot;&quot;</span>)</a>
<a class="sourceLine" id="cb36-8" title="8">    <span class="bu">print</span>(<span class="st">&#39;======== Epoch </span><span class="sc">{:}</span><span class="st"> / </span><span class="sc">{:}</span><span class="st"> ========&#39;</span>.<span class="bu">format</span>(epoch <span class="op">+</span> <span class="dv">1</span>, epochs))</a>
<a class="sourceLine" id="cb36-9" title="9">    <span class="bu">print</span>(<span class="st">&#39;Training...&#39;</span>)</a>
<a class="sourceLine" id="cb36-10" title="10"></a>
<a class="sourceLine" id="cb36-11" title="11">    <span class="co"># reset total loss for epoch</span></a>
<a class="sourceLine" id="cb36-12" title="12">    train_total_loss <span class="op">=</span> <span class="dv">0</span></a>
<a class="sourceLine" id="cb36-13" title="13">    total_train_f1 <span class="op">=</span> <span class="dv">0</span></a>
<a class="sourceLine" id="cb36-14" title="14"></a>
<a class="sourceLine" id="cb36-15" title="15">    <span class="co"># put model into traning mode</span></a>
<a class="sourceLine" id="cb36-16" title="16">    model.train()</a>
<a class="sourceLine" id="cb36-17" title="17"></a>
<a class="sourceLine" id="cb36-18" title="18">    <span class="co"># for each batch of training data...</span></a>
<a class="sourceLine" id="cb36-19" title="19">    <span class="cf">for</span> step, batch <span class="kw">in</span> <span class="bu">enumerate</span>(dataloader):</a>
<a class="sourceLine" id="cb36-20" title="20"></a>
<a class="sourceLine" id="cb36-21" title="21">        <span class="co"># progress update every 40 batches.</span></a>
<a class="sourceLine" id="cb36-22" title="22">        <span class="cf">if</span> step <span class="op">%</span> <span class="dv">40</span> <span class="op">==</span> <span class="dv">0</span> <span class="kw">and</span> <span class="kw">not</span> step <span class="op">==</span> <span class="dv">0</span>:</a>
<a class="sourceLine" id="cb36-23" title="23"></a>
<a class="sourceLine" id="cb36-24" title="24">            <span class="co"># Report progress.</span></a>
<a class="sourceLine" id="cb36-25" title="25">            <span class="bu">print</span>(<span class="st">&#39;  Batch {:&gt;5,}  of  {:&gt;5,}.&#39;</span>.<span class="bu">format</span>(step, <span class="bu">len</span>(dataloader)))</a>
<a class="sourceLine" id="cb36-26" title="26"></a>
<a class="sourceLine" id="cb36-27" title="27">        <span class="co"># Unpack this training batch from our dataloader:</span></a>
<a class="sourceLine" id="cb36-28" title="28">        <span class="co">#</span></a>
<a class="sourceLine" id="cb36-29" title="29">        <span class="co"># As we unpack the batch, we&#39;ll also copy each tensor to the GPU</span></a>
<a class="sourceLine" id="cb36-30" title="30">        <span class="co">#</span></a>
<a class="sourceLine" id="cb36-31" title="31">        <span class="co"># `batch` contains two pytorch tensors:</span></a>
<a class="sourceLine" id="cb36-32" title="32">        <span class="co">#   [0]: input ids</span></a>
<a class="sourceLine" id="cb36-33" title="33">        <span class="co">#   [1]: labels</span></a>
<a class="sourceLine" id="cb36-34" title="34">        b_input_ids <span class="op">=</span> batch[<span class="dv">0</span>].cuda()</a>
<a class="sourceLine" id="cb36-35" title="35">        b_labels <span class="op">=</span> batch[<span class="dv">1</span>].cuda().<span class="bu">type</span>(torch.cuda.FloatTensor)</a>
<a class="sourceLine" id="cb36-36" title="36"></a>
<a class="sourceLine" id="cb36-37" title="37">        <span class="co"># clear previously calculated gradients</span></a>
<a class="sourceLine" id="cb36-38" title="38">        optimizer.zero_grad()</a>
<a class="sourceLine" id="cb36-39" title="39"></a>
<a class="sourceLine" id="cb36-40" title="40">        <span class="co"># forward propagation (evaluate model on training batch)</span></a>
<a class="sourceLine" id="cb36-41" title="41">        logits <span class="op">=</span> model(b_input_ids)</a>
<a class="sourceLine" id="cb36-42" title="42"></a>
<a class="sourceLine" id="cb36-43" title="43">        <span class="co"># calculate BCEWithLogitsLoss</span></a>
<a class="sourceLine" id="cb36-44" title="44">        loss <span class="op">=</span> criterion(logits, b_labels)</a>
<a class="sourceLine" id="cb36-45" title="45"></a>
<a class="sourceLine" id="cb36-46" title="46">        <span class="co"># sum the training loss over all batches for average loss at end</span></a>
<a class="sourceLine" id="cb36-47" title="47">        train_total_loss <span class="op">+=</span> loss.item()</a>
<a class="sourceLine" id="cb36-48" title="48"></a>
<a class="sourceLine" id="cb36-49" title="49">        <span class="co"># perform backward propagation to calculate gradients</span></a>
<a class="sourceLine" id="cb36-50" title="50">        loss.backward()</a>
<a class="sourceLine" id="cb36-51" title="51"></a>
<a class="sourceLine" id="cb36-52" title="52">        <span class="co"># clip the gradients to 1 to reduce exploding gradients</span></a>
<a class="sourceLine" id="cb36-53" title="53">        torch.nn.utils.clip_grad_norm_(model.parameters(), <span class="fl">1.0</span>)</a>
<a class="sourceLine" id="cb36-54" title="54"></a>
<a class="sourceLine" id="cb36-55" title="55">        <span class="co"># update coefficients and toward gradient</span></a>
<a class="sourceLine" id="cb36-56" title="56">        optimizer.step()</a>
<a class="sourceLine" id="cb36-57" title="57"></a>
<a class="sourceLine" id="cb36-58" title="58">        <span class="co"># update the learning rate</span></a>
<a class="sourceLine" id="cb36-59" title="59">        scheduler.step()</a>
<a class="sourceLine" id="cb36-60" title="60"></a>
<a class="sourceLine" id="cb36-61" title="61">        <span class="co"># generate predictions</span></a>
<a class="sourceLine" id="cb36-62" title="62">        rounded_preds <span class="op">=</span> torch.<span class="bu">round</span>(torch.sigmoid(logits))</a>
<a class="sourceLine" id="cb36-63" title="63"></a>
<a class="sourceLine" id="cb36-64" title="64">        <span class="co"># move logits and labels to CPU</span></a>
<a class="sourceLine" id="cb36-65" title="65">        rounded_preds <span class="op">=</span> rounded_preds.detach().cpu().numpy()</a>
<a class="sourceLine" id="cb36-66" title="66">        y_true <span class="op">=</span> b_labels.detach().cpu().numpy()</a>
<a class="sourceLine" id="cb36-67" title="67"></a>
<a class="sourceLine" id="cb36-68" title="68">        <span class="co"># calculate f1</span></a>
<a class="sourceLine" id="cb36-69" title="69">        total_train_f1 <span class="op">+=</span> f1_score(rounded_preds, y_true,</a>
<a class="sourceLine" id="cb36-70" title="70">                                   average<span class="op">=</span><span class="st">&#39;weighted&#39;</span>,</a>
<a class="sourceLine" id="cb36-71" title="71">                                   labels<span class="op">=</span>np.unique(rounded_preds))</a>
<a class="sourceLine" id="cb36-72" title="72"></a>
<a class="sourceLine" id="cb36-73" title="73">    <span class="co"># calculate the average loss over all of the batches</span></a>
<a class="sourceLine" id="cb36-74" title="74">    avg_train_loss <span class="op">=</span> train_total_loss <span class="op">/</span> <span class="bu">len</span>(dataloader)</a>
<a class="sourceLine" id="cb36-75" title="75"></a>
<a class="sourceLine" id="cb36-76" title="76">    <span class="co"># calculate the average f1 over all of the batches</span></a>
<a class="sourceLine" id="cb36-77" title="77">    avg_train_f1 <span class="op">=</span> total_train_f1 <span class="op">/</span> <span class="bu">len</span>(dataloader)</a>
<a class="sourceLine" id="cb36-78" title="78"></a>
<a class="sourceLine" id="cb36-79" title="79">    <span class="co"># Record all statistics from this epoch.</span></a>
<a class="sourceLine" id="cb36-80" title="80">    training_stats.append(</a>
<a class="sourceLine" id="cb36-81" title="81">        {</a>
<a class="sourceLine" id="cb36-82" title="82">            <span class="st">&#39;Train Loss&#39;</span>: avg_train_loss,</a>
<a class="sourceLine" id="cb36-83" title="83">            <span class="st">&#39;Train F1&#39;</span>: avg_train_f1</a>
<a class="sourceLine" id="cb36-84" title="84">        }</a>
<a class="sourceLine" id="cb36-85" title="85">    )</a>
<a class="sourceLine" id="cb36-86" title="86"></a>
<a class="sourceLine" id="cb36-87" title="87">    <span class="co"># training time end</span></a>
<a class="sourceLine" id="cb36-88" title="88">    training_time <span class="op">=</span> format_time(time.time() <span class="op">-</span> total_t0)</a>
<a class="sourceLine" id="cb36-89" title="89"></a>
<a class="sourceLine" id="cb36-90" title="90">    <span class="co"># print result summaries</span></a>
<a class="sourceLine" id="cb36-91" title="91">    <span class="bu">print</span>(<span class="st">&quot;&quot;</span>)</a>
<a class="sourceLine" id="cb36-92" title="92">    <span class="bu">print</span>(<span class="st">&quot;summary results&quot;</span>)</a>
<a class="sourceLine" id="cb36-93" title="93">    <span class="bu">print</span>(<span class="st">&quot;epoch | trn loss | trn f1 | trn time &quot;</span>)</a>
<a class="sourceLine" id="cb36-94" title="94">    <span class="bu">print</span>(<span class="ss">f&quot;</span><span class="sc">{</span>epoch<span class="op">+</span><span class="dv">1</span><span class="sc">:5d}</span><span class="ss"> | </span><span class="sc">{</span>avg_train_loss<span class="sc">:.5f}</span><span class="ss"> | </span><span class="sc">{</span>avg_train_f1<span class="sc">:.5f}</span><span class="ss"> | </span><span class="sc">{</span>training_time<span class="sc">:}</span><span class="ss">&quot;</span>)</a>
<a class="sourceLine" id="cb36-95" title="95"></a>
<a class="sourceLine" id="cb36-96" title="96">    torch.cuda.empty_cache()</a>
<a class="sourceLine" id="cb36-97" title="97"></a>
<a class="sourceLine" id="cb36-98" title="98">    <span class="cf">return</span> training_stats</a></code></pre></div>
<div class="sourceCode" id="cb37"><pre class="sourceCode python"><code class="sourceCode python"><a class="sourceLine" id="cb37-1" title="1"><span class="kw">def</span> validating(model, dataloader, criterion):</a>
<a class="sourceLine" id="cb37-2" title="2"></a>
<a class="sourceLine" id="cb37-3" title="3">    <span class="co"># capture validation time</span></a>
<a class="sourceLine" id="cb37-4" title="4">    total_t0 <span class="op">=</span> time.time()</a>
<a class="sourceLine" id="cb37-5" title="5"></a>
<a class="sourceLine" id="cb37-6" title="6">    <span class="co"># After the completion of each training epoch, measure our performance on</span></a>
<a class="sourceLine" id="cb37-7" title="7">    <span class="co"># our validation set.</span></a>
<a class="sourceLine" id="cb37-8" title="8">    <span class="bu">print</span>(<span class="st">&quot;&quot;</span>)</a>
<a class="sourceLine" id="cb37-9" title="9">    <span class="bu">print</span>(<span class="st">&quot;Running Validation...&quot;</span>)</a>
<a class="sourceLine" id="cb37-10" title="10"></a>
<a class="sourceLine" id="cb37-11" title="11">    <span class="co"># put the model in evaluation mode</span></a>
<a class="sourceLine" id="cb37-12" title="12">    model.<span class="bu">eval</span>()</a>
<a class="sourceLine" id="cb37-13" title="13"></a>
<a class="sourceLine" id="cb37-14" title="14">    <span class="co"># track variables</span></a>
<a class="sourceLine" id="cb37-15" title="15">    total_valid_accuracy <span class="op">=</span> <span class="dv">0</span></a>
<a class="sourceLine" id="cb37-16" title="16">    total_valid_loss <span class="op">=</span> <span class="dv">0</span></a>
<a class="sourceLine" id="cb37-17" title="17">    total_valid_f1 <span class="op">=</span> <span class="dv">0</span></a>
<a class="sourceLine" id="cb37-18" title="18">    total_valid_recall <span class="op">=</span> <span class="dv">0</span></a>
<a class="sourceLine" id="cb37-19" title="19">    total_valid_precision <span class="op">=</span> <span class="dv">0</span></a>
<a class="sourceLine" id="cb37-20" title="20"></a>
<a class="sourceLine" id="cb37-21" title="21">    <span class="co"># evaluate data for one epoch</span></a>
<a class="sourceLine" id="cb37-22" title="22">    <span class="cf">for</span> batch <span class="kw">in</span> dataloader:</a>
<a class="sourceLine" id="cb37-23" title="23"></a>
<a class="sourceLine" id="cb37-24" title="24">        <span class="co"># unpack batch from dataloader</span></a>
<a class="sourceLine" id="cb37-25" title="25">        b_input_ids <span class="op">=</span> batch[<span class="dv">0</span>].cuda()</a>
<a class="sourceLine" id="cb37-26" title="26">        b_labels <span class="op">=</span> batch[<span class="dv">1</span>].cuda().<span class="bu">type</span>(torch.cuda.FloatTensor)</a>
<a class="sourceLine" id="cb37-27" title="27"></a>
<a class="sourceLine" id="cb37-28" title="28">        <span class="co"># tell pytorch not to bother calculating gradients</span></a>
<a class="sourceLine" id="cb37-29" title="29">        <span class="co"># as its only necessary for training</span></a>
<a class="sourceLine" id="cb37-30" title="30">        <span class="cf">with</span> torch.no_grad():</a>
<a class="sourceLine" id="cb37-31" title="31"></a>
<a class="sourceLine" id="cb37-32" title="32">            <span class="co"># forward propagation (evaluate model on training batch)</span></a>
<a class="sourceLine" id="cb37-33" title="33">            logits <span class="op">=</span> model(b_input_ids)</a>
<a class="sourceLine" id="cb37-34" title="34"></a>
<a class="sourceLine" id="cb37-35" title="35">            <span class="co"># calculate BCEWithLogitsLoss</span></a>
<a class="sourceLine" id="cb37-36" title="36">            loss <span class="op">=</span> criterion(logits, b_labels)</a>
<a class="sourceLine" id="cb37-37" title="37"></a>
<a class="sourceLine" id="cb37-38" title="38">        <span class="co"># accumulate validation loss</span></a>
<a class="sourceLine" id="cb37-39" title="39">        total_valid_loss <span class="op">+=</span> loss.item()</a>
<a class="sourceLine" id="cb37-40" title="40"></a>
<a class="sourceLine" id="cb37-41" title="41">        <span class="co"># generate predictions</span></a>
<a class="sourceLine" id="cb37-42" title="42">        rounded_preds <span class="op">=</span> torch.<span class="bu">round</span>(torch.sigmoid(logits))</a>
<a class="sourceLine" id="cb37-43" title="43"></a>
<a class="sourceLine" id="cb37-44" title="44">        <span class="co"># move logits and labels to CPU</span></a>
<a class="sourceLine" id="cb37-45" title="45">        rounded_preds <span class="op">=</span> rounded_preds.detach().cpu().numpy()</a>
<a class="sourceLine" id="cb37-46" title="46">        y_true <span class="op">=</span> b_labels.detach().cpu().numpy()</a>
<a class="sourceLine" id="cb37-47" title="47"></a>
<a class="sourceLine" id="cb37-48" title="48">        <span class="co"># calculate f1</span></a>
<a class="sourceLine" id="cb37-49" title="49">        total_valid_f1 <span class="op">+=</span> f1_score(rounded_preds, y_true,</a>
<a class="sourceLine" id="cb37-50" title="50">                                   average<span class="op">=</span><span class="st">&#39;weighted&#39;</span>,</a>
<a class="sourceLine" id="cb37-51" title="51">                                   labels<span class="op">=</span>np.unique(rounded_preds))</a>
<a class="sourceLine" id="cb37-52" title="52"></a>
<a class="sourceLine" id="cb37-53" title="53">        <span class="co"># calculate accuracy</span></a>
<a class="sourceLine" id="cb37-54" title="54">        total_valid_accuracy <span class="op">+=</span> accuracy_score(rounded_preds, y_true)</a>
<a class="sourceLine" id="cb37-55" title="55"></a>
<a class="sourceLine" id="cb37-56" title="56">        <span class="co"># calculate precision</span></a>
<a class="sourceLine" id="cb37-57" title="57">        total_valid_precision <span class="op">+=</span> precision_score(rounded_preds, y_true,</a>
<a class="sourceLine" id="cb37-58" title="58">                                                 average<span class="op">=</span><span class="st">&#39;weighted&#39;</span>,</a>
<a class="sourceLine" id="cb37-59" title="59">                                                 labels<span class="op">=</span>np.unique(rounded_preds))</a>
<a class="sourceLine" id="cb37-60" title="60"></a>
<a class="sourceLine" id="cb37-61" title="61">        <span class="co"># calculate recall</span></a>
<a class="sourceLine" id="cb37-62" title="62">        total_valid_recall <span class="op">+=</span> recall_score(rounded_preds, y_true,</a>
<a class="sourceLine" id="cb37-63" title="63">                                                 average<span class="op">=</span><span class="st">&#39;weighted&#39;</span>,</a>
<a class="sourceLine" id="cb37-64" title="64">                                                 labels<span class="op">=</span>np.unique(rounded_preds))</a>
<a class="sourceLine" id="cb37-65" title="65"></a>
<a class="sourceLine" id="cb37-66" title="66">    <span class="co"># report final accuracy of validation run</span></a>
<a class="sourceLine" id="cb37-67" title="67">    avg_accuracy <span class="op">=</span> total_valid_accuracy <span class="op">/</span> <span class="bu">len</span>(dataloader)</a>
<a class="sourceLine" id="cb37-68" title="68"></a>
<a class="sourceLine" id="cb37-69" title="69">    <span class="co"># report final f1 of validation run</span></a>
<a class="sourceLine" id="cb37-70" title="70">    <span class="kw">global</span> avg_val_f1</a>
<a class="sourceLine" id="cb37-71" title="71">    avg_val_f1 <span class="op">=</span> total_valid_f1 <span class="op">/</span> <span class="bu">len</span>(dataloader)</a>
<a class="sourceLine" id="cb37-72" title="72"></a>
<a class="sourceLine" id="cb37-73" title="73">    <span class="co"># report final f1 of validation run</span></a>
<a class="sourceLine" id="cb37-74" title="74">    avg_precision <span class="op">=</span> total_valid_precision <span class="op">/</span> <span class="bu">len</span>(dataloader)</a>
<a class="sourceLine" id="cb37-75" title="75"></a>
<a class="sourceLine" id="cb37-76" title="76">    <span class="co"># report final f1 of validation run</span></a>
<a class="sourceLine" id="cb37-77" title="77">    avg_recall <span class="op">=</span> total_valid_recall <span class="op">/</span> <span class="bu">len</span>(dataloader)</a>
<a class="sourceLine" id="cb37-78" title="78"></a>
<a class="sourceLine" id="cb37-79" title="79">    <span class="co"># calculate the average loss over all of the batches.</span></a>
<a class="sourceLine" id="cb37-80" title="80">    avg_val_loss <span class="op">=</span> total_valid_loss <span class="op">/</span> <span class="bu">len</span>(dataloader)</a>
<a class="sourceLine" id="cb37-81" title="81"></a>
<a class="sourceLine" id="cb37-82" title="82">    <span class="co"># Record all statistics from this epoch.</span></a>
<a class="sourceLine" id="cb37-83" title="83">    valid_stats.append(</a>
<a class="sourceLine" id="cb37-84" title="84">        {</a>
<a class="sourceLine" id="cb37-85" title="85">            <span class="st">&#39;Val Loss&#39;</span>: avg_val_loss,</a>
<a class="sourceLine" id="cb37-86" title="86">            <span class="st">&#39;Val Accur.&#39;</span>: avg_accuracy,</a>
<a class="sourceLine" id="cb37-87" title="87">            <span class="st">&#39;Val precision&#39;</span>: avg_precision,</a>
<a class="sourceLine" id="cb37-88" title="88">            <span class="st">&#39;Val recall&#39;</span>: avg_recall,</a>
<a class="sourceLine" id="cb37-89" title="89">            <span class="st">&#39;Val F1&#39;</span>: avg_val_f1</a>
<a class="sourceLine" id="cb37-90" title="90">        }</a>
<a class="sourceLine" id="cb37-91" title="91">    )</a>
<a class="sourceLine" id="cb37-92" title="92"></a>
<a class="sourceLine" id="cb37-93" title="93">    <span class="co"># capture end validation time</span></a>
<a class="sourceLine" id="cb37-94" title="94">    training_time <span class="op">=</span> format_time(time.time() <span class="op">-</span> total_t0)</a>
<a class="sourceLine" id="cb37-95" title="95"></a>
<a class="sourceLine" id="cb37-96" title="96">    <span class="co"># print result summaries</span></a>
<a class="sourceLine" id="cb37-97" title="97">    <span class="bu">print</span>(<span class="st">&quot;&quot;</span>)</a>
<a class="sourceLine" id="cb37-98" title="98">    <span class="bu">print</span>(<span class="st">&quot;summary results&quot;</span>)</a>
<a class="sourceLine" id="cb37-99" title="99">    <span class="bu">print</span>(<span class="st">&quot;epoch | val loss | val f1 | val time&quot;</span>)</a>
<a class="sourceLine" id="cb37-100" title="100">    <span class="bu">print</span>(<span class="ss">f&quot;</span><span class="sc">{</span>epoch<span class="op">+</span><span class="dv">1</span><span class="sc">:5d}</span><span class="ss"> | </span><span class="sc">{</span>avg_val_loss<span class="sc">:.5f}</span><span class="ss"> | </span><span class="sc">{</span>avg_val_f1<span class="sc">:.5f}</span><span class="ss"> | </span><span class="sc">{</span>training_time<span class="sc">:}</span><span class="ss">&quot;</span>)</a>
<a class="sourceLine" id="cb37-101" title="101"></a>
<a class="sourceLine" id="cb37-102" title="102">    <span class="cf">return</span> valid_stats</a></code></pre></div>
<div class="sourceCode" id="cb38"><pre class="sourceCode python"><code class="sourceCode python"><a class="sourceLine" id="cb38-1" title="1"><span class="kw">def</span> testing(model, dataloader, criterion):</a>
<a class="sourceLine" id="cb38-2" title="2"></a>
<a class="sourceLine" id="cb38-3" title="3">    <span class="bu">print</span>(<span class="st">&quot;&quot;</span>)</a>
<a class="sourceLine" id="cb38-4" title="4">    <span class="bu">print</span>(<span class="st">&quot;Running Testing...&quot;</span>)</a>
<a class="sourceLine" id="cb38-5" title="5"></a>
<a class="sourceLine" id="cb38-6" title="6">    <span class="co"># put the model in evaluation mode</span></a>
<a class="sourceLine" id="cb38-7" title="7">    model.<span class="bu">eval</span>()</a>
<a class="sourceLine" id="cb38-8" title="8"></a>
<a class="sourceLine" id="cb38-9" title="9">    <span class="co"># track variables</span></a>
<a class="sourceLine" id="cb38-10" title="10">    total_test_accuracy <span class="op">=</span> <span class="dv">0</span></a>
<a class="sourceLine" id="cb38-11" title="11">    total_test_loss <span class="op">=</span> <span class="dv">0</span></a>
<a class="sourceLine" id="cb38-12" title="12">    total_test_f1 <span class="op">=</span> <span class="dv">0</span></a>
<a class="sourceLine" id="cb38-13" title="13">    total_test_recall <span class="op">=</span> <span class="dv">0</span></a>
<a class="sourceLine" id="cb38-14" title="14">    total_test_precision <span class="op">=</span> <span class="dv">0</span></a>
<a class="sourceLine" id="cb38-15" title="15"></a>
<a class="sourceLine" id="cb38-16" title="16">    <span class="co"># evaluate data for one epoch</span></a>
<a class="sourceLine" id="cb38-17" title="17">    <span class="cf">for</span> step, batch <span class="kw">in</span> <span class="bu">enumerate</span>(dataloader):</a>
<a class="sourceLine" id="cb38-18" title="18">        <span class="co"># progress update every 40 batches.</span></a>
<a class="sourceLine" id="cb38-19" title="19">        <span class="cf">if</span> step <span class="op">%</span> <span class="dv">40</span> <span class="op">==</span> <span class="dv">0</span> <span class="kw">and</span> <span class="kw">not</span> step <span class="op">==</span> <span class="dv">0</span>:</a>
<a class="sourceLine" id="cb38-20" title="20"></a>
<a class="sourceLine" id="cb38-21" title="21">            <span class="co"># Report progress.</span></a>
<a class="sourceLine" id="cb38-22" title="22">            <span class="bu">print</span>(<span class="st">&#39;  Batch {:&gt;5,}  of  {:&gt;5,}.&#39;</span>.<span class="bu">format</span>(step, <span class="bu">len</span>(dataloader)))</a>
<a class="sourceLine" id="cb38-23" title="23"></a>
<a class="sourceLine" id="cb38-24" title="24">        <span class="co"># unpack batch from dataloader</span></a>
<a class="sourceLine" id="cb38-25" title="25">        b_input_ids <span class="op">=</span> batch[<span class="dv">0</span>].cuda()</a>
<a class="sourceLine" id="cb38-26" title="26">        b_labels <span class="op">=</span> batch[<span class="dv">1</span>].cuda().<span class="bu">type</span>(torch.cuda.FloatTensor)</a>
<a class="sourceLine" id="cb38-27" title="27"></a>
<a class="sourceLine" id="cb38-28" title="28">        <span class="co"># tell pytorch not to bother calculating gradients</span></a>
<a class="sourceLine" id="cb38-29" title="29">        <span class="co"># only necessary for training</span></a>
<a class="sourceLine" id="cb38-30" title="30">        <span class="cf">with</span> torch.no_grad():</a>
<a class="sourceLine" id="cb38-31" title="31"></a>
<a class="sourceLine" id="cb38-32" title="32">            <span class="co"># forward propagation (evaluate model on training batch)</span></a>
<a class="sourceLine" id="cb38-33" title="33">            logits <span class="op">=</span> model(b_input_ids)</a>
<a class="sourceLine" id="cb38-34" title="34"></a>
<a class="sourceLine" id="cb38-35" title="35">            <span class="co"># calculate BCEWithLogitsLoss</span></a>
<a class="sourceLine" id="cb38-36" title="36">            loss <span class="op">=</span> criterion(logits, b_labels)</a>
<a class="sourceLine" id="cb38-37" title="37"></a>
<a class="sourceLine" id="cb38-38" title="38">            <span class="co"># accumulate validation loss</span></a>
<a class="sourceLine" id="cb38-39" title="39">            total_test_loss <span class="op">+=</span> loss.item()</a>
<a class="sourceLine" id="cb38-40" title="40"></a>
<a class="sourceLine" id="cb38-41" title="41">            <span class="co"># generate predictions</span></a>
<a class="sourceLine" id="cb38-42" title="42">            rounded_preds <span class="op">=</span> torch.<span class="bu">round</span>(torch.sigmoid(logits))</a>
<a class="sourceLine" id="cb38-43" title="43"></a>
<a class="sourceLine" id="cb38-44" title="44">            <span class="co"># move logits and labels to CPU</span></a>
<a class="sourceLine" id="cb38-45" title="45">            rounded_preds <span class="op">=</span> rounded_preds.detach().cpu().numpy()</a>
<a class="sourceLine" id="cb38-46" title="46">            y_true <span class="op">=</span> b_labels.detach().cpu().numpy()</a>
<a class="sourceLine" id="cb38-47" title="47"></a>
<a class="sourceLine" id="cb38-48" title="48">            <span class="co"># calculate f1</span></a>
<a class="sourceLine" id="cb38-49" title="49">            total_test_f1 <span class="op">+=</span> f1_score(rounded_preds, y_true,</a>
<a class="sourceLine" id="cb38-50" title="50">                                       average<span class="op">=</span><span class="st">&#39;weighted&#39;</span>,</a>
<a class="sourceLine" id="cb38-51" title="51">                                       labels<span class="op">=</span>np.unique(rounded_preds))</a>
<a class="sourceLine" id="cb38-52" title="52"></a>
<a class="sourceLine" id="cb38-53" title="53">            <span class="co"># calculate accuracy</span></a>
<a class="sourceLine" id="cb38-54" title="54">            total_test_accuracy <span class="op">+=</span> accuracy_score(rounded_preds, y_true)</a>
<a class="sourceLine" id="cb38-55" title="55"></a>
<a class="sourceLine" id="cb38-56" title="56">            <span class="co"># calculate precision</span></a>
<a class="sourceLine" id="cb38-57" title="57">            total_test_precision <span class="op">+=</span> precision_score(rounded_preds, y_true,</a>
<a class="sourceLine" id="cb38-58" title="58">                                                     average<span class="op">=</span><span class="st">&#39;weighted&#39;</span>,</a>
<a class="sourceLine" id="cb38-59" title="59">                                                     labels<span class="op">=</span>np.unique(rounded_preds))</a>
<a class="sourceLine" id="cb38-60" title="60"></a>
<a class="sourceLine" id="cb38-61" title="61">            <span class="co"># calculate recall</span></a>
<a class="sourceLine" id="cb38-62" title="62">            total_test_recall <span class="op">+=</span> recall_score(rounded_preds, y_true,</a>
<a class="sourceLine" id="cb38-63" title="63">                                                     average<span class="op">=</span><span class="st">&#39;weighted&#39;</span>,</a>
<a class="sourceLine" id="cb38-64" title="64">                                                     labels<span class="op">=</span>np.unique(rounded_preds))</a>
<a class="sourceLine" id="cb38-65" title="65"></a>
<a class="sourceLine" id="cb38-66" title="66">    <span class="co"># report final accuracy of validation run</span></a>
<a class="sourceLine" id="cb38-67" title="67">    avg_accuracy <span class="op">=</span> total_test_accuracy <span class="op">/</span> <span class="bu">len</span>(dataloader)</a>
<a class="sourceLine" id="cb38-68" title="68"></a>
<a class="sourceLine" id="cb38-69" title="69">    <span class="co"># report final f1 of validation run</span></a>
<a class="sourceLine" id="cb38-70" title="70">    avg_test_f1 <span class="op">=</span> total_test_f1 <span class="op">/</span> <span class="bu">len</span>(dataloader)</a>
<a class="sourceLine" id="cb38-71" title="71"></a>
<a class="sourceLine" id="cb38-72" title="72">    <span class="co"># report final f1 of validation run</span></a>
<a class="sourceLine" id="cb38-73" title="73">    avg_precision <span class="op">=</span> total_test_precision <span class="op">/</span> <span class="bu">len</span>(dataloader)</a>
<a class="sourceLine" id="cb38-74" title="74"></a>
<a class="sourceLine" id="cb38-75" title="75">    <span class="co"># report final f1 of validation run</span></a>
<a class="sourceLine" id="cb38-76" title="76">    avg_recall <span class="op">=</span> total_test_recall <span class="op">/</span> <span class="bu">len</span>(dataloader)</a>
<a class="sourceLine" id="cb38-77" title="77"></a>
<a class="sourceLine" id="cb38-78" title="78">    <span class="co"># calculate the average loss over all of the batches.</span></a>
<a class="sourceLine" id="cb38-79" title="79">    avg_test_loss <span class="op">=</span> total_test_loss <span class="op">/</span> <span class="bu">len</span>(dataloader)</a>
<a class="sourceLine" id="cb38-80" title="80"></a>
<a class="sourceLine" id="cb38-81" title="81">    <span class="co"># Record all statistics from this epoch.</span></a>
<a class="sourceLine" id="cb38-82" title="82">    test_stats.append(</a>
<a class="sourceLine" id="cb38-83" title="83">        {</a>
<a class="sourceLine" id="cb38-84" title="84">            <span class="st">&#39;Test Loss&#39;</span>: avg_test_loss,</a>
<a class="sourceLine" id="cb38-85" title="85">            <span class="st">&#39;Test Accur.&#39;</span>: avg_accuracy,</a>
<a class="sourceLine" id="cb38-86" title="86">            <span class="st">&#39;Test precision&#39;</span>: avg_precision,</a>
<a class="sourceLine" id="cb38-87" title="87">            <span class="st">&#39;Test recall&#39;</span>: avg_recall,</a>
<a class="sourceLine" id="cb38-88" title="88">            <span class="st">&#39;Test F1&#39;</span>: avg_test_f1</a>
<a class="sourceLine" id="cb38-89" title="89">        }</a>
<a class="sourceLine" id="cb38-90" title="90">    )</a>
<a class="sourceLine" id="cb38-91" title="91">    <span class="cf">return</span> test_stats</a></code></pre></div>
<p>In order to use our CNN, we need to specify a config class that sets a number of hyperparameters that the class is expecting.</p>
<div class="sourceCode" id="cb39"><pre class="sourceCode python"><code class="sourceCode python"><a class="sourceLine" id="cb39-1" title="1"><span class="co"># instantiate model config -- set ex-post from optuna search</span></a>
<a class="sourceLine" id="cb39-2" title="2"><span class="kw">class</span> config:</a>
<a class="sourceLine" id="cb39-3" title="3">    <span class="kw">def</span> <span class="fu">__init__</span>(<span class="va">self</span>):</a>
<a class="sourceLine" id="cb39-4" title="4">        config.pre_embed <span class="op">=</span> embeddings_tensor  <span class="co"># GloVe vectors</span></a>
<a class="sourceLine" id="cb39-5" title="5">        config.mode <span class="op">=</span> <span class="st">&#39;static&#39;</span>  <span class="co"># dont train embedding</span></a>
<a class="sourceLine" id="cb39-6" title="6">        config.num_classes <span class="op">=</span> <span class="dv">1</span>  <span class="co"># binary</span></a>
<a class="sourceLine" id="cb39-7" title="7">        config.output_channel <span class="op">=</span> <span class="dv">1450</span>  <span class="co"># number of kernels</span></a>
<a class="sourceLine" id="cb39-8" title="8">        config.embedding_dim <span class="op">=</span> <span class="dv">201</span>  <span class="co"># GloVe embed dimension (202)</span></a>
<a class="sourceLine" id="cb39-9" title="9">        config.vocab_size <span class="op">=</span> <span class="bu">len</span>(vocab)<span class="op">+</span><span class="dv">2</span>  <span class="co"># vocab size of corpus plus unknown/padding</span></a>
<a class="sourceLine" id="cb39-10" title="10">        config.dropout <span class="op">=</span> <span class="fl">0.1</span>  <span class="co"># dropout value</span></a>
<a class="sourceLine" id="cb39-11" title="11">        config.padding_idx <span class="op">=</span> <span class="dv">400001</span>  <span class="co"># padding token index</span></a>
<a class="sourceLine" id="cb39-12" title="12">        <span class="cf">return</span> <span class="va">None</span></a>
<a class="sourceLine" id="cb39-13" title="13"></a>
<a class="sourceLine" id="cb39-14" title="14"><span class="co"># create config</span></a>
<a class="sourceLine" id="cb39-15" title="15">config1 <span class="op">=</span> config()</a>
<a class="sourceLine" id="cb39-16" title="16"></a>
<a class="sourceLine" id="cb39-17" title="17"><span class="co"># instantiate model - attach to GPU</span></a>
<a class="sourceLine" id="cb39-18" title="18">model <span class="op">=</span> KimCNN(config1).cuda()</a></code></pre></div>
<p>Now we are almost ready to train. A few other preparatory objects are created like the loss criteria, epochs, the optimizer, and our optimizer scheduler.</p>
<div class="sourceCode" id="cb40"><pre class="sourceCode python"><code class="sourceCode python"><a class="sourceLine" id="cb40-1" title="1"><span class="co"># set loss</span></a>
<a class="sourceLine" id="cb40-2" title="2">criterion <span class="op">=</span> nn.BCEWithLogitsLoss()</a>
<a class="sourceLine" id="cb40-3" title="3"></a>
<a class="sourceLine" id="cb40-4" title="4"><span class="co"># set number of epochs</span></a>
<a class="sourceLine" id="cb40-5" title="5">epochs <span class="op">=</span> <span class="dv">4</span></a>
<a class="sourceLine" id="cb40-6" title="6"></a>
<a class="sourceLine" id="cb40-7" title="7"><span class="co"># set optimizer</span></a>
<a class="sourceLine" id="cb40-8" title="8">optimizer <span class="op">=</span> torch.optim.Adam(model.parameters(), lr<span class="op">=</span><span class="fl">0.000147</span>)</a>
<a class="sourceLine" id="cb40-9" title="9"></a>
<a class="sourceLine" id="cb40-10" title="10"><span class="co"># set LR scheduler</span></a>
<a class="sourceLine" id="cb40-11" title="11">total_steps <span class="op">=</span> <span class="bu">len</span>(train_dataloader) <span class="op">*</span> epochs</a>
<a class="sourceLine" id="cb40-12" title="12">scheduler <span class="op">=</span> get_linear_schedule_with_warmup(optimizer,</a>
<a class="sourceLine" id="cb40-13" title="13">                                            num_warmup_steps<span class="op">=</span><span class="dv">0</span>,</a>
<a class="sourceLine" id="cb40-14" title="14">                                            num_training_steps<span class="op">=</span>total_steps)</a></code></pre></div>
<p>Finally we are ready to train. Two containers are created to store the results of each training and validation epoch</p>
<div class="sourceCode" id="cb41"><pre class="sourceCode python"><code class="sourceCode python"><a class="sourceLine" id="cb41-1" title="1"><span class="co"># create training result storage</span></a>
<a class="sourceLine" id="cb41-2" title="2">training_stats <span class="op">=</span> []</a>
<a class="sourceLine" id="cb41-3" title="3">valid_stats <span class="op">=</span> []</a>
<a class="sourceLine" id="cb41-4" title="4">best_valid_loss <span class="op">=</span> <span class="bu">float</span>(<span class="st">&#39;inf&#39;</span>)</a>
<a class="sourceLine" id="cb41-5" title="5"></a>
<a class="sourceLine" id="cb41-6" title="6"><span class="co"># for each epoch</span></a>
<a class="sourceLine" id="cb41-7" title="7"><span class="cf">for</span> epoch <span class="kw">in</span> <span class="bu">range</span>(epochs):</a>
<a class="sourceLine" id="cb41-8" title="8">    <span class="co"># train</span></a>
<a class="sourceLine" id="cb41-9" title="9">    train(model, train_dataloader, optimizer, criterion)</a>
<a class="sourceLine" id="cb41-10" title="10">    <span class="co"># validate</span></a>
<a class="sourceLine" id="cb41-11" title="11">    validating(model, valid_dataloader, criterion)</a>
<a class="sourceLine" id="cb41-12" title="12">    <span class="co"># check validation loss</span></a>
<a class="sourceLine" id="cb41-13" title="13">    <span class="cf">if</span> valid_stats[epoch][<span class="st">&#39;Val Loss&#39;</span>] <span class="op">&lt;</span> best_valid_loss:</a>
<a class="sourceLine" id="cb41-14" title="14">        best_valid_loss <span class="op">=</span> valid_stats[epoch][<span class="st">&#39;Val Loss&#39;</span>]</a>
<a class="sourceLine" id="cb41-15" title="15">        <span class="co"># save best model for use later</span></a>
<a class="sourceLine" id="cb41-16" title="16">        torch.save(model.state_dict(), <span class="st">&#39;cnn-model1.pt&#39;</span>)</a></code></pre></div>
<pre><code>## 
## ======== Epoch 1 / 4 ========
## Training...
##   Batch    40  of    125.
##   Batch    80  of    125.
##   Batch   120  of    125.
## 
## summary results
## epoch | trn loss | trn f1 | trn time 
##     1 | 0.34258 | 0.84309 | 0:00:33
## [{&#39;Train Loss&#39;: 0.34257625544071196, &#39;Train F1&#39;: 0.8430875575961214}]
## 
## Running Validation...
## 
## summary results
## epoch | val loss | val f1 | val time
##     1 | 0.29642 | 0.86360 | 0:00:02
## [{&#39;Val Loss&#39;: 0.2964185804128647, &#39;Val Accur.&#39;: 0.8666666666666667, &#39;Val precision&#39;: 0.8682571060895364, &#39;Val recall&#39;: 0.8666666666666667, &#39;Val F1&#39;: 0.8635968856043325}]
## 
## ======== Epoch 2 / 4 ========
## Training...
##   Batch    40  of    125.
##   Batch    80  of    125.
##   Batch   120  of    125.
## 
## summary results
## epoch | trn loss | trn f1 | trn time 
##     2 | 0.26690 | 0.88535 | 0:00:32
## [{&#39;Train Loss&#39;: 0.34257625544071196, &#39;Train F1&#39;: 0.8430875575961214}, {&#39;Train Loss&#39;: 0.26690465259552004, &#39;Train F1&#39;: 0.8853466192255715}]
## 
## Running Validation...
## 
## summary results
## epoch | val loss | val f1 | val time
##     2 | 0.26909 | 0.88255 | 0:00:02
## [{&#39;Val Loss&#39;: 0.2964185804128647, &#39;Val Accur.&#39;: 0.8666666666666667, &#39;Val precision&#39;: 0.8682571060895364, &#39;Val recall&#39;: 0.8666666666666667, &#39;Val F1&#39;: 0.8635968856043325}, {&#39;Val Loss&#39;: 0.2690899670124054, &#39;Val Accur.&#39;: 0.8822916666666667, &#39;Val precision&#39;: 0.8877307486684166, &#39;Val recall&#39;: 0.8822916666666667, &#39;Val F1&#39;: 0.8825540483510671}]
## 
## ======== Epoch 3 / 4 ========
## Training...
##   Batch    40  of    125.
##   Batch    80  of    125.
##   Batch   120  of    125.
## 
## summary results
## epoch | trn loss | trn f1 | trn time 
##     3 | 0.23255 | 0.90257 | 0:00:34
## [{&#39;Train Loss&#39;: 0.34257625544071196, &#39;Train F1&#39;: 0.8430875575961214}, {&#39;Train Loss&#39;: 0.26690465259552004, &#39;Train F1&#39;: 0.8853466192255715}, {&#39;Train Loss&#39;: 0.23254692482948303, &#39;Train F1&#39;: 0.9025737543822568}]
## 
## Running Validation...
## 
## summary results
## epoch | val loss | val f1 | val time
##     3 | 0.26009 | 0.88351 | 0:00:02
## [{&#39;Val Loss&#39;: 0.2964185804128647, &#39;Val Accur.&#39;: 0.8666666666666667, &#39;Val precision&#39;: 0.8682571060895364, &#39;Val recall&#39;: 0.8666666666666667, &#39;Val F1&#39;: 0.8635968856043325}, {&#39;Val Loss&#39;: 0.2690899670124054, &#39;Val Accur.&#39;: 0.8822916666666667, &#39;Val precision&#39;: 0.8877307486684166, &#39;Val recall&#39;: 0.8822916666666667, &#39;Val F1&#39;: 0.8825540483510671}, {&#39;Val Loss&#39;: 0.26008678376674654, &#39;Val Accur.&#39;: 0.884375, &#39;Val precision&#39;: 0.8876622447516984, &#39;Val recall&#39;: 0.884375, &#39;Val F1&#39;: 0.8835106182265878}]
## 
## ======== Epoch 4 / 4 ========
## Training...
##   Batch    40  of    125.
##   Batch    80  of    125.
##   Batch   120  of    125.
## 
## summary results
## epoch | trn loss | trn f1 | trn time 
##     4 | 0.21405 | 0.91920 | 0:00:33
## [{&#39;Train Loss&#39;: 0.34257625544071196, &#39;Train F1&#39;: 0.8430875575961214}, {&#39;Train Loss&#39;: 0.26690465259552004, &#39;Train F1&#39;: 0.8853466192255715}, {&#39;Train Loss&#39;: 0.23254692482948303, &#39;Train F1&#39;: 0.9025737543822568}, {&#39;Train Loss&#39;: 0.21405383133888245, &#39;Train F1&#39;: 0.9191950351867836}]
## 
## Running Validation...
## 
## summary results
## epoch | val loss | val f1 | val time
##     4 | 0.25764 | 0.88874 | 0:00:02
## [{&#39;Val Loss&#39;: 0.2964185804128647, &#39;Val Accur.&#39;: 0.8666666666666667, &#39;Val precision&#39;: 0.8682571060895364, &#39;Val recall&#39;: 0.8666666666666667, &#39;Val F1&#39;: 0.8635968856043325}, {&#39;Val Loss&#39;: 0.2690899670124054, &#39;Val Accur.&#39;: 0.8822916666666667, &#39;Val precision&#39;: 0.8877307486684166, &#39;Val recall&#39;: 0.8822916666666667, &#39;Val F1&#39;: 0.8825540483510671}, {&#39;Val Loss&#39;: 0.26008678376674654, &#39;Val Accur.&#39;: 0.884375, &#39;Val precision&#39;: 0.8876622447516984, &#39;Val recall&#39;: 0.884375, &#39;Val F1&#39;: 0.8835106182265878}, {&#39;Val Loss&#39;: 0.2576443016529083, &#39;Val Accur.&#39;: 0.8885416666666667, &#39;Val precision&#39;: 0.8933767399199204, &#39;Val recall&#39;: 0.8885416666666667, &#39;Val F1&#39;: 0.8887403379573173}]</code></pre>
<p>After training, we organize the results nicely in <code>pandas</code>.</p>
<div class="sourceCode" id="cb43"><pre class="sourceCode python"><code class="sourceCode python"><a class="sourceLine" id="cb43-1" title="1"><span class="co"># organize results</span></a>
<a class="sourceLine" id="cb43-2" title="2">pd.set_option(<span class="st">&#39;precision&#39;</span>, <span class="dv">3</span>)</a>
<a class="sourceLine" id="cb43-3" title="3">df_train_stats <span class="op">=</span> pd.DataFrame(data<span class="op">=</span>training_stats)</a>
<a class="sourceLine" id="cb43-4" title="4">df_valid_stats <span class="op">=</span> pd.DataFrame(data<span class="op">=</span>valid_stats)</a>
<a class="sourceLine" id="cb43-5" title="5">df_stats <span class="op">=</span> pd.concat([df_train_stats, df_valid_stats], axis<span class="op">=</span><span class="dv">1</span>)</a>
<a class="sourceLine" id="cb43-6" title="6">df_stats.insert(<span class="dv">0</span>, <span class="st">&#39;Epoch&#39;</span>, <span class="bu">range</span>(<span class="dv">1</span>, <span class="bu">len</span>(df_stats)<span class="op">+</span><span class="dv">1</span>))</a>
<a class="sourceLine" id="cb43-7" title="7">df_stats <span class="op">=</span> df_stats.set_index(<span class="st">&#39;Epoch&#39;</span>)</a>
<a class="sourceLine" id="cb43-8" title="8">df_stats</a></code></pre></div>
<pre><code>##        Train Loss  Train F1  Val Loss  ...  Val precision  Val recall  Val F1
## Epoch                                  ...                                   
## 1           0.343     0.843     0.296  ...          0.868       0.867   0.864
## 2           0.267     0.885     0.269  ...          0.888       0.882   0.883
## 3           0.233     0.903     0.260  ...          0.888       0.884   0.884
## 4           0.214     0.919     0.258  ...          0.893       0.889   0.889
## 
## [4 rows x 7 columns]</code></pre>
<p>Then we plot our results like so:</p>
<div class="sourceCode" id="cb45"><pre class="sourceCode python"><code class="sourceCode python"><a class="sourceLine" id="cb45-1" title="1"><span class="kw">def</span> plot_results(df):</a>
<a class="sourceLine" id="cb45-2" title="2">    <span class="co"># styling from seaborn.</span></a>
<a class="sourceLine" id="cb45-3" title="3">    sns.<span class="bu">set</span>(style<span class="op">=</span><span class="st">&#39;darkgrid&#39;</span>)</a>
<a class="sourceLine" id="cb45-4" title="4">    <span class="co"># uncrease the plot size and font size.</span></a>
<a class="sourceLine" id="cb45-5" title="5">    sns.<span class="bu">set</span>(font_scale<span class="op">=</span><span class="fl">1.5</span>)</a>
<a class="sourceLine" id="cb45-6" title="6">    plt.rcParams[<span class="st">&quot;figure.figsize&quot;</span>] <span class="op">=</span> (<span class="dv">12</span>,<span class="dv">6</span>)</a>
<a class="sourceLine" id="cb45-7" title="7"></a>
<a class="sourceLine" id="cb45-8" title="8">    <span class="co"># plot the learning curve.</span></a>
<a class="sourceLine" id="cb45-9" title="9">    plt.plot(df_stats[<span class="st">&#39;Train Loss&#39;</span>], <span class="st">&#39;b-o&#39;</span>, label<span class="op">=</span><span class="st">&quot;Training&quot;</span>)</a>
<a class="sourceLine" id="cb45-10" title="10">    plt.plot(df_stats[<span class="st">&#39;Val Loss&#39;</span>], <span class="st">&#39;g-o&#39;</span>, label<span class="op">=</span><span class="st">&quot;Validation&quot;</span>)</a>
<a class="sourceLine" id="cb45-11" title="11"></a>
<a class="sourceLine" id="cb45-12" title="12">    <span class="co"># Label the plot.</span></a>
<a class="sourceLine" id="cb45-13" title="13">    plt.title(<span class="st">&quot;Training &amp; Validation Loss&quot;</span>)</a>
<a class="sourceLine" id="cb45-14" title="14">    plt.xlabel(<span class="st">&quot;Epoch&quot;</span>)</a>
<a class="sourceLine" id="cb45-15" title="15">    plt.ylabel(<span class="st">&quot;Loss&quot;</span>)</a>
<a class="sourceLine" id="cb45-16" title="16">    plt.legend()</a>
<a class="sourceLine" id="cb45-17" title="17">    plt.xticks([<span class="dv">1</span>, <span class="dv">2</span>, <span class="dv">3</span>, <span class="dv">4</span>])</a>
<a class="sourceLine" id="cb45-18" title="18">    <span class="cf">return</span> plt.show()</a>
<a class="sourceLine" id="cb45-19" title="19"></a>
<a class="sourceLine" id="cb45-20" title="20"></a>
<a class="sourceLine" id="cb45-21" title="21">plot_results(df_stats)</a></code></pre></div>
<div class="figure">
<img src="data:image/png;base64,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" alt="Training Results" style="width:75.0%" />
<p class="caption">Training Results</p>
</div>
<p>And lastly run our final test:</p>
<div class="sourceCode" id="cb46"><pre class="sourceCode python"><code class="sourceCode python"><a class="sourceLine" id="cb46-1" title="1"><span class="co"># test the model</span></a>
<a class="sourceLine" id="cb46-2" title="2">test_stats <span class="op">=</span> []</a>
<a class="sourceLine" id="cb46-3" title="3">model.load_state_dict(torch.load(<span class="st">&#39;cnn-model1.pt&#39;</span>))</a></code></pre></div>
<pre><code>## &lt;All keys matched successfully&gt;</code></pre>
<div class="sourceCode" id="cb48"><pre class="sourceCode python"><code class="sourceCode python"><a class="sourceLine" id="cb48-1" title="1">testing(model, test_dataloader, criterion)</a></code></pre></div>
<pre><code>## 
## Running Testing...
## [{&#39;Test Loss&#39;: 0.2702034145593643, &#39;Test Accur.&#39;: 0.8729166666666667, &#39;Test precision&#39;: 0.8767763702811966, &#39;Test recall&#39;: 0.8729166666666667, &#39;Test F1&#39;: 0.8730302599153013}]</code></pre>
<div class="sourceCode" id="cb50"><pre class="sourceCode python"><code class="sourceCode python"><a class="sourceLine" id="cb50-1" title="1">df_test_stats <span class="op">=</span> pd.DataFrame(data<span class="op">=</span>test_stats)</a>
<a class="sourceLine" id="cb50-2" title="2">df_test_stats</a></code></pre></div>
<pre><code>##    Test Loss  Test Accur.  Test precision  Test recall  Test F1
## 0       0.27        0.873           0.877        0.873    0.873</code></pre>
<p>Pretty good results for a novel data set made from scratch with an “outdated” model.</p>
</div>
<div id="cnn-inference" class="section level1">
<h1><span class="header-section-number">4</span> CNN: Inference</h1>
<p>There are some other tasks that might want to do like inference which is using what we know to predict what we do not. So let’s say that we have two new messages but no labels (see below). We can tokenize these strings like all of our other data and generate on-the-fly predictions about their inferred label.</p>
<div class="sourceCode" id="cb52"><pre class="sourceCode python"><code class="sourceCode python"><a class="sourceLine" id="cb52-1" title="1"><span class="co"># inference</span></a>
<a class="sourceLine" id="cb52-2" title="2"><span class="kw">def</span> infer_class(model, string_df, min_len<span class="op">=</span>percentile_95):</a>
<a class="sourceLine" id="cb52-3" title="3">    <span class="co"># tokenize the string into GloVe</span></a>
<a class="sourceLine" id="cb52-4" title="4">    no_matches, glove_tokenized_data <span class="op">=</span> text_to_GloVe_tokens(string_df, embeddings_dictionary)</a>
<a class="sourceLine" id="cb52-5" title="5">    <span class="co"># check length</span></a>
<a class="sourceLine" id="cb52-6" title="6">    <span class="cf">if</span> <span class="bu">len</span>(glove_tokenized_data[<span class="dv">0</span>]) <span class="op">&lt;</span> min_len:</a>
<a class="sourceLine" id="cb52-7" title="7">        glove_tokenized_data <span class="op">=</span> pad_GloVe(glove_tokenized_data, percentile_95)</a>
<a class="sourceLine" id="cb52-8" title="8">    tensor <span class="op">=</span> torch.LongTensor(glove_tokenized_data[<span class="dv">0</span>]).cuda()</a>
<a class="sourceLine" id="cb52-9" title="9">    tensor <span class="op">=</span> tensor.unsqueeze(<span class="dv">0</span>)</a>
<a class="sourceLine" id="cb52-10" title="10">    logits <span class="op">=</span> model(tensor)</a>
<a class="sourceLine" id="cb52-11" title="11">    rounded_preds <span class="op">=</span> torch.<span class="bu">round</span>(torch.sigmoid(logits))</a>
<a class="sourceLine" id="cb52-12" title="12">    <span class="cf">return</span> <span class="bu">print</span>(rounded_preds.item())</a></code></pre></div>
<div class="sourceCode" id="cb53"><pre class="sourceCode python"><code class="sourceCode python"><a class="sourceLine" id="cb53-1" title="1">str_US <span class="op">=</span> [<span class="st">&#39;You will no longer be sent to an eternal war, President Donald Trump told a gathering marking the graduation of the US military academy. You will no longer fight in countries whose names are not known to most Americans. You will no longer be involved in the wars of the ancient nations. Clearly, Trump is referring to the long-running war in Afghanistan. The United States has been fighting the for the past two decades; it suffered a high number of casualties along with enormous financial losses. Many times, senior US officials have acknowledged that they cannot win the war in Afghanistan. Trump has told the truth, that his troops will no longer be involved in the wars of the ancient nations, because the never-ending war in Afghanistan has severely damaged America is reputation on the international level and caused the country extreme economic hardships. Recent surveys show that the support in the United States for this lost war has plummeted, and the people have now realized that the American leaders made false promises about this war. Nearly 20 years ago, the founder of the Islamic Emirate, the late Amir al- Mu aminin Mullah Mohammad Omar, warned the Americans to give up the intention of occupying Afghanistan.&#39;</span>]</a>
<a class="sourceLine" id="cb53-2" title="2"></a>
<a class="sourceLine" id="cb53-3" title="3">str_AF <span class="op">=</span> [<span class="st">&#39;On 15 June, the soldiers of the puppet regime came to carry out operations in Sheikhano area , Tagab District, Kapisa Province. The mujahideen retaliated severely: 17 offensive soldiers of the puppet were killed in the operation; many of their corpses are lying on the battlefield; and many others were wounded.&#39;</span>]</a>
<a class="sourceLine" id="cb53-4" title="4"></a>
<a class="sourceLine" id="cb53-5" title="5"></a>
<a class="sourceLine" id="cb53-6" title="6">temp_df_US <span class="op">=</span> pd.DataFrame({<span class="st">&#39;body&#39;</span>: str_US})</a>
<a class="sourceLine" id="cb53-7" title="7">temp_df_US <span class="op">=</span> clean_df(temp_df_US)</a>
<a class="sourceLine" id="cb53-8" title="8"><span class="bu">print</span>(infer_class(model, temp_df_US))  <span class="co"># 1 = US = Correct</span></a></code></pre></div>
<pre><code>## 1.0
## None</code></pre>
<div class="sourceCode" id="cb55"><pre class="sourceCode python"><code class="sourceCode python"><a class="sourceLine" id="cb55-1" title="1">temp_df_AF <span class="op">=</span> pd.DataFrame({<span class="st">&#39;body&#39;</span>: str_AF})</a>
<a class="sourceLine" id="cb55-2" title="2">temp_df_AF <span class="op">=</span> clean_df(temp_df_AF)</a>
<a class="sourceLine" id="cb55-3" title="3"><span class="bu">print</span>(infer_class(model, temp_df_AF))  <span class="co"># 0 = Kabul = Correct</span></a></code></pre></div>
<pre><code>## 0.0
## None</code></pre>
</div>
<div id="cnn-hyperband-and-asha-hyperparameter-search-with-optuna" class="section level1">
<h1><span class="header-section-number">5</span> CNN: Hyperband and ASHA Hyperparameter Search with Optuna</h1>
<p>The code below shows how we can use state-of-the-art pruning and search algorithms to improve our model’s performance through hyperparameter selection.</p>
<div class="sourceCode" id="cb57"><pre class="sourceCode python"><code class="sourceCode python"><a class="sourceLine" id="cb57-1" title="1"><span class="co"># optuna -- tune hyperparameters</span></a>
<a class="sourceLine" id="cb57-2" title="2">training_stats <span class="op">=</span> []</a>
<a class="sourceLine" id="cb57-3" title="3">valid_stats <span class="op">=</span> []</a>
<a class="sourceLine" id="cb57-4" title="4">epochs <span class="op">=</span> <span class="dv">5</span></a>
<a class="sourceLine" id="cb57-5" title="5"><span class="kw">def</span> objective(trial):</a>
<a class="sourceLine" id="cb57-6" title="6"></a>
<a class="sourceLine" id="cb57-7" title="7">    kernel_num <span class="op">=</span> trial.suggest_int(<span class="st">&#39;output_channel&#39;</span>, low<span class="op">=</span><span class="dv">600</span>, high<span class="op">=</span><span class="dv">1500</span>, step<span class="op">=</span><span class="dv">50</span>)</a>
<a class="sourceLine" id="cb57-8" title="8">    batch_size <span class="op">=</span> trial.suggest_int(<span class="st">&#39;batch_size&#39;</span>, low<span class="op">=</span><span class="dv">64</span>, high<span class="op">=</span><span class="dv">128</span>, step<span class="op">=</span><span class="dv">16</span>)</a>
<a class="sourceLine" id="cb57-9" title="9">    dropout_num <span class="op">=</span> trial.suggest_float(<span class="st">&#39;dropout&#39;</span>, low<span class="op">=</span><span class="fl">0.1</span>, high<span class="op">=</span><span class="fl">0.5</span>, step<span class="op">=</span><span class="fl">0.05</span>)</a>
<a class="sourceLine" id="cb57-10" title="10">    learning_rate <span class="op">=</span> trial.suggest_loguniform(<span class="st">&#39;lr&#39;</span>, <span class="fl">1e-4</span>, <span class="fl">1e-3</span>)</a>
<a class="sourceLine" id="cb57-11" title="11">    config1 <span class="op">=</span> config()</a>
<a class="sourceLine" id="cb57-12" title="12">    config1.output_channel <span class="op">=</span> kernel_num</a>
<a class="sourceLine" id="cb57-13" title="13">    config1.dropout <span class="op">=</span> dropout_num</a>
<a class="sourceLine" id="cb57-14" title="14"></a>
<a class="sourceLine" id="cb57-15" title="15">    <span class="co"># Generate the model.</span></a>
<a class="sourceLine" id="cb57-16" title="16">    train_dataloader <span class="op">=</span> data_loading(batch_size<span class="op">=</span>batch_size,</a>
<a class="sourceLine" id="cb57-17" title="17">                                    data_set<span class="op">=</span>train_dataset,</a>
<a class="sourceLine" id="cb57-18" title="18">                                    sampler<span class="op">=</span>train_sampler)</a>
<a class="sourceLine" id="cb57-19" title="19"></a>
<a class="sourceLine" id="cb57-20" title="20">    valid_dataloader <span class="op">=</span> data_loading(batch_size<span class="op">=</span>batch_size,</a>
<a class="sourceLine" id="cb57-21" title="21">                                    data_set<span class="op">=</span>val_dataset,</a>
<a class="sourceLine" id="cb57-22" title="22">                                    sampler<span class="op">=</span>val_sampler)</a>
<a class="sourceLine" id="cb57-23" title="23"></a>
<a class="sourceLine" id="cb57-24" title="24">    model <span class="op">=</span> KimCNN(config1).cuda()</a>
<a class="sourceLine" id="cb57-25" title="25">    optimizer <span class="op">=</span> torch.optim.Adam(model.parameters(), lr<span class="op">=</span>learning_rate)</a>
<a class="sourceLine" id="cb57-26" title="26">    criterion <span class="op">=</span> nn.BCEWithLogitsLoss()</a>
<a class="sourceLine" id="cb57-27" title="27"></a>
<a class="sourceLine" id="cb57-28" title="28">    <span class="co"># set LR scheduler</span></a>
<a class="sourceLine" id="cb57-29" title="29">    total_steps <span class="op">=</span> <span class="bu">len</span>(train_dataloader) <span class="op">*</span> epochs</a>
<a class="sourceLine" id="cb57-30" title="30">    <span class="kw">global</span> scheduler</a>
<a class="sourceLine" id="cb57-31" title="31">    scheduler <span class="op">=</span> get_linear_schedule_with_warmup(optimizer,</a>
<a class="sourceLine" id="cb57-32" title="32">                                                num_warmup_steps<span class="op">=</span><span class="dv">0</span>,</a>
<a class="sourceLine" id="cb57-33" title="33">                                                num_training_steps<span class="op">=</span>total_steps)</a>
<a class="sourceLine" id="cb57-34" title="34"></a>
<a class="sourceLine" id="cb57-35" title="35">    <span class="kw">global</span> epoch</a>
<a class="sourceLine" id="cb57-36" title="36">    <span class="cf">for</span> epoch <span class="kw">in</span> <span class="bu">range</span>(epochs):</a>
<a class="sourceLine" id="cb57-37" title="37">        train(model, train_dataloader, optimizer, criterion)</a>
<a class="sourceLine" id="cb57-38" title="38">        validating(model, valid_dataloader, criterion)</a>
<a class="sourceLine" id="cb57-39" title="39"></a>
<a class="sourceLine" id="cb57-40" title="40">    trial.report(avg_val_f1, epoch)</a>
<a class="sourceLine" id="cb57-41" title="41"></a>
<a class="sourceLine" id="cb57-42" title="42">    <span class="co"># Handle pruning based on the intermediate value.</span></a>
<a class="sourceLine" id="cb57-43" title="43">    <span class="cf">if</span> trial.should_prune():</a>
<a class="sourceLine" id="cb57-44" title="44">        <span class="cf">raise</span> optuna.exceptions.TrialPruned()</a>
<a class="sourceLine" id="cb57-45" title="45"></a>
<a class="sourceLine" id="cb57-46" title="46">    <span class="cf">return</span> avg_val_f1</a>
<a class="sourceLine" id="cb57-47" title="47"></a>
<a class="sourceLine" id="cb57-48" title="48"></a>
<a class="sourceLine" id="cb57-49" title="49">study <span class="op">=</span> optuna.create_study(direction<span class="op">=</span><span class="st">&quot;maximize&quot;</span>,</a>
<a class="sourceLine" id="cb57-50" title="50">                            sampler<span class="op">=</span>TPESampler(),</a>
<a class="sourceLine" id="cb57-51" title="51">                            pruner<span class="op">=</span>optuna.pruners.HyperbandPruner(min_resource<span class="op">=</span><span class="dv">1</span>,</a>
<a class="sourceLine" id="cb57-52" title="52">                                                                  max_resource<span class="op">=</span><span class="dv">5</span>,</a>
<a class="sourceLine" id="cb57-53" title="53">                                                                  reduction_factor<span class="op">=</span><span class="dv">3</span>,</a>
<a class="sourceLine" id="cb57-54" title="54">                                                                  ))</a>
<a class="sourceLine" id="cb57-55" title="55">study.optimize(objective, n_trials<span class="op">=</span><span class="dv">35</span>)</a>
<a class="sourceLine" id="cb57-56" title="56"></a>
<a class="sourceLine" id="cb57-57" title="57"></a>
<a class="sourceLine" id="cb57-58" title="58">pruned_trials <span class="op">=</span> [t <span class="cf">for</span> t <span class="kw">in</span> study.trials <span class="cf">if</span> t.state <span class="op">==</span> optuna.trial.TrialState.PRUNED]</a>
<a class="sourceLine" id="cb57-59" title="59">complete_trials <span class="op">=</span> [t <span class="cf">for</span> t <span class="kw">in</span> study.trials <span class="cf">if</span> t.state <span class="op">==</span> optuna.trial.TrialState.COMPLETE]</a>
<a class="sourceLine" id="cb57-60" title="60"></a>
<a class="sourceLine" id="cb57-61" title="61"><span class="bu">print</span>(<span class="st">&quot;Study statistics: &quot;</span>)</a>
<a class="sourceLine" id="cb57-62" title="62"><span class="bu">print</span>(<span class="st">&quot;  Number of finished trials: &quot;</span>, <span class="bu">len</span>(study.trials))</a>
<a class="sourceLine" id="cb57-63" title="63"><span class="bu">print</span>(<span class="st">&quot;  Number of pruned trials: &quot;</span>, <span class="bu">len</span>(pruned_trials))</a>
<a class="sourceLine" id="cb57-64" title="64"><span class="bu">print</span>(<span class="st">&quot;  Number of complete trials: &quot;</span>, <span class="bu">len</span>(complete_trials))</a>
<a class="sourceLine" id="cb57-65" title="65"></a>
<a class="sourceLine" id="cb57-66" title="66"><span class="bu">print</span>(<span class="st">&quot;Best trial:&quot;</span>)</a>
<a class="sourceLine" id="cb57-67" title="67">trial <span class="op">=</span> study.best_trial</a>
<a class="sourceLine" id="cb57-68" title="68"></a>
<a class="sourceLine" id="cb57-69" title="69"><span class="bu">print</span>(<span class="st">&quot;  Value: &quot;</span>, trial.value)</a>
<a class="sourceLine" id="cb57-70" title="70"></a>
<a class="sourceLine" id="cb57-71" title="71"><span class="bu">print</span>(<span class="st">&quot;  Params: &quot;</span>)</a>
<a class="sourceLine" id="cb57-72" title="72"><span class="cf">for</span> key, value <span class="kw">in</span> trial.params.items():</a>
<a class="sourceLine" id="cb57-73" title="73">    <span class="bu">print</span>(<span class="st">&quot;    </span><span class="sc">{}</span><span class="st">: </span><span class="sc">{}</span><span class="st">&quot;</span>.<span class="bu">format</span>(key, value))</a></code></pre></div>
</div>
<div id="sources" class="section level1">
<h1><span class="header-section-number">6</span> Sources</h1>
<ul>
<li><p>Pennington, Jeffrey, Richard Socher, and Christopher D. Manning. “Glove: Global vectors for word representation.” In Proceedings of the 2014 conference on empirical methods in natural language processing (EMNLP), pp. 1532-1543. 2014. GloVe <a href="https://nlp.stanford.edu/projects/glove/" class="uri">https://nlp.stanford.edu/projects/glove/</a></p></li>
<li><p>Kim, Yoon. “Convolutional neural networks for sentence classification.” arXiv preprint arXiv:1408.5882 (2014).</p></li>
</ul>
</div>



<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    script.src  = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML";
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>

</body>
</html>
