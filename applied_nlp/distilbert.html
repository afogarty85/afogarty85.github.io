<!DOCTYPE html>

<html xmlns="http://www.w3.org/1999/xhtml">

<head>

<meta charset="utf-8" />
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="generator" content="pandoc" />

<meta name="viewport" content="width=device-width, initial-scale=1">

<meta name="author" content="Andrew Fogarty" />


<title>Text Classification: (Distil)BERT</title>



<style type="text/css">code{white-space: pre;}</style>
<style type="text/css" data-origin="pandoc">
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */

</style>
<script>
// apply pandoc div.sourceCode style to pre.sourceCode instead
(function() {
  var sheets = document.styleSheets;
  for (var i = 0; i < sheets.length; i++) {
    if (sheets[i].ownerNode.dataset["origin"] !== "pandoc") continue;
    try { var rules = sheets[i].cssRules; } catch (e) { continue; }
    for (var j = 0; j < rules.length; j++) {
      var rule = rules[j];
      // check if there is a div.sourceCode rule
      if (rule.type !== rule.STYLE_RULE || rule.selectorText !== "div.sourceCode") continue;
      var style = rule.style.cssText;
      // check if color or background-color is set
      if (rule.style.color === '' || rule.style.backgroundColor === '') continue;
      // replace div.sourceCode by a pre.sourceCode rule
      sheets[i].deleteRule(j);
      sheets[i].insertRule('pre.sourceCode{' + style + '}', j);
    }
  }
})();
</script>



<style type="text/css">body {
background-color: #fff;
margin: 1em auto;
max-width: 700px;
overflow: visible;
padding-left: 2em;
padding-right: 2em;
font-family: "Open Sans", "Helvetica Neue", Helvetica, Arial, sans-serif;
font-size: 14px;
line-height: 1.35;
}
#header {
text-align: center;
}
#TOC {
clear: both;
margin: 0 0 10px 10px;
padding: 4px;
width: 400px;
border: 1px solid #CCCCCC;
border-radius: 5px;
background-color: #f6f6f6;
font-size: 13px;
line-height: 1.3;
}
#TOC .toctitle {
font-weight: bold;
font-size: 15px;
margin-left: 5px;
}
#TOC ul {
padding-left: 40px;
margin-left: -1.5em;
margin-top: 5px;
margin-bottom: 5px;
}
#TOC ul ul {
margin-left: -2em;
}
#TOC li {
line-height: 16px;
}
table {
margin: 1em auto;
border-width: 1px;
border-color: #DDDDDD;
border-style: outset;
border-collapse: collapse;
}
table th {
border-width: 2px;
padding: 5px;
border-style: inset;
}
table td {
border-width: 1px;
border-style: inset;
line-height: 18px;
padding: 5px 5px;
}
table, table th, table td {
border-left-style: none;
border-right-style: none;
}
table thead, table tr.even {
background-color: #f7f7f7;
}
p {
margin: 0.5em 0;
}
blockquote {
background-color: #f6f6f6;
padding: 0.25em 0.75em;
}
hr {
border-style: solid;
border: none;
border-top: 1px solid #777;
margin: 28px 0;
}
dl {
margin-left: 0;
}
dl dd {
margin-bottom: 13px;
margin-left: 13px;
}
dl dt {
font-weight: bold;
}
ul {
margin-top: 0;
}
ul li {
list-style: circle outside;
}
ul ul {
margin-bottom: 0;
}
pre, code {
background-color: #f7f7f7;
border-radius: 3px;
color: #333;
white-space: pre-wrap; 
}
pre {
border-radius: 3px;
margin: 5px 0px 10px 0px;
padding: 10px;
}
pre:not([class]) {
background-color: #f7f7f7;
}
code {
font-family: Consolas, Monaco, 'Courier New', monospace;
font-size: 85%;
}
p > code, li > code {
padding: 2px 0px;
}
div.figure {
text-align: center;
}
img {
background-color: #FFFFFF;
padding: 2px;
border: 1px solid #DDDDDD;
border-radius: 3px;
border: 1px solid #CCCCCC;
margin: 0 5px;
}
h1 {
margin-top: 0;
font-size: 35px;
line-height: 40px;
}
h2 {
border-bottom: 4px solid #f7f7f7;
padding-top: 10px;
padding-bottom: 2px;
font-size: 145%;
}
h3 {
border-bottom: 2px solid #f7f7f7;
padding-top: 10px;
font-size: 120%;
}
h4 {
border-bottom: 1px solid #f7f7f7;
margin-left: 8px;
font-size: 105%;
}
h5, h6 {
border-bottom: 1px solid #ccc;
font-size: 105%;
}
a {
color: #0033dd;
text-decoration: none;
}
a:hover {
color: #6666ff; }
a:visited {
color: #800080; }
a:visited:hover {
color: #BB00BB; }
a[href^="http:"] {
text-decoration: underline; }
a[href^="https:"] {
text-decoration: underline; }

code > span.kw { color: #555; font-weight: bold; } 
code > span.dt { color: #902000; } 
code > span.dv { color: #40a070; } 
code > span.bn { color: #d14; } 
code > span.fl { color: #d14; } 
code > span.ch { color: #d14; } 
code > span.st { color: #d14; } 
code > span.co { color: #888888; font-style: italic; } 
code > span.ot { color: #007020; } 
code > span.al { color: #ff0000; font-weight: bold; } 
code > span.fu { color: #900; font-weight: bold; }  code > span.er { color: #a61717; background-color: #e3d2d2; } 
</style>




</head>

<body>




<h1 class="title toc-ignore">Text Classification: (Distil)BERT</h1>
<h4 class="author">Andrew Fogarty</h4>
<h4 class="date">7/15/2020</h4>


<div id="TOC">
<ul>
<li><a href="#introduction"><span class="toc-section-number">1</span> Introduction</a></li>
<li><a href="#encoder-transformer-architecture-bert"><span class="toc-section-number">2</span> Encoder Transformer Architecture: BERT</a>
<ul>
<li><a href="#load-our-data-set"><span class="toc-section-number">2.1</span> Load Our Data Set</a></li>
<li><a href="#tokenize-the-data"><span class="toc-section-number">2.2</span> Tokenize the Data</a></li>
<li><a href="#prepare-train-validation-and-testing-functions"><span class="toc-section-number">2.3</span> Prepare Train, Validation, and Testing Functions</a></li>
<li><a href="#prepare-tensor-data-sets"><span class="toc-section-number">2.4</span> Prepare Tensor Data Sets</a></li>
</ul></li>
<li><a href="#distilbert-hyperband-and-asha-hyperparameter-search-with-optuna"><span class="toc-section-number">3</span> DistilBERT: Hyperband and ASHA Hyperparameter Search with Optuna</a></li>
<li><a href="#sources"><span class="toc-section-number">4</span> Sources</a></li>
</ul>
</div>

<div class="sourceCode" id="cb1"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb1-1"><a href="#cb1-1"></a><span class="co"># load python</span></span>
<span id="cb1-2"><a href="#cb1-2"></a><span class="kw">library</span>(reticulate)</span>
<span id="cb1-3"><a href="#cb1-3"></a><span class="kw">use_condaenv</span>(<span class="st">&quot;my_ml&quot;</span>)</span></code></pre></div>
<div class="sourceCode" id="cb2"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb2-1"><a href="#cb2-1"></a><span class="co"># load packages</span></span>
<span id="cb2-2"><a href="#cb2-2"></a><span class="im">import</span> torch</span>
<span id="cb2-3"><a href="#cb2-3"></a><span class="im">import</span> torch.nn <span class="im">as</span> nn</span>
<span id="cb2-4"><a href="#cb2-4"></a><span class="im">from</span> transformers <span class="im">import</span> DistilBertForSequenceClassification, DistilBertTokenizer</span>
<span id="cb2-5"><a href="#cb2-5"></a><span class="im">from</span> transformers <span class="im">import</span> get_linear_schedule_with_warmup, AdamW</span>
<span id="cb2-6"><a href="#cb2-6"></a><span class="im">from</span> torch.utils.data <span class="im">import</span> TensorDataset, random_split, DataLoader, RandomSampler, SequentialSampler</span>
<span id="cb2-7"><a href="#cb2-7"></a><span class="im">import</span> time</span>
<span id="cb2-8"><a href="#cb2-8"></a><span class="im">import</span> datetime</span>
<span id="cb2-9"><a href="#cb2-9"></a><span class="im">import</span> random</span>
<span id="cb2-10"><a href="#cb2-10"></a><span class="im">import</span> pandas <span class="im">as</span> pd</span>
<span id="cb2-11"><a href="#cb2-11"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb2-12"><a href="#cb2-12"></a><span class="im">from</span> sklearn.metrics <span class="im">import</span> accuracy_score, f1_score, precision_score, recall_score</span>
<span id="cb2-13"><a href="#cb2-13"></a><span class="im">import</span> matplotlib.pyplot <span class="im">as</span> plt</span>
<span id="cb2-14"><a href="#cb2-14"></a><span class="im">import</span> seaborn <span class="im">as</span> sns</span>
<span id="cb2-15"><a href="#cb2-15"></a><span class="im">import</span> optuna</span>
<span id="cb2-16"><a href="#cb2-16"></a><span class="im">from</span> optuna.pruners <span class="im">import</span> SuccessiveHalvingPruner</span>
<span id="cb2-17"><a href="#cb2-17"></a><span class="im">from</span> optuna.samplers <span class="im">import</span> TPESampler</span>
<span id="cb2-18"><a href="#cb2-18"></a><span class="im">import</span> re</span>
<span id="cb2-19"><a href="#cb2-19"></a><span class="im">from</span> torch.cuda.amp <span class="im">import</span> autocast, GradScaler</span>
<span id="cb2-20"><a href="#cb2-20"></a></span>
<span id="cb2-21"><a href="#cb2-21"></a>SEED <span class="op">=</span> <span class="dv">15</span></span>
<span id="cb2-22"><a href="#cb2-22"></a>random.seed(SEED)</span>
<span id="cb2-23"><a href="#cb2-23"></a>np.random.seed(SEED)</span>
<span id="cb2-24"><a href="#cb2-24"></a>torch.manual_seed(SEED)</span></code></pre></div>
<pre><code>## &lt;torch._C.Generator object at 0x000000001F49C050&gt;</code></pre>
<div class="sourceCode" id="cb4"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb4-1"><a href="#cb4-1"></a>torch.backends.cudnn.deterministic <span class="op">=</span> <span class="va">True</span></span>
<span id="cb4-2"><a href="#cb4-2"></a></span>
<span id="cb4-3"><a href="#cb4-3"></a><span class="co"># tell pytorch to use cuda</span></span>
<span id="cb4-4"><a href="#cb4-4"></a>device <span class="op">=</span> torch.device(<span class="st">&quot;cuda&quot;</span>)</span></code></pre></div>
<div id="introduction" class="section level1" number="1">
<h1 number="1"><span class="header-section-number">1</span> Introduction</h1>
<p>Text or sequence classification aims to label a sentence or document based on its content. In this post, we use Transformers to classify a novel data set that I created based on insurgent propaganda messages.</p>
</div>
<div id="encoder-transformer-architecture-bert" class="section level1" number="2">
<h1 number="2"><span class="header-section-number">2</span> Encoder Transformer Architecture: BERT</h1>
<p>Bidirectional Encoder Representations from Transformers (BERT) is a encoder only transformer architecture that takes input of up to 512 word piece tokens, is comprised of 12 encoder layers (24 for BERT large) and 12 attention heads (16 for BERT large), and outputs a 768 dimensional vector (or 1024 for BERT large). BERT is pre-trained, which means that it has been trained on <em>tasks</em> (e.g., masked language model and next sentence prediction) and <em>corpora</em> (e.g., books corpus and Wikipedia). BERT offers cased, uncased, base, large, and multi-lingual models that we will sample from using the <code>transformers</code> (huggingface) library in PyTorch.</p>
<p>Among BERT’s most novel shifts, aside from using transformers, was to move away from the traditional form of predicting the next word task to taking an entire sentence, corruipting parts of it, and then predicting the corrupted parts. In turn, this helps the model work with entire sentences at a time.</p>
<p>To get value out of BERT, we need to adapt it to our task at hand which amounts to placing the minimal amount of additional structure on top of the model. So for our classification tasks, a <code>CLS</code> token begins each sentence which is used to predict whether one sentence follows another. So with a single sentence input, we take the output vector from the CLS position, create a feed forward network with affine and sigmoid to classify, and then fine tune to learn specific classification labels.</p>
<p>The guide proceeds by (1) preparing the data for text classification with DistilBERT – a distilled version of BERT base, and (2) analyzing the data in PyTorch.</p>
<div id="load-our-data-set" class="section level2" number="2.1">
<h2 number="2.1"><span class="header-section-number">2.1</span> Load Our Data Set</h2>
<p>While little data pre-processing is needed when using BERT, owing to its word piece tokenization, some minor cleanup is applied for clarity.</p>
<div class="sourceCode" id="cb5"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb5-1"><a href="#cb5-1"></a><span class="co"># prepare and load data</span></span>
<span id="cb5-2"><a href="#cb5-2"></a><span class="kw">def</span> prepare_df(pkl_location):</span>
<span id="cb5-3"><a href="#cb5-3"></a>    <span class="co"># read pkl as pandas</span></span>
<span id="cb5-4"><a href="#cb5-4"></a>    df <span class="op">=</span> pd.read_pickle(pkl_location)</span>
<span id="cb5-5"><a href="#cb5-5"></a>    <span class="co"># just keep us/kabul labels</span></span>
<span id="cb5-6"><a href="#cb5-6"></a>    df <span class="op">=</span> df.loc[(df[<span class="st">&#39;target&#39;</span>] <span class="op">==</span> <span class="st">&#39;US&#39;</span>) <span class="op">|</span> (df[<span class="st">&#39;target&#39;</span>] <span class="op">==</span> <span class="st">&#39;Kabul&#39;</span>)]</span>
<span id="cb5-7"><a href="#cb5-7"></a>    <span class="co"># mask DV to recode</span></span>
<span id="cb5-8"><a href="#cb5-8"></a>    us <span class="op">=</span> df[<span class="st">&#39;target&#39;</span>] <span class="op">==</span> <span class="st">&#39;US&#39;</span></span>
<span id="cb5-9"><a href="#cb5-9"></a>    kabul <span class="op">=</span> df[<span class="st">&#39;target&#39;</span>] <span class="op">==</span> <span class="st">&#39;Kabul&#39;</span></span>
<span id="cb5-10"><a href="#cb5-10"></a>    <span class="co"># apply mask</span></span>
<span id="cb5-11"><a href="#cb5-11"></a>    df.loc[us, <span class="st">&#39;target&#39;</span>] <span class="op">=</span> <span class="dv">1</span></span>
<span id="cb5-12"><a href="#cb5-12"></a>    df.loc[kabul, <span class="st">&#39;target&#39;</span>] <span class="op">=</span> <span class="dv">0</span></span>
<span id="cb5-13"><a href="#cb5-13"></a>    <span class="co"># reset index</span></span>
<span id="cb5-14"><a href="#cb5-14"></a>    df <span class="op">=</span> df.reset_index(drop<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb5-15"><a href="#cb5-15"></a>    <span class="cf">return</span> df</span>
<span id="cb5-16"><a href="#cb5-16"></a></span>
<span id="cb5-17"><a href="#cb5-17"></a></span>
<span id="cb5-18"><a href="#cb5-18"></a><span class="co"># instantiate df</span></span>
<span id="cb5-19"><a href="#cb5-19"></a>df <span class="op">=</span> prepare_df(<span class="st">&#39;C:</span><span class="ch">\\</span><span class="st">Users</span><span class="ch">\\</span><span class="st">Andrew</span><span class="ch">\\</span><span class="st">Desktop</span><span class="ch">\\</span><span class="st">df.pkl&#39;</span>)</span>
<span id="cb5-20"><a href="#cb5-20"></a></span>
<span id="cb5-21"><a href="#cb5-21"></a><span class="co"># remove excess white spaces</span></span>
<span id="cb5-22"><a href="#cb5-22"></a>df[<span class="st">&#39;body&#39;</span>] <span class="op">=</span> df[<span class="st">&#39;body&#39;</span>].<span class="bu">apply</span>(<span class="kw">lambda</span> x: <span class="st">&quot; &quot;</span>.join(x.split()))</span>
<span id="cb5-23"><a href="#cb5-23"></a></span>
<span id="cb5-24"><a href="#cb5-24"></a><span class="co"># remove excess spaces near punctuation</span></span>
<span id="cb5-25"><a href="#cb5-25"></a>df[<span class="st">&#39;body&#39;</span>] <span class="op">=</span> df[<span class="st">&#39;body&#39;</span>].<span class="bu">apply</span>(<span class="kw">lambda</span> x: re.sub(<span class="vs">r&#39;\s([?.!&quot;](?:\s|$))&#39;</span>, <span class="vs">r&#39;\1&#39;</span>, x))</span></code></pre></div>
</div>
<div id="tokenize-the-data" class="section level2" number="2.2">
<h2 number="2.2"><span class="header-section-number">2.2</span> Tokenize the Data</h2>
<p>Next, we instantiate the DistilBERT tokenizer from <code>transformers</code> and tokenize our entire corpus.</p>
<div class="sourceCode" id="cb6"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb6-1"><a href="#cb6-1"></a><span class="co"># instantiate BERT tokenizer with upper + lower case</span></span>
<span id="cb6-2"><a href="#cb6-2"></a>tokenizer <span class="op">=</span> DistilBertTokenizer.from_pretrained(<span class="st">&#39;distilbert-base-cased&#39;</span>)</span>
<span id="cb6-3"><a href="#cb6-3"></a></span>
<span id="cb6-4"><a href="#cb6-4"></a><span class="co"># a look at some of the DistilBERT vocab</span></span>
<span id="cb6-5"><a href="#cb6-5"></a>word_map <span class="op">=</span> <span class="bu">dict</span>(<span class="bu">zip</span>(tokenizer.vocab.keys(), <span class="bu">range</span>(<span class="bu">len</span>(tokenizer))))</span>
<span id="cb6-6"><a href="#cb6-6"></a>word_map.get(<span class="st">&#39;the&#39;</span>)  <span class="co"># find index value</span></span></code></pre></div>
<pre><code>## 1103</code></pre>
<div class="sourceCode" id="cb8"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb8-1"><a href="#cb8-1"></a><span class="bu">list</span>(tokenizer.vocab.keys())[<span class="dv">2000</span>:<span class="dv">2010</span>]</span></code></pre></div>
<pre><code>## [&#39;space&#39;, &#39;La&#39;, &#39;directed&#39;, &#39;smile&#39;, &#39;episode&#39;, &#39;hours&#39;, &#39;whole&#39;, &#39;##de&#39;, &#39;##less&#39;, &#39;Why&#39;]</code></pre>
<div class="sourceCode" id="cb10"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb10-1"><a href="#cb10-1"></a><span class="bu">len</span>(tokenizer)</span>
<span id="cb10-2"><a href="#cb10-2"></a></span>
<span id="cb10-3"><a href="#cb10-3"></a></span>
<span id="cb10-4"><a href="#cb10-4"></a><span class="co"># tokenize corpus using BERT</span></span></code></pre></div>
<pre><code>## 28996</code></pre>
<div class="sourceCode" id="cb12"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb12-1"><a href="#cb12-1"></a><span class="kw">def</span> tokenize_corpus(df, tokenizer, max_len):</span>
<span id="cb12-2"><a href="#cb12-2"></a>    <span class="co"># token ID storage</span></span>
<span id="cb12-3"><a href="#cb12-3"></a>    input_ids <span class="op">=</span> []</span>
<span id="cb12-4"><a href="#cb12-4"></a>    <span class="co"># attension mask storage</span></span>
<span id="cb12-5"><a href="#cb12-5"></a>    attention_masks <span class="op">=</span> []</span>
<span id="cb12-6"><a href="#cb12-6"></a>    <span class="co"># max len -- 512 is max</span></span>
<span id="cb12-7"><a href="#cb12-7"></a>    max_len <span class="op">=</span> max_len</span>
<span id="cb12-8"><a href="#cb12-8"></a>    <span class="co"># for every document:</span></span>
<span id="cb12-9"><a href="#cb12-9"></a>    <span class="cf">for</span> doc <span class="kw">in</span> df:</span>
<span id="cb12-10"><a href="#cb12-10"></a>        <span class="co"># `encode_plus` will:</span></span>
<span id="cb12-11"><a href="#cb12-11"></a>        <span class="co">#   (1) Tokenize the sentence.</span></span>
<span id="cb12-12"><a href="#cb12-12"></a>        <span class="co">#   (2) Prepend the `[CLS]` token to the start.</span></span>
<span id="cb12-13"><a href="#cb12-13"></a>        <span class="co">#   (3) Append the `[SEP]` token to the end.</span></span>
<span id="cb12-14"><a href="#cb12-14"></a>        <span class="co">#   (4) Map tokens to their IDs.</span></span>
<span id="cb12-15"><a href="#cb12-15"></a>        <span class="co">#   (5) Pad or truncate the sentence to `max_length`</span></span>
<span id="cb12-16"><a href="#cb12-16"></a>        <span class="co">#   (6) Create attention masks for [PAD] tokens.</span></span>
<span id="cb12-17"><a href="#cb12-17"></a>        encoded_dict <span class="op">=</span> tokenizer.encode_plus(</span>
<span id="cb12-18"><a href="#cb12-18"></a>                            doc,  <span class="co"># document to encode.</span></span>
<span id="cb12-19"><a href="#cb12-19"></a>                            add_special_tokens<span class="op">=</span><span class="va">True</span>,  <span class="co"># add &#39;[CLS]&#39; and &#39;[SEP]&#39;</span></span>
<span id="cb12-20"><a href="#cb12-20"></a>                            max_length<span class="op">=</span>max_len,  <span class="co"># set max length</span></span>
<span id="cb12-21"><a href="#cb12-21"></a>                            truncation<span class="op">=</span><span class="va">True</span>,  <span class="co"># truncate longer messages</span></span>
<span id="cb12-22"><a href="#cb12-22"></a>                            pad_to_max_length<span class="op">=</span><span class="va">True</span>,  <span class="co"># add padding</span></span>
<span id="cb12-23"><a href="#cb12-23"></a>                            return_attention_mask<span class="op">=</span><span class="va">True</span>,  <span class="co"># create attn. masks</span></span>
<span id="cb12-24"><a href="#cb12-24"></a>                            return_tensors<span class="op">=</span><span class="st">&#39;pt&#39;</span>  <span class="co"># return pytorch tensors</span></span>
<span id="cb12-25"><a href="#cb12-25"></a>                       )</span>
<span id="cb12-26"><a href="#cb12-26"></a></span>
<span id="cb12-27"><a href="#cb12-27"></a>        <span class="co"># add the tokenized sentence to the list</span></span>
<span id="cb12-28"><a href="#cb12-28"></a>        input_ids.append(encoded_dict[<span class="st">&#39;input_ids&#39;</span>])</span>
<span id="cb12-29"><a href="#cb12-29"></a></span>
<span id="cb12-30"><a href="#cb12-30"></a>        <span class="co"># and its attention mask (differentiates padding from non-padding)</span></span>
<span id="cb12-31"><a href="#cb12-31"></a>        attention_masks.append(encoded_dict[<span class="st">&#39;attention_mask&#39;</span>])</span>
<span id="cb12-32"><a href="#cb12-32"></a></span>
<span id="cb12-33"><a href="#cb12-33"></a>    <span class="cf">return</span> torch.cat(input_ids, dim<span class="op">=</span><span class="dv">0</span>), torch.cat(attention_masks, dim<span class="op">=</span><span class="dv">0</span>)</span>
<span id="cb12-34"><a href="#cb12-34"></a></span>
<span id="cb12-35"><a href="#cb12-35"></a></span>
<span id="cb12-36"><a href="#cb12-36"></a><span class="co"># create tokenized data</span></span>
<span id="cb12-37"><a href="#cb12-37"></a>input_ids, attention_masks <span class="op">=</span> tokenize_corpus(df[<span class="st">&#39;body&#39;</span>].values, tokenizer, <span class="dv">512</span>)</span>
<span id="cb12-38"><a href="#cb12-38"></a></span>
<span id="cb12-39"><a href="#cb12-39"></a><span class="co"># convert the labels into tensors.</span></span>
<span id="cb12-40"><a href="#cb12-40"></a>labels <span class="op">=</span> torch.tensor(df[<span class="st">&#39;target&#39;</span>].values.astype(np.float32))</span></code></pre></div>
</div>
<div id="prepare-train-validation-and-testing-functions" class="section level2" number="2.3">
<h2 number="2.3"><span class="header-section-number">2.3</span> Prepare Train, Validation, and Testing Functions</h2>
<div class="sourceCode" id="cb13"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb13-1"><a href="#cb13-1"></a><span class="kw">def</span> train(model, dataloader, optimizer):</span>
<span id="cb13-2"><a href="#cb13-2"></a></span>
<span id="cb13-3"><a href="#cb13-3"></a>    <span class="co"># capture time</span></span>
<span id="cb13-4"><a href="#cb13-4"></a>    total_t0 <span class="op">=</span> time.time()</span>
<span id="cb13-5"><a href="#cb13-5"></a></span>
<span id="cb13-6"><a href="#cb13-6"></a>    <span class="co"># Perform one full pass over the training set.</span></span>
<span id="cb13-7"><a href="#cb13-7"></a>    <span class="bu">print</span>(<span class="st">&quot;&quot;</span>)</span>
<span id="cb13-8"><a href="#cb13-8"></a>    <span class="bu">print</span>(<span class="st">&#39;======== Epoch </span><span class="sc">{:}</span><span class="st"> / </span><span class="sc">{:}</span><span class="st"> ========&#39;</span>.<span class="bu">format</span>(epoch <span class="op">+</span> <span class="dv">1</span>, epochs))</span>
<span id="cb13-9"><a href="#cb13-9"></a>    <span class="bu">print</span>(<span class="st">&#39;Training...&#39;</span>)</span>
<span id="cb13-10"><a href="#cb13-10"></a></span>
<span id="cb13-11"><a href="#cb13-11"></a>    <span class="co"># reset total loss for epoch</span></span>
<span id="cb13-12"><a href="#cb13-12"></a>    train_total_loss <span class="op">=</span> <span class="dv">0</span></span>
<span id="cb13-13"><a href="#cb13-13"></a>    total_train_f1 <span class="op">=</span> <span class="dv">0</span></span>
<span id="cb13-14"><a href="#cb13-14"></a></span>
<span id="cb13-15"><a href="#cb13-15"></a>    <span class="co"># put model into traning mode</span></span>
<span id="cb13-16"><a href="#cb13-16"></a>    model.train()</span>
<span id="cb13-17"><a href="#cb13-17"></a></span>
<span id="cb13-18"><a href="#cb13-18"></a>    <span class="co"># for each batch of training data...</span></span>
<span id="cb13-19"><a href="#cb13-19"></a>    <span class="cf">for</span> step, batch <span class="kw">in</span> <span class="bu">enumerate</span>(dataloader):</span>
<span id="cb13-20"><a href="#cb13-20"></a></span>
<span id="cb13-21"><a href="#cb13-21"></a>        <span class="co"># progress update every 40 batches.</span></span>
<span id="cb13-22"><a href="#cb13-22"></a>        <span class="cf">if</span> step <span class="op">%</span> <span class="dv">40</span> <span class="op">==</span> <span class="dv">0</span> <span class="kw">and</span> <span class="kw">not</span> step <span class="op">==</span> <span class="dv">0</span>:</span>
<span id="cb13-23"><a href="#cb13-23"></a></span>
<span id="cb13-24"><a href="#cb13-24"></a>            <span class="co"># Report progress.</span></span>
<span id="cb13-25"><a href="#cb13-25"></a>            <span class="bu">print</span>(<span class="st">&#39;  Batch {:&gt;5,}  of  {:&gt;5,}.&#39;</span>.<span class="bu">format</span>(step, <span class="bu">len</span>(dataloader)))</span>
<span id="cb13-26"><a href="#cb13-26"></a></span>
<span id="cb13-27"><a href="#cb13-27"></a>        <span class="co"># Unpack this training batch from our dataloader:</span></span>
<span id="cb13-28"><a href="#cb13-28"></a>        <span class="co">#</span></span>
<span id="cb13-29"><a href="#cb13-29"></a>        <span class="co"># As we unpack the batch, we&#39;ll also copy each tensor to the GPU using</span></span>
<span id="cb13-30"><a href="#cb13-30"></a>        <span class="co"># the `to` method.</span></span>
<span id="cb13-31"><a href="#cb13-31"></a>        <span class="co">#</span></span>
<span id="cb13-32"><a href="#cb13-32"></a>        <span class="co"># `batch` contains three pytorch tensors:</span></span>
<span id="cb13-33"><a href="#cb13-33"></a>        <span class="co">#   [0]: input ids</span></span>
<span id="cb13-34"><a href="#cb13-34"></a>        <span class="co">#   [1]: attention masks</span></span>
<span id="cb13-35"><a href="#cb13-35"></a>        <span class="co">#   [2]: labels</span></span>
<span id="cb13-36"><a href="#cb13-36"></a>        b_input_ids <span class="op">=</span> batch[<span class="dv">0</span>].cuda()</span>
<span id="cb13-37"><a href="#cb13-37"></a>        b_input_mask <span class="op">=</span> batch[<span class="dv">1</span>].cuda()</span>
<span id="cb13-38"><a href="#cb13-38"></a>        b_labels <span class="op">=</span> batch[<span class="dv">2</span>].cuda().<span class="bu">long</span>()</span>
<span id="cb13-39"><a href="#cb13-39"></a></span>
<span id="cb13-40"><a href="#cb13-40"></a>        <span class="co"># clear previously calculated gradients</span></span>
<span id="cb13-41"><a href="#cb13-41"></a>        optimizer.zero_grad()</span>
<span id="cb13-42"><a href="#cb13-42"></a></span>
<span id="cb13-43"><a href="#cb13-43"></a>        <span class="co"># runs the forward pass with autocasting.</span></span>
<span id="cb13-44"><a href="#cb13-44"></a>        <span class="cf">with</span> autocast():</span>
<span id="cb13-45"><a href="#cb13-45"></a>            <span class="co"># forward propagation (evaluate model on training batch)</span></span>
<span id="cb13-46"><a href="#cb13-46"></a>            loss, logits <span class="op">=</span> model(b_input_ids,</span>
<span id="cb13-47"><a href="#cb13-47"></a>                                 attention_mask<span class="op">=</span>b_input_mask,</span>
<span id="cb13-48"><a href="#cb13-48"></a>                                 labels<span class="op">=</span>b_labels)</span>
<span id="cb13-49"><a href="#cb13-49"></a>            <span class="co"># sum the training loss over all batches for average loss at end</span></span>
<span id="cb13-50"><a href="#cb13-50"></a>            <span class="co"># loss is a tensor containing a single value</span></span>
<span id="cb13-51"><a href="#cb13-51"></a>            train_total_loss <span class="op">+=</span> loss.item()</span>
<span id="cb13-52"><a href="#cb13-52"></a></span>
<span id="cb13-53"><a href="#cb13-53"></a>        <span class="co"># Scales loss.  Calls backward() on scaled loss to create scaled gradients.</span></span>
<span id="cb13-54"><a href="#cb13-54"></a>        <span class="co"># Backward passes under autocast are not recommended.</span></span>
<span id="cb13-55"><a href="#cb13-55"></a>        <span class="co"># Backward ops run in the same dtype autocast chose for corresponding forward ops.</span></span>
<span id="cb13-56"><a href="#cb13-56"></a>        scaler.scale(loss).backward()</span>
<span id="cb13-57"><a href="#cb13-57"></a></span>
<span id="cb13-58"><a href="#cb13-58"></a>        <span class="co"># scaler.step() first unscales the gradients of the optimizer&#39;s assigned params.</span></span>
<span id="cb13-59"><a href="#cb13-59"></a>        <span class="co"># If these gradients do not contain infs or NaNs, optimizer.step() is then called,</span></span>
<span id="cb13-60"><a href="#cb13-60"></a>        <span class="co"># otherwise, optimizer.step() is skipped.</span></span>
<span id="cb13-61"><a href="#cb13-61"></a>        scaler.step(optimizer)</span>
<span id="cb13-62"><a href="#cb13-62"></a></span>
<span id="cb13-63"><a href="#cb13-63"></a>        <span class="co"># Updates the scale for next iteration.</span></span>
<span id="cb13-64"><a href="#cb13-64"></a>        scaler.update()</span>
<span id="cb13-65"><a href="#cb13-65"></a></span>
<span id="cb13-66"><a href="#cb13-66"></a>        <span class="co"># update the learning rate</span></span>
<span id="cb13-67"><a href="#cb13-67"></a>        scheduler.step()</span>
<span id="cb13-68"><a href="#cb13-68"></a></span>
<span id="cb13-69"><a href="#cb13-69"></a>        <span class="co"># move logits and labels to CPU</span></span>
<span id="cb13-70"><a href="#cb13-70"></a>        logits <span class="op">=</span> logits.detach().cpu().numpy()</span>
<span id="cb13-71"><a href="#cb13-71"></a>        y_true <span class="op">=</span> b_labels.detach().cpu().numpy()</span>
<span id="cb13-72"><a href="#cb13-72"></a></span>
<span id="cb13-73"><a href="#cb13-73"></a>        <span class="co"># calculate preds</span></span>
<span id="cb13-74"><a href="#cb13-74"></a>        rounded_preds <span class="op">=</span> np.argmax(logits, axis<span class="op">=</span><span class="dv">1</span>).flatten()</span>
<span id="cb13-75"><a href="#cb13-75"></a></span>
<span id="cb13-76"><a href="#cb13-76"></a>        <span class="co"># calculate f1</span></span>
<span id="cb13-77"><a href="#cb13-77"></a>        total_train_f1 <span class="op">+=</span> f1_score(rounded_preds, y_true,</span>
<span id="cb13-78"><a href="#cb13-78"></a>                                   average<span class="op">=</span><span class="st">&#39;weighted&#39;</span>,</span>
<span id="cb13-79"><a href="#cb13-79"></a>                                   labels<span class="op">=</span>np.unique(rounded_preds))</span>
<span id="cb13-80"><a href="#cb13-80"></a></span>
<span id="cb13-81"><a href="#cb13-81"></a>    <span class="co"># calculate the average loss over all of the batches</span></span>
<span id="cb13-82"><a href="#cb13-82"></a>    avg_train_loss <span class="op">=</span> train_total_loss <span class="op">/</span> <span class="bu">len</span>(dataloader)</span>
<span id="cb13-83"><a href="#cb13-83"></a></span>
<span id="cb13-84"><a href="#cb13-84"></a>    <span class="co"># calculate the average f1 over all of the batches</span></span>
<span id="cb13-85"><a href="#cb13-85"></a>    avg_train_f1 <span class="op">=</span> total_train_f1 <span class="op">/</span> <span class="bu">len</span>(dataloader)</span>
<span id="cb13-86"><a href="#cb13-86"></a></span>
<span id="cb13-87"><a href="#cb13-87"></a>    <span class="co"># Record all statistics from this epoch.</span></span>
<span id="cb13-88"><a href="#cb13-88"></a>    training_stats.append(</span>
<span id="cb13-89"><a href="#cb13-89"></a>        {</span>
<span id="cb13-90"><a href="#cb13-90"></a>            <span class="st">&#39;Train Loss&#39;</span>: avg_train_loss,</span>
<span id="cb13-91"><a href="#cb13-91"></a>            <span class="st">&#39;Train F1&#39;</span>: avg_train_f1</span>
<span id="cb13-92"><a href="#cb13-92"></a>        }</span>
<span id="cb13-93"><a href="#cb13-93"></a>    )</span>
<span id="cb13-94"><a href="#cb13-94"></a></span>
<span id="cb13-95"><a href="#cb13-95"></a>    <span class="co"># training time end</span></span>
<span id="cb13-96"><a href="#cb13-96"></a>    training_time <span class="op">=</span> format_time(time.time() <span class="op">-</span> total_t0)</span>
<span id="cb13-97"><a href="#cb13-97"></a></span>
<span id="cb13-98"><a href="#cb13-98"></a>    <span class="co"># print result summaries</span></span>
<span id="cb13-99"><a href="#cb13-99"></a>    <span class="bu">print</span>(<span class="st">&quot;&quot;</span>)</span>
<span id="cb13-100"><a href="#cb13-100"></a>    <span class="bu">print</span>(<span class="st">&quot;summary results&quot;</span>)</span>
<span id="cb13-101"><a href="#cb13-101"></a>    <span class="bu">print</span>(<span class="st">&quot;epoch | trn loss | trn f1 | trn time &quot;</span>)</span>
<span id="cb13-102"><a href="#cb13-102"></a>    <span class="bu">print</span>(<span class="ss">f&quot;</span><span class="sc">{</span>epoch<span class="op">+</span><span class="dv">1</span><span class="sc">:5d}</span><span class="ss"> | </span><span class="sc">{</span>avg_train_loss<span class="sc">:.5f}</span><span class="ss"> | </span><span class="sc">{</span>avg_train_f1<span class="sc">:.5f}</span><span class="ss"> | </span><span class="sc">{</span>training_time<span class="sc">:}</span><span class="ss">&quot;</span>)</span>
<span id="cb13-103"><a href="#cb13-103"></a></span>
<span id="cb13-104"><a href="#cb13-104"></a>    torch.cuda.empty_cache()</span>
<span id="cb13-105"><a href="#cb13-105"></a></span>
<span id="cb13-106"><a href="#cb13-106"></a>    <span class="cf">return</span> training_stats</span>
<span id="cb13-107"><a href="#cb13-107"></a></span>
<span id="cb13-108"><a href="#cb13-108"></a></span>
<span id="cb13-109"><a href="#cb13-109"></a><span class="kw">def</span> validating(model, dataloader):</span>
<span id="cb13-110"><a href="#cb13-110"></a></span>
<span id="cb13-111"><a href="#cb13-111"></a>    <span class="co"># capture validation time</span></span>
<span id="cb13-112"><a href="#cb13-112"></a>    total_t0 <span class="op">=</span> time.time()</span>
<span id="cb13-113"><a href="#cb13-113"></a></span>
<span id="cb13-114"><a href="#cb13-114"></a>    <span class="co"># After the completion of each training epoch, measure our performance on</span></span>
<span id="cb13-115"><a href="#cb13-115"></a>    <span class="co"># our validation set.</span></span>
<span id="cb13-116"><a href="#cb13-116"></a>    <span class="bu">print</span>(<span class="st">&quot;&quot;</span>)</span>
<span id="cb13-117"><a href="#cb13-117"></a>    <span class="bu">print</span>(<span class="st">&quot;Running Validation...&quot;</span>)</span>
<span id="cb13-118"><a href="#cb13-118"></a></span>
<span id="cb13-119"><a href="#cb13-119"></a>    <span class="co"># put the model in evaluation mode</span></span>
<span id="cb13-120"><a href="#cb13-120"></a>    model.<span class="bu">eval</span>()</span>
<span id="cb13-121"><a href="#cb13-121"></a></span>
<span id="cb13-122"><a href="#cb13-122"></a>    <span class="co"># track variables</span></span>
<span id="cb13-123"><a href="#cb13-123"></a>    total_valid_accuracy <span class="op">=</span> <span class="dv">0</span></span>
<span id="cb13-124"><a href="#cb13-124"></a>    total_valid_loss <span class="op">=</span> <span class="dv">0</span></span>
<span id="cb13-125"><a href="#cb13-125"></a>    total_valid_f1 <span class="op">=</span> <span class="dv">0</span></span>
<span id="cb13-126"><a href="#cb13-126"></a>    total_valid_recall <span class="op">=</span> <span class="dv">0</span></span>
<span id="cb13-127"><a href="#cb13-127"></a>    total_valid_precision <span class="op">=</span> <span class="dv">0</span></span>
<span id="cb13-128"><a href="#cb13-128"></a></span>
<span id="cb13-129"><a href="#cb13-129"></a>    <span class="co"># evaluate data for one epoch</span></span>
<span id="cb13-130"><a href="#cb13-130"></a>    <span class="cf">for</span> batch <span class="kw">in</span> dataloader:</span>
<span id="cb13-131"><a href="#cb13-131"></a></span>
<span id="cb13-132"><a href="#cb13-132"></a>        <span class="co"># Unpack this training batch from our dataloader:</span></span>
<span id="cb13-133"><a href="#cb13-133"></a>        <span class="co"># `batch` contains three pytorch tensors:</span></span>
<span id="cb13-134"><a href="#cb13-134"></a>        <span class="co">#   [0]: input ids</span></span>
<span id="cb13-135"><a href="#cb13-135"></a>        <span class="co">#   [1]: attention masks</span></span>
<span id="cb13-136"><a href="#cb13-136"></a>        <span class="co">#   [2]: labels</span></span>
<span id="cb13-137"><a href="#cb13-137"></a>        b_input_ids <span class="op">=</span> batch[<span class="dv">0</span>].cuda()</span>
<span id="cb13-138"><a href="#cb13-138"></a>        b_input_mask <span class="op">=</span> batch[<span class="dv">1</span>].cuda()</span>
<span id="cb13-139"><a href="#cb13-139"></a>        b_labels <span class="op">=</span> batch[<span class="dv">2</span>].cuda().<span class="bu">long</span>()</span>
<span id="cb13-140"><a href="#cb13-140"></a></span>
<span id="cb13-141"><a href="#cb13-141"></a>        <span class="co"># tell pytorch not to bother calculating gradients</span></span>
<span id="cb13-142"><a href="#cb13-142"></a>        <span class="co"># as its only necessary for training</span></span>
<span id="cb13-143"><a href="#cb13-143"></a>        <span class="cf">with</span> torch.no_grad():</span>
<span id="cb13-144"><a href="#cb13-144"></a></span>
<span id="cb13-145"><a href="#cb13-145"></a>            <span class="co"># forward propagation (evaluate model on training batch)</span></span>
<span id="cb13-146"><a href="#cb13-146"></a>            loss, logits <span class="op">=</span> model(b_input_ids,</span>
<span id="cb13-147"><a href="#cb13-147"></a>                                 attention_mask<span class="op">=</span>b_input_mask,</span>
<span id="cb13-148"><a href="#cb13-148"></a>                                 labels<span class="op">=</span>b_labels)</span>
<span id="cb13-149"><a href="#cb13-149"></a></span>
<span id="cb13-150"><a href="#cb13-150"></a>        <span class="co"># accumulate validation loss</span></span>
<span id="cb13-151"><a href="#cb13-151"></a>        total_valid_loss <span class="op">+=</span> loss.item()</span>
<span id="cb13-152"><a href="#cb13-152"></a></span>
<span id="cb13-153"><a href="#cb13-153"></a>        <span class="co"># move logits and labels to CPU</span></span>
<span id="cb13-154"><a href="#cb13-154"></a>        logits <span class="op">=</span> logits.detach().cpu().numpy()</span>
<span id="cb13-155"><a href="#cb13-155"></a>        y_true <span class="op">=</span> b_labels.detach().cpu().numpy()</span>
<span id="cb13-156"><a href="#cb13-156"></a></span>
<span id="cb13-157"><a href="#cb13-157"></a>        <span class="co"># calculate preds</span></span>
<span id="cb13-158"><a href="#cb13-158"></a>        rounded_preds <span class="op">=</span> np.argmax(logits, axis<span class="op">=</span><span class="dv">1</span>).flatten()</span>
<span id="cb13-159"><a href="#cb13-159"></a></span>
<span id="cb13-160"><a href="#cb13-160"></a>        <span class="co"># calculate f1</span></span>
<span id="cb13-161"><a href="#cb13-161"></a>        total_valid_f1 <span class="op">+=</span> f1_score(rounded_preds, y_true,</span>
<span id="cb13-162"><a href="#cb13-162"></a>                                   average<span class="op">=</span><span class="st">&#39;weighted&#39;</span>,</span>
<span id="cb13-163"><a href="#cb13-163"></a>                                   labels<span class="op">=</span>np.unique(rounded_preds))</span>
<span id="cb13-164"><a href="#cb13-164"></a></span>
<span id="cb13-165"><a href="#cb13-165"></a>        <span class="co"># calculate accuracy</span></span>
<span id="cb13-166"><a href="#cb13-166"></a>        total_valid_accuracy <span class="op">+=</span> accuracy_score(rounded_preds, y_true)</span>
<span id="cb13-167"><a href="#cb13-167"></a></span>
<span id="cb13-168"><a href="#cb13-168"></a>        <span class="co"># calculate precision</span></span>
<span id="cb13-169"><a href="#cb13-169"></a>        total_valid_precision <span class="op">+=</span> precision_score(rounded_preds, y_true,</span>
<span id="cb13-170"><a href="#cb13-170"></a>                                                 average<span class="op">=</span><span class="st">&#39;weighted&#39;</span>,</span>
<span id="cb13-171"><a href="#cb13-171"></a>                                                 labels<span class="op">=</span>np.unique(rounded_preds))</span>
<span id="cb13-172"><a href="#cb13-172"></a></span>
<span id="cb13-173"><a href="#cb13-173"></a>        <span class="co"># calculate recall</span></span>
<span id="cb13-174"><a href="#cb13-174"></a>        total_valid_recall <span class="op">+=</span> recall_score(rounded_preds, y_true,</span>
<span id="cb13-175"><a href="#cb13-175"></a>                                                 average<span class="op">=</span><span class="st">&#39;weighted&#39;</span>,</span>
<span id="cb13-176"><a href="#cb13-176"></a>                                                 labels<span class="op">=</span>np.unique(rounded_preds))</span>
<span id="cb13-177"><a href="#cb13-177"></a></span>
<span id="cb13-178"><a href="#cb13-178"></a>    <span class="co"># report final accuracy of validation run</span></span>
<span id="cb13-179"><a href="#cb13-179"></a>    avg_accuracy <span class="op">=</span> total_valid_accuracy <span class="op">/</span> <span class="bu">len</span>(dataloader)</span>
<span id="cb13-180"><a href="#cb13-180"></a></span>
<span id="cb13-181"><a href="#cb13-181"></a>    <span class="co"># report final f1 of validation run</span></span>
<span id="cb13-182"><a href="#cb13-182"></a>    <span class="kw">global</span> avg_val_f1</span>
<span id="cb13-183"><a href="#cb13-183"></a>    avg_val_f1 <span class="op">=</span> total_valid_f1 <span class="op">/</span> <span class="bu">len</span>(dataloader)</span>
<span id="cb13-184"><a href="#cb13-184"></a></span>
<span id="cb13-185"><a href="#cb13-185"></a>    <span class="co"># report final f1 of validation run</span></span>
<span id="cb13-186"><a href="#cb13-186"></a>    avg_precision <span class="op">=</span> total_valid_precision <span class="op">/</span> <span class="bu">len</span>(dataloader)</span>
<span id="cb13-187"><a href="#cb13-187"></a></span>
<span id="cb13-188"><a href="#cb13-188"></a>    <span class="co"># report final f1 of validation run</span></span>
<span id="cb13-189"><a href="#cb13-189"></a>    avg_recall <span class="op">=</span> total_valid_recall <span class="op">/</span> <span class="bu">len</span>(dataloader)</span>
<span id="cb13-190"><a href="#cb13-190"></a></span>
<span id="cb13-191"><a href="#cb13-191"></a>    <span class="co"># calculate the average loss over all of the batches.</span></span>
<span id="cb13-192"><a href="#cb13-192"></a>    <span class="kw">global</span> avg_val_loss</span>
<span id="cb13-193"><a href="#cb13-193"></a>    avg_val_loss <span class="op">=</span> total_valid_loss <span class="op">/</span> <span class="bu">len</span>(dataloader)</span>
<span id="cb13-194"><a href="#cb13-194"></a></span>
<span id="cb13-195"><a href="#cb13-195"></a>    <span class="co"># Record all statistics from this epoch.</span></span>
<span id="cb13-196"><a href="#cb13-196"></a>    valid_stats.append(</span>
<span id="cb13-197"><a href="#cb13-197"></a>        {</span>
<span id="cb13-198"><a href="#cb13-198"></a>            <span class="st">&#39;Val Loss&#39;</span>: avg_val_loss,</span>
<span id="cb13-199"><a href="#cb13-199"></a>            <span class="st">&#39;Val Accur.&#39;</span>: avg_accuracy,</span>
<span id="cb13-200"><a href="#cb13-200"></a>            <span class="st">&#39;Val precision&#39;</span>: avg_precision,</span>
<span id="cb13-201"><a href="#cb13-201"></a>            <span class="st">&#39;Val recall&#39;</span>: avg_recall,</span>
<span id="cb13-202"><a href="#cb13-202"></a>            <span class="st">&#39;Val F1&#39;</span>: avg_val_f1</span>
<span id="cb13-203"><a href="#cb13-203"></a>        }</span>
<span id="cb13-204"><a href="#cb13-204"></a>    )</span>
<span id="cb13-205"><a href="#cb13-205"></a></span>
<span id="cb13-206"><a href="#cb13-206"></a>    <span class="co"># capture end validation time</span></span>
<span id="cb13-207"><a href="#cb13-207"></a>    training_time <span class="op">=</span> format_time(time.time() <span class="op">-</span> total_t0)</span>
<span id="cb13-208"><a href="#cb13-208"></a></span>
<span id="cb13-209"><a href="#cb13-209"></a>    <span class="co"># print result summaries</span></span>
<span id="cb13-210"><a href="#cb13-210"></a>    <span class="bu">print</span>(<span class="st">&quot;&quot;</span>)</span>
<span id="cb13-211"><a href="#cb13-211"></a>    <span class="bu">print</span>(<span class="st">&quot;summary results&quot;</span>)</span>
<span id="cb13-212"><a href="#cb13-212"></a>    <span class="bu">print</span>(<span class="st">&quot;epoch | val loss | val f1 | val time&quot;</span>)</span>
<span id="cb13-213"><a href="#cb13-213"></a>    <span class="bu">print</span>(<span class="ss">f&quot;</span><span class="sc">{</span>epoch<span class="op">+</span><span class="dv">1</span><span class="sc">:5d}</span><span class="ss"> | </span><span class="sc">{</span>avg_val_loss<span class="sc">:.5f}</span><span class="ss"> | </span><span class="sc">{</span>avg_val_f1<span class="sc">:.5f}</span><span class="ss"> | </span><span class="sc">{</span>training_time<span class="sc">:}</span><span class="ss">&quot;</span>)</span>
<span id="cb13-214"><a href="#cb13-214"></a></span>
<span id="cb13-215"><a href="#cb13-215"></a>    <span class="cf">return</span> valid_stats</span>
<span id="cb13-216"><a href="#cb13-216"></a></span>
<span id="cb13-217"><a href="#cb13-217"></a></span>
<span id="cb13-218"><a href="#cb13-218"></a><span class="kw">def</span> testing(model, dataloader):</span>
<span id="cb13-219"><a href="#cb13-219"></a></span>
<span id="cb13-220"><a href="#cb13-220"></a>    <span class="bu">print</span>(<span class="st">&quot;&quot;</span>)</span>
<span id="cb13-221"><a href="#cb13-221"></a>    <span class="bu">print</span>(<span class="st">&quot;Running Testing...&quot;</span>)</span>
<span id="cb13-222"><a href="#cb13-222"></a></span>
<span id="cb13-223"><a href="#cb13-223"></a>    <span class="co"># put the model in evaluation mode</span></span>
<span id="cb13-224"><a href="#cb13-224"></a>    model.<span class="bu">eval</span>()</span>
<span id="cb13-225"><a href="#cb13-225"></a></span>
<span id="cb13-226"><a href="#cb13-226"></a>    <span class="co"># track variables</span></span>
<span id="cb13-227"><a href="#cb13-227"></a>    total_test_accuracy <span class="op">=</span> <span class="dv">0</span></span>
<span id="cb13-228"><a href="#cb13-228"></a>    total_test_loss <span class="op">=</span> <span class="dv">0</span></span>
<span id="cb13-229"><a href="#cb13-229"></a>    total_test_f1 <span class="op">=</span> <span class="dv">0</span></span>
<span id="cb13-230"><a href="#cb13-230"></a>    total_test_recall <span class="op">=</span> <span class="dv">0</span></span>
<span id="cb13-231"><a href="#cb13-231"></a>    total_test_precision <span class="op">=</span> <span class="dv">0</span></span>
<span id="cb13-232"><a href="#cb13-232"></a></span>
<span id="cb13-233"><a href="#cb13-233"></a>    <span class="co"># evaluate data for one epoch</span></span>
<span id="cb13-234"><a href="#cb13-234"></a>    <span class="cf">for</span> batch <span class="kw">in</span> dataloader:</span>
<span id="cb13-235"><a href="#cb13-235"></a></span>
<span id="cb13-236"><a href="#cb13-236"></a>        <span class="co"># Unpack this training batch from our dataloader:</span></span>
<span id="cb13-237"><a href="#cb13-237"></a>        <span class="co"># `batch` contains three pytorch tensors:</span></span>
<span id="cb13-238"><a href="#cb13-238"></a>        <span class="co">#   [0]: input ids</span></span>
<span id="cb13-239"><a href="#cb13-239"></a>        <span class="co">#   [1]: attention masks</span></span>
<span id="cb13-240"><a href="#cb13-240"></a>        <span class="co">#   [2]: labels</span></span>
<span id="cb13-241"><a href="#cb13-241"></a>        b_input_ids <span class="op">=</span> batch[<span class="dv">0</span>].cuda()</span>
<span id="cb13-242"><a href="#cb13-242"></a>        b_input_mask <span class="op">=</span> batch[<span class="dv">1</span>].cuda()</span>
<span id="cb13-243"><a href="#cb13-243"></a>        b_labels <span class="op">=</span> batch[<span class="dv">2</span>].cuda().<span class="bu">long</span>()</span>
<span id="cb13-244"><a href="#cb13-244"></a></span>
<span id="cb13-245"><a href="#cb13-245"></a>        <span class="co"># tell pytorch not to bother calculating gradients</span></span>
<span id="cb13-246"><a href="#cb13-246"></a>        <span class="co"># as its only necessary for training</span></span>
<span id="cb13-247"><a href="#cb13-247"></a>        <span class="cf">with</span> torch.no_grad():</span>
<span id="cb13-248"><a href="#cb13-248"></a></span>
<span id="cb13-249"><a href="#cb13-249"></a>            <span class="co"># forward propagation (evaluate model on training batch)</span></span>
<span id="cb13-250"><a href="#cb13-250"></a>            loss, logits <span class="op">=</span> model(b_input_ids,</span>
<span id="cb13-251"><a href="#cb13-251"></a>                                 attention_mask<span class="op">=</span>b_input_mask,</span>
<span id="cb13-252"><a href="#cb13-252"></a>                                 labels<span class="op">=</span>b_labels)</span>
<span id="cb13-253"><a href="#cb13-253"></a></span>
<span id="cb13-254"><a href="#cb13-254"></a>        <span class="co"># accumulate validation loss</span></span>
<span id="cb13-255"><a href="#cb13-255"></a>        total_test_loss <span class="op">+=</span> loss.item()</span>
<span id="cb13-256"><a href="#cb13-256"></a></span>
<span id="cb13-257"><a href="#cb13-257"></a>        <span class="co"># move logits and labels to CPU</span></span>
<span id="cb13-258"><a href="#cb13-258"></a>        logits <span class="op">=</span> logits.detach().cpu().numpy()</span>
<span id="cb13-259"><a href="#cb13-259"></a>        y_true <span class="op">=</span> b_labels.detach().cpu().numpy()</span>
<span id="cb13-260"><a href="#cb13-260"></a></span>
<span id="cb13-261"><a href="#cb13-261"></a>        <span class="co"># calculate preds</span></span>
<span id="cb13-262"><a href="#cb13-262"></a>        rounded_preds <span class="op">=</span> np.argmax(logits, axis<span class="op">=</span><span class="dv">1</span>).flatten()</span>
<span id="cb13-263"><a href="#cb13-263"></a></span>
<span id="cb13-264"><a href="#cb13-264"></a>        <span class="co"># calculate f1</span></span>
<span id="cb13-265"><a href="#cb13-265"></a>        total_test_f1 <span class="op">+=</span> f1_score(rounded_preds, y_true,</span>
<span id="cb13-266"><a href="#cb13-266"></a>                                   average<span class="op">=</span><span class="st">&#39;weighted&#39;</span>,</span>
<span id="cb13-267"><a href="#cb13-267"></a>                                   labels<span class="op">=</span>np.unique(rounded_preds))</span>
<span id="cb13-268"><a href="#cb13-268"></a></span>
<span id="cb13-269"><a href="#cb13-269"></a>        <span class="co"># calculate accuracy</span></span>
<span id="cb13-270"><a href="#cb13-270"></a>        total_test_accuracy <span class="op">+=</span> accuracy_score(rounded_preds, y_true)</span>
<span id="cb13-271"><a href="#cb13-271"></a></span>
<span id="cb13-272"><a href="#cb13-272"></a>        <span class="co"># calculate precision</span></span>
<span id="cb13-273"><a href="#cb13-273"></a>        total_test_precision <span class="op">+=</span> precision_score(rounded_preds, y_true,</span>
<span id="cb13-274"><a href="#cb13-274"></a>                                                 average<span class="op">=</span><span class="st">&#39;weighted&#39;</span>,</span>
<span id="cb13-275"><a href="#cb13-275"></a>                                                 labels<span class="op">=</span>np.unique(rounded_preds))</span>
<span id="cb13-276"><a href="#cb13-276"></a></span>
<span id="cb13-277"><a href="#cb13-277"></a>        <span class="co"># calculate recall</span></span>
<span id="cb13-278"><a href="#cb13-278"></a>        total_test_recall <span class="op">+=</span> recall_score(rounded_preds, y_true,</span>
<span id="cb13-279"><a href="#cb13-279"></a>                                                 average<span class="op">=</span><span class="st">&#39;weighted&#39;</span>,</span>
<span id="cb13-280"><a href="#cb13-280"></a>                                                 labels<span class="op">=</span>np.unique(rounded_preds))</span>
<span id="cb13-281"><a href="#cb13-281"></a></span>
<span id="cb13-282"><a href="#cb13-282"></a>    <span class="co"># report final accuracy of validation run</span></span>
<span id="cb13-283"><a href="#cb13-283"></a>    avg_accuracy <span class="op">=</span> total_test_accuracy <span class="op">/</span> <span class="bu">len</span>(dataloader)</span>
<span id="cb13-284"><a href="#cb13-284"></a></span>
<span id="cb13-285"><a href="#cb13-285"></a>    <span class="co"># report final f1 of validation run</span></span>
<span id="cb13-286"><a href="#cb13-286"></a>    avg_test_f1 <span class="op">=</span> total_test_f1 <span class="op">/</span> <span class="bu">len</span>(dataloader)</span>
<span id="cb13-287"><a href="#cb13-287"></a></span>
<span id="cb13-288"><a href="#cb13-288"></a>    <span class="co"># report final f1 of validation run</span></span>
<span id="cb13-289"><a href="#cb13-289"></a>    avg_precision <span class="op">=</span> total_test_precision <span class="op">/</span> <span class="bu">len</span>(dataloader)</span>
<span id="cb13-290"><a href="#cb13-290"></a></span>
<span id="cb13-291"><a href="#cb13-291"></a>    <span class="co"># report final f1 of validation run</span></span>
<span id="cb13-292"><a href="#cb13-292"></a>    avg_recall <span class="op">=</span> total_test_recall <span class="op">/</span> <span class="bu">len</span>(dataloader)</span>
<span id="cb13-293"><a href="#cb13-293"></a></span>
<span id="cb13-294"><a href="#cb13-294"></a>    <span class="co"># calculate the average loss over all of the batches.</span></span>
<span id="cb13-295"><a href="#cb13-295"></a>    avg_test_loss <span class="op">=</span> total_test_loss <span class="op">/</span> <span class="bu">len</span>(dataloader)</span>
<span id="cb13-296"><a href="#cb13-296"></a></span>
<span id="cb13-297"><a href="#cb13-297"></a>    <span class="co"># Record all statistics from this epoch.</span></span>
<span id="cb13-298"><a href="#cb13-298"></a>    test_stats.append(</span>
<span id="cb13-299"><a href="#cb13-299"></a>        {</span>
<span id="cb13-300"><a href="#cb13-300"></a>            <span class="st">&#39;Test Loss&#39;</span>: avg_test_loss,</span>
<span id="cb13-301"><a href="#cb13-301"></a>            <span class="st">&#39;Test Accur.&#39;</span>: avg_accuracy,</span>
<span id="cb13-302"><a href="#cb13-302"></a>            <span class="st">&#39;Test precision&#39;</span>: avg_precision,</span>
<span id="cb13-303"><a href="#cb13-303"></a>            <span class="st">&#39;Test recall&#39;</span>: avg_recall,</span>
<span id="cb13-304"><a href="#cb13-304"></a>            <span class="st">&#39;Test F1&#39;</span>: avg_test_f1</span>
<span id="cb13-305"><a href="#cb13-305"></a>        }</span>
<span id="cb13-306"><a href="#cb13-306"></a>    )</span>
<span id="cb13-307"><a href="#cb13-307"></a>    <span class="cf">return</span> test_stats</span></code></pre></div>
</div>
<div id="prepare-tensor-data-sets" class="section level2" number="2.4">
<h2 number="2.4"><span class="header-section-number">2.4</span> Prepare Tensor Data Sets</h2>
<p>With the corpus work out of the way, we now proceed to prepare our data for analysis in PyTorch. The code below creates a <code>TensorDataset</code> comprised of our features, attention masks, and our labels. It then proceeds to spit the data sets into train, validation, and test sets.</p>
<div class="sourceCode" id="cb14"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb14-1"><a href="#cb14-1"></a><span class="co"># prepare tensor data sets</span></span>
<span id="cb14-2"><a href="#cb14-2"></a><span class="kw">def</span> prepare_dataset(padded_tokens, attention_masks, target):</span>
<span id="cb14-3"><a href="#cb14-3"></a>    <span class="co"># prepare target into np array</span></span>
<span id="cb14-4"><a href="#cb14-4"></a>    target <span class="op">=</span> np.array(target.values, dtype<span class="op">=</span>np.int64).reshape(<span class="op">-</span><span class="dv">1</span>, <span class="dv">1</span>)</span>
<span id="cb14-5"><a href="#cb14-5"></a>    <span class="co"># create tensor data sets</span></span>
<span id="cb14-6"><a href="#cb14-6"></a>    tensor_df <span class="op">=</span> TensorDataset(padded_tokens, attention_masks, torch.from_numpy(target))</span>
<span id="cb14-7"><a href="#cb14-7"></a>    <span class="co"># 80% of df</span></span>
<span id="cb14-8"><a href="#cb14-8"></a>    train_size <span class="op">=</span> <span class="bu">int</span>(<span class="fl">0.8</span> <span class="op">*</span> <span class="bu">len</span>(df))</span>
<span id="cb14-9"><a href="#cb14-9"></a>    <span class="co"># 20% of df</span></span>
<span id="cb14-10"><a href="#cb14-10"></a>    val_size <span class="op">=</span> <span class="bu">len</span>(df) <span class="op">-</span> train_size</span>
<span id="cb14-11"><a href="#cb14-11"></a>    <span class="co"># 50% of validation</span></span>
<span id="cb14-12"><a href="#cb14-12"></a>    test_size <span class="op">=</span> <span class="bu">int</span>(val_size <span class="op">-</span> <span class="fl">0.5</span><span class="op">*</span>val_size)</span>
<span id="cb14-13"><a href="#cb14-13"></a>    <span class="co"># divide the dataset by randomly selecting samples</span></span>
<span id="cb14-14"><a href="#cb14-14"></a>    train_dataset, val_dataset <span class="op">=</span> random_split(tensor_df, [train_size, val_size])</span>
<span id="cb14-15"><a href="#cb14-15"></a>    <span class="co"># divide validation by randomly selecting samples</span></span>
<span id="cb14-16"><a href="#cb14-16"></a>    val_dataset, test_dataset <span class="op">=</span> random_split(val_dataset, [test_size, test_size<span class="op">+</span><span class="dv">1</span>])</span>
<span id="cb14-17"><a href="#cb14-17"></a></span>
<span id="cb14-18"><a href="#cb14-18"></a>    <span class="cf">return</span> train_dataset, val_dataset, test_dataset</span>
<span id="cb14-19"><a href="#cb14-19"></a></span>
<span id="cb14-20"><a href="#cb14-20"></a></span>
<span id="cb14-21"><a href="#cb14-21"></a><span class="co"># create tenor data sets</span></span>
<span id="cb14-22"><a href="#cb14-22"></a>train_dataset, val_dataset, test_dataset <span class="op">=</span> prepare_dataset(input_ids,</span>
<span id="cb14-23"><a href="#cb14-23"></a>                                                           attention_masks,</span>
<span id="cb14-24"><a href="#cb14-24"></a>                                                           df[<span class="st">&#39;target&#39;</span>])</span></code></pre></div>
<p>Since my corpus is imbalanced, I produce weighted samplers to help balance the distribution of data as it is fed outside of my data loaders.</p>
<div class="sourceCode" id="cb15"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb15-1"><a href="#cb15-1"></a><span class="co"># helper function to count target distribution inside tensor data sets</span></span>
<span id="cb15-2"><a href="#cb15-2"></a><span class="kw">def</span> target_count(tensor_dataset):</span>
<span id="cb15-3"><a href="#cb15-3"></a>    <span class="co"># set empty count containers</span></span>
<span id="cb15-4"><a href="#cb15-4"></a>    count0 <span class="op">=</span> <span class="dv">0</span></span>
<span id="cb15-5"><a href="#cb15-5"></a>    count1 <span class="op">=</span> <span class="dv">0</span></span>
<span id="cb15-6"><a href="#cb15-6"></a>    <span class="co"># set total container to turn into torch tensor</span></span>
<span id="cb15-7"><a href="#cb15-7"></a>    total <span class="op">=</span> []</span>
<span id="cb15-8"><a href="#cb15-8"></a>    <span class="co"># for every item in the tensor data set</span></span>
<span id="cb15-9"><a href="#cb15-9"></a>    <span class="cf">for</span> i <span class="kw">in</span> tensor_dataset:</span>
<span id="cb15-10"><a href="#cb15-10"></a>        <span class="co"># if the target is equal to 0</span></span>
<span id="cb15-11"><a href="#cb15-11"></a>        <span class="cf">if</span> i[<span class="dv">2</span>].item() <span class="op">==</span> <span class="dv">0</span>:</span>
<span id="cb15-12"><a href="#cb15-12"></a>            count0 <span class="op">+=</span> <span class="dv">1</span></span>
<span id="cb15-13"><a href="#cb15-13"></a>        <span class="co"># if the target is equal to 1</span></span>
<span id="cb15-14"><a href="#cb15-14"></a>        <span class="cf">elif</span> i[<span class="dv">2</span>].item() <span class="op">==</span> <span class="dv">1</span>:</span>
<span id="cb15-15"><a href="#cb15-15"></a>            count1 <span class="op">+=</span> <span class="dv">1</span></span>
<span id="cb15-16"><a href="#cb15-16"></a>    total.append(count0)</span>
<span id="cb15-17"><a href="#cb15-17"></a>    total.append(count1)</span>
<span id="cb15-18"><a href="#cb15-18"></a>    <span class="cf">return</span> torch.tensor(total)</span>
<span id="cb15-19"><a href="#cb15-19"></a></span>
<span id="cb15-20"><a href="#cb15-20"></a></span>
<span id="cb15-21"><a href="#cb15-21"></a><span class="co"># prepare weighted sampling for imbalanced classification</span></span>
<span id="cb15-22"><a href="#cb15-22"></a><span class="kw">def</span> create_sampler(target_tensor, tensor_dataset):</span>
<span id="cb15-23"><a href="#cb15-23"></a>    <span class="co"># generate class distributions [x, y]</span></span>
<span id="cb15-24"><a href="#cb15-24"></a>    class_sample_count <span class="op">=</span> target_count(tensor_dataset)</span>
<span id="cb15-25"><a href="#cb15-25"></a>    <span class="co"># weight</span></span>
<span id="cb15-26"><a href="#cb15-26"></a>    weight <span class="op">=</span> <span class="fl">1.</span> <span class="op">/</span> class_sample_count.<span class="bu">float</span>()</span>
<span id="cb15-27"><a href="#cb15-27"></a>    <span class="co"># produce weights for each observation in the data set</span></span>
<span id="cb15-28"><a href="#cb15-28"></a>    samples_weight <span class="op">=</span> torch.tensor([weight[t[<span class="dv">2</span>]] <span class="cf">for</span> t <span class="kw">in</span> tensor_dataset])</span>
<span id="cb15-29"><a href="#cb15-29"></a>    <span class="co"># prepare sampler</span></span>
<span id="cb15-30"><a href="#cb15-30"></a>    sampler <span class="op">=</span> torch.utils.data.WeightedRandomSampler(weights<span class="op">=</span>samples_weight,</span>
<span id="cb15-31"><a href="#cb15-31"></a>                                                     num_samples<span class="op">=</span><span class="bu">len</span>(samples_weight),</span>
<span id="cb15-32"><a href="#cb15-32"></a>                                                     replacement<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb15-33"><a href="#cb15-33"></a>    <span class="cf">return</span> sampler</span>
<span id="cb15-34"><a href="#cb15-34"></a></span>
<span id="cb15-35"><a href="#cb15-35"></a></span>
<span id="cb15-36"><a href="#cb15-36"></a><span class="co"># create samplers for just training</span></span>
<span id="cb15-37"><a href="#cb15-37"></a>train_sampler <span class="op">=</span> create_sampler(target_count(train_dataset), train_dataset)</span></code></pre></div>
<p>As you might have guessed, preparing data loaders for each of our train, dev, and test data sets is our next task.</p>
<div class="sourceCode" id="cb16"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb16-1"><a href="#cb16-1"></a><span class="co"># prepare data loaders</span></span>
<span id="cb16-2"><a href="#cb16-2"></a><span class="kw">def</span> data_loading(batch_size, data_set, <span class="op">**</span>kwargs):</span>
<span id="cb16-3"><a href="#cb16-3"></a>    <span class="co"># instantiate sampler and don&#39;t use last batch if uneven</span></span>
<span id="cb16-4"><a href="#cb16-4"></a>    temp_dataloader <span class="op">=</span> DataLoader(data_set,</span>
<span id="cb16-5"><a href="#cb16-5"></a>                                 batch_size<span class="op">=</span>batch_size,</span>
<span id="cb16-6"><a href="#cb16-6"></a>                                 drop_last<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb16-7"><a href="#cb16-7"></a>    <span class="cf">return</span> temp_dataloader</span>
<span id="cb16-8"><a href="#cb16-8"></a></span>
<span id="cb16-9"><a href="#cb16-9"></a></span>
<span id="cb16-10"><a href="#cb16-10"></a><span class="co"># create DataLoaders with samplers</span></span>
<span id="cb16-11"><a href="#cb16-11"></a>train_dataloader <span class="op">=</span> data_loading(batch_size<span class="op">=</span><span class="dv">16</span>,</span>
<span id="cb16-12"><a href="#cb16-12"></a>                                data_set<span class="op">=</span>train_dataset,</span>
<span id="cb16-13"><a href="#cb16-13"></a>                                sampler<span class="op">=</span>train_sampler)</span>
<span id="cb16-14"><a href="#cb16-14"></a></span>
<span id="cb16-15"><a href="#cb16-15"></a>valid_dataloader <span class="op">=</span> data_loading(batch_size<span class="op">=</span><span class="dv">16</span>,</span>
<span id="cb16-16"><a href="#cb16-16"></a>                                data_set<span class="op">=</span>val_dataset)</span>
<span id="cb16-17"><a href="#cb16-17"></a></span>
<span id="cb16-18"><a href="#cb16-18"></a>test_dataloader <span class="op">=</span> data_loading(batch_size<span class="op">=</span><span class="dv">16</span>,</span>
<span id="cb16-19"><a href="#cb16-19"></a>                               data_set<span class="op">=</span>test_dataset)</span></code></pre></div>
<p>Below we instantiate some helper functions for time keeping.</p>
<div class="sourceCode" id="cb17"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb17-1"><a href="#cb17-1"></a><span class="co"># time function</span></span>
<span id="cb17-2"><a href="#cb17-2"></a><span class="kw">def</span> format_time(elapsed):</span>
<span id="cb17-3"><a href="#cb17-3"></a>    <span class="co">&#39;&#39;&#39;</span></span>
<span id="cb17-4"><a href="#cb17-4"></a><span class="co">    Takes a time in seconds and returns a string hh:mm:ss</span></span>
<span id="cb17-5"><a href="#cb17-5"></a><span class="co">    &#39;&#39;&#39;</span></span>
<span id="cb17-6"><a href="#cb17-6"></a>    <span class="co"># round to the nearest second.</span></span>
<span id="cb17-7"><a href="#cb17-7"></a>    elapsed_rounded <span class="op">=</span> <span class="bu">int</span>(<span class="bu">round</span>((elapsed)))</span>
<span id="cb17-8"><a href="#cb17-8"></a>    <span class="co"># format as hh:mm:ss</span></span>
<span id="cb17-9"><a href="#cb17-9"></a>    <span class="cf">return</span> <span class="bu">str</span>(datetime.timedelta(seconds<span class="op">=</span>elapsed_rounded))</span></code></pre></div>
<p>Next, we load our DistilBERT model and tweak its hyperparameters.</p>
<div class="sourceCode" id="cb18"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb18-1"><a href="#cb18-1"></a><span class="co"># Load DistilBERT with a single a single linear classification layer</span></span>
<span id="cb18-2"><a href="#cb18-2"></a>model <span class="op">=</span> DistilBertForSequenceClassification.from_pretrained(</span>
<span id="cb18-3"><a href="#cb18-3"></a>    <span class="st">&quot;distilbert-base-cased&quot;</span>,</span>
<span id="cb18-4"><a href="#cb18-4"></a>    num_labels<span class="op">=</span><span class="dv">2</span>)</span>
<span id="cb18-5"><a href="#cb18-5"></a>    </span>
<span id="cb18-6"><a href="#cb18-6"></a><span class="co"># 25 trials optuna results: set ex-post</span></span>
<span id="cb18-7"><a href="#cb18-7"></a><span class="co"># batch_size: 16</span></span>
<span id="cb18-8"><a href="#cb18-8"></a><span class="co"># attention_dropout: 0.15000000000000002</span></span>
<span id="cb18-9"><a href="#cb18-9"></a><span class="co"># dropout: 0.1</span></span>
<span id="cb18-10"><a href="#cb18-10"></a><span class="co"># lr: 6.189759270321299e-06</span></span>
<span id="cb18-11"><a href="#cb18-11"></a><span class="co"># seq_classif_dropout: 0.4</span></span>
<span id="cb18-12"><a href="#cb18-12"></a><span class="co"># n_layers: 7</span></span>
<span id="cb18-13"><a href="#cb18-13"></a><span class="co"># weight_decay: 0.9</span></span>
<span id="cb18-14"><a href="#cb18-14"></a></span>
<span id="cb18-15"><a href="#cb18-15"></a><span class="co"># edit config items like this</span></span></code></pre></div>
<pre><code>## Some weights of the model checkpoint at distilbert-base-cased were not used when initializing DistilBertForSequenceClassification: [&#39;vocab_transform.weight&#39;, &#39;vocab_transform.bias&#39;, &#39;vocab_layer_norm.weight&#39;, &#39;vocab_layer_norm.bias&#39;, &#39;vocab_projector.weight&#39;, &#39;vocab_projector.bias&#39;]
## - This IS expected if you are initializing DistilBertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPretraining model).
## - This IS NOT expected if you are initializing DistilBertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
## Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-cased and are newly initialized: [&#39;pre_classifier.weight&#39;, &#39;pre_classifier.bias&#39;, &#39;classifier.weight&#39;, &#39;classifier.bias&#39;]
## You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.</code></pre>
<div class="sourceCode" id="cb20"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb20-1"><a href="#cb20-1"></a>model.config.__dict__[<span class="st">&#39;attention_dropout&#39;</span>] <span class="op">=</span> <span class="fl">0.15</span></span>
<span id="cb20-2"><a href="#cb20-2"></a>model.config.__dict__[<span class="st">&#39;dropout&#39;</span>] <span class="op">=</span> <span class="fl">0.1</span></span>
<span id="cb20-3"><a href="#cb20-3"></a>model.config.__dict__[<span class="st">&#39;seq_classif_dropout&#39;</span>] <span class="op">=</span> <span class="fl">0.4</span></span>
<span id="cb20-4"><a href="#cb20-4"></a>model.config.__dict__[<span class="st">&#39;n_layers&#39;</span>] <span class="op">=</span> <span class="dv">7</span></span></code></pre></div>
<p>Now we are almost ready to train. A few other preparatory objects are created like the loss criteria, epochs, the optimizer, and our optimizer scheduler.</p>
<div class="sourceCode" id="cb21"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb21-1"><a href="#cb21-1"></a><span class="co"># instantiate model - attach to GPU</span></span>
<span id="cb21-2"><a href="#cb21-2"></a>model.cuda()</span>
<span id="cb21-3"><a href="#cb21-3"></a></span>
<span id="cb21-4"><a href="#cb21-4"></a><span class="co"># optimizer</span></span></code></pre></div>
<pre><code>## DistilBertForSequenceClassification(
##   (distilbert): DistilBertModel(
##     (embeddings): Embeddings(
##       (word_embeddings): Embedding(28996, 768, padding_idx=0)
##       (position_embeddings): Embedding(512, 768)
##       (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
##       (dropout): Dropout(p=0.1, inplace=False)
##     )
##     (transformer): Transformer(
##       (layer): ModuleList(
##         (0): TransformerBlock(
##           (attention): MultiHeadSelfAttention(
##             (dropout): Dropout(p=0.1, inplace=False)
##             (q_lin): Linear(in_features=768, out_features=768, bias=True)
##             (k_lin): Linear(in_features=768, out_features=768, bias=True)
##             (v_lin): Linear(in_features=768, out_features=768, bias=True)
##             (out_lin): Linear(in_features=768, out_features=768, bias=True)
##           )
##           (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
##           (ffn): FFN(
##             (dropout): Dropout(p=0.1, inplace=False)
##             (lin1): Linear(in_features=768, out_features=3072, bias=True)
##             (lin2): Linear(in_features=3072, out_features=768, bias=True)
##           )
##           (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
##         )
##         (1): TransformerBlock(
##           (attention): MultiHeadSelfAttention(
##             (dropout): Dropout(p=0.1, inplace=False)
##             (q_lin): Linear(in_features=768, out_features=768, bias=True)
##             (k_lin): Linear(in_features=768, out_features=768, bias=True)
##             (v_lin): Linear(in_features=768, out_features=768, bias=True)
##             (out_lin): Linear(in_features=768, out_features=768, bias=True)
##           )
##           (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
##           (ffn): FFN(
##             (dropout): Dropout(p=0.1, inplace=False)
##             (lin1): Linear(in_features=768, out_features=3072, bias=True)
##             (lin2): Linear(in_features=3072, out_features=768, bias=True)
##           )
##           (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
##         )
##         (2): TransformerBlock(
##           (attention): MultiHeadSelfAttention(
##             (dropout): Dropout(p=0.1, inplace=False)
##             (q_lin): Linear(in_features=768, out_features=768, bias=True)
##             (k_lin): Linear(in_features=768, out_features=768, bias=True)
##             (v_lin): Linear(in_features=768, out_features=768, bias=True)
##             (out_lin): Linear(in_features=768, out_features=768, bias=True)
##           )
##           (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
##           (ffn): FFN(
##             (dropout): Dropout(p=0.1, inplace=False)
##             (lin1): Linear(in_features=768, out_features=3072, bias=True)
##             (lin2): Linear(in_features=3072, out_features=768, bias=True)
##           )
##           (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
##         )
##         (3): TransformerBlock(
##           (attention): MultiHeadSelfAttention(
##             (dropout): Dropout(p=0.1, inplace=False)
##             (q_lin): Linear(in_features=768, out_features=768, bias=True)
##             (k_lin): Linear(in_features=768, out_features=768, bias=True)
##             (v_lin): Linear(in_features=768, out_features=768, bias=True)
##             (out_lin): Linear(in_features=768, out_features=768, bias=True)
##           )
##           (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
##           (ffn): FFN(
##             (dropout): Dropout(p=0.1, inplace=False)
##             (lin1): Linear(in_features=768, out_features=3072, bias=True)
##             (lin2): Linear(in_features=3072, out_features=768, bias=True)
##           )
##           (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
##         )
##         (4): TransformerBlock(
##           (attention): MultiHeadSelfAttention(
##             (dropout): Dropout(p=0.1, inplace=False)
##             (q_lin): Linear(in_features=768, out_features=768, bias=True)
##             (k_lin): Linear(in_features=768, out_features=768, bias=True)
##             (v_lin): Linear(in_features=768, out_features=768, bias=True)
##             (out_lin): Linear(in_features=768, out_features=768, bias=True)
##           )
##           (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
##           (ffn): FFN(
##             (dropout): Dropout(p=0.1, inplace=False)
##             (lin1): Linear(in_features=768, out_features=3072, bias=True)
##             (lin2): Linear(in_features=3072, out_features=768, bias=True)
##           )
##           (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
##         )
##         (5): TransformerBlock(
##           (attention): MultiHeadSelfAttention(
##             (dropout): Dropout(p=0.1, inplace=False)
##             (q_lin): Linear(in_features=768, out_features=768, bias=True)
##             (k_lin): Linear(in_features=768, out_features=768, bias=True)
##             (v_lin): Linear(in_features=768, out_features=768, bias=True)
##             (out_lin): Linear(in_features=768, out_features=768, bias=True)
##           )
##           (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
##           (ffn): FFN(
##             (dropout): Dropout(p=0.1, inplace=False)
##             (lin1): Linear(in_features=768, out_features=3072, bias=True)
##             (lin2): Linear(in_features=3072, out_features=768, bias=True)
##           )
##           (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
##         )
##       )
##     )
##   )
##   (pre_classifier): Linear(in_features=768, out_features=768, bias=True)
##   (classifier): Linear(in_features=768, out_features=2, bias=True)
##   (dropout): Dropout(p=0.2, inplace=False)
## )</code></pre>
<div class="sourceCode" id="cb23"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb23-1"><a href="#cb23-1"></a>optimizer <span class="op">=</span> AdamW(model.parameters(),</span>
<span id="cb23-2"><a href="#cb23-2"></a>                  lr<span class="op">=</span><span class="fl">6.189759270321299e-06</span>,</span>
<span id="cb23-3"><a href="#cb23-3"></a>                  weight_decay<span class="op">=</span><span class="fl">0.9</span></span>
<span id="cb23-4"><a href="#cb23-4"></a>                )</span>
<span id="cb23-5"><a href="#cb23-5"></a></span>
<span id="cb23-6"><a href="#cb23-6"></a><span class="co"># set number of epochs</span></span>
<span id="cb23-7"><a href="#cb23-7"></a>epochs <span class="op">=</span> <span class="dv">3</span></span>
<span id="cb23-8"><a href="#cb23-8"></a></span>
<span id="cb23-9"><a href="#cb23-9"></a><span class="co"># set LR scheduler</span></span>
<span id="cb23-10"><a href="#cb23-10"></a>total_steps <span class="op">=</span> <span class="bu">len</span>(train_dataloader) <span class="op">*</span> epochs</span>
<span id="cb23-11"><a href="#cb23-11"></a>scheduler <span class="op">=</span> get_linear_schedule_with_warmup(optimizer,</span>
<span id="cb23-12"><a href="#cb23-12"></a>                                            num_warmup_steps<span class="op">=</span><span class="dv">0</span>,</span>
<span id="cb23-13"><a href="#cb23-13"></a>                                            num_training_steps<span class="op">=</span>total_steps)</span>
<span id="cb23-14"><a href="#cb23-14"></a></span>
<span id="cb23-15"><a href="#cb23-15"></a><span class="co"># create gradient scaler for mixed precision</span></span>
<span id="cb23-16"><a href="#cb23-16"></a>scaler <span class="op">=</span> GradScaler()</span></code></pre></div>
<p>Finally we are ready to train. Two containers are created to store the results of each training and validation epoch</p>
<div class="sourceCode" id="cb24"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb24-1"><a href="#cb24-1"></a><span class="co"># create training result storage</span></span>
<span id="cb24-2"><a href="#cb24-2"></a>training_stats <span class="op">=</span> []</span>
<span id="cb24-3"><a href="#cb24-3"></a>valid_stats <span class="op">=</span> []</span>
<span id="cb24-4"><a href="#cb24-4"></a>best_valid_loss <span class="op">=</span> <span class="bu">float</span>(<span class="st">&#39;inf&#39;</span>)</span>
<span id="cb24-5"><a href="#cb24-5"></a></span>
<span id="cb24-6"><a href="#cb24-6"></a><span class="co"># for each epoch</span></span>
<span id="cb24-7"><a href="#cb24-7"></a><span class="cf">for</span> epoch <span class="kw">in</span> <span class="bu">range</span>(epochs):</span>
<span id="cb24-8"><a href="#cb24-8"></a>    <span class="co"># train</span></span>
<span id="cb24-9"><a href="#cb24-9"></a>    train(model, train_dataloader, optimizer)</span>
<span id="cb24-10"><a href="#cb24-10"></a>    <span class="co"># validate</span></span>
<span id="cb24-11"><a href="#cb24-11"></a>    validating(model, valid_dataloader)</span>
<span id="cb24-12"><a href="#cb24-12"></a>    <span class="co"># check validation loss</span></span>
<span id="cb24-13"><a href="#cb24-13"></a>    <span class="cf">if</span> valid_stats[epoch][<span class="st">&#39;Val Loss&#39;</span>] <span class="op">&lt;</span> best_valid_loss:</span>
<span id="cb24-14"><a href="#cb24-14"></a>        best_valid_loss <span class="op">=</span> valid_stats[epoch][<span class="st">&#39;Val Loss&#39;</span>]</span>
<span id="cb24-15"><a href="#cb24-15"></a>        <span class="co"># save best model for use later</span></span>
<span id="cb24-16"><a href="#cb24-16"></a>        torch.save(model.state_dict(), <span class="st">&#39;distilbert-model1.pt&#39;</span>)  <span class="co"># torch save</span></span>
<span id="cb24-17"><a href="#cb24-17"></a>        model_to_save <span class="op">=</span> model.module <span class="cf">if</span> <span class="bu">hasattr</span>(model, <span class="st">&#39;module&#39;</span>) <span class="cf">else</span> model</span>
<span id="cb24-18"><a href="#cb24-18"></a>        model_to_save.save_pretrained(<span class="st">&#39;./model_save/&#39;</span>)  <span class="co"># transformers save</span></span>
<span id="cb24-19"><a href="#cb24-19"></a>        tokenizer.save_pretrained(<span class="st">&#39;./model_save/&#39;</span>)  <span class="co"># transformers save</span></span></code></pre></div>
<pre><code>## 
## ======== Epoch 1 / 3 ========
## Training...
##   Batch    40  of    502.
##   Batch    80  of    502.
##   Batch   120  of    502.
##   Batch   160  of    502.
##   Batch   200  of    502.
##   Batch   240  of    502.
##   Batch   280  of    502.
##   Batch   320  of    502.
##   Batch   360  of    502.
##   Batch   400  of    502.
##   Batch   440  of    502.
##   Batch   480  of    502.
## 
## summary results
## epoch | trn loss | trn f1 | trn time 
##     1 | 0.33346 | 0.85568 | 0:01:20
## [{&#39;Train Loss&#39;: 0.33346027665701045, &#39;Train F1&#39;: 0.8556771397805686}]
## 
## Running Validation...
## 
## summary results
## epoch | val loss | val f1 | val time
##     1 | 0.24317 | 0.90132 | 0:00:05
## [{&#39;Val Loss&#39;: 0.24317258638480016, &#39;Val Accur.&#39;: 0.8961693548387096, &#39;Val precision&#39;: 0.9181362152632312, &#39;Val recall&#39;: 0.8961693548387096, &#39;Val F1&#39;: 0.901324986534041}]
## (&#39;./model_save/vocab.txt&#39;, &#39;./model_save/special_tokens_map.json&#39;, &#39;./model_save/added_tokens.json&#39;)
## 
## ======== Epoch 2 / 3 ========
## Training...
##   Batch    40  of    502.
##   Batch    80  of    502.
##   Batch   120  of    502.
##   Batch   160  of    502.
##   Batch   200  of    502.
##   Batch   240  of    502.
##   Batch   280  of    502.
##   Batch   320  of    502.
##   Batch   360  of    502.
##   Batch   400  of    502.
##   Batch   440  of    502.
##   Batch   480  of    502.
## 
## summary results
## epoch | trn loss | trn f1 | trn time 
##     2 | 0.25252 | 0.88742 | 0:01:20
## [{&#39;Train Loss&#39;: 0.33346027665701045, &#39;Train F1&#39;: 0.8556771397805686}, {&#39;Train Loss&#39;: 0.25252413576045835, &#39;Train F1&#39;: 0.8874199802234229}]
## 
## Running Validation...
## 
## summary results
## epoch | val loss | val f1 | val time
##     2 | 0.23641 | 0.89860 | 0:00:05
## [{&#39;Val Loss&#39;: 0.24317258638480016, &#39;Val Accur.&#39;: 0.8961693548387096, &#39;Val precision&#39;: 0.9181362152632312, &#39;Val recall&#39;: 0.8961693548387096, &#39;Val F1&#39;: 0.901324986534041}, {&#39;Val Loss&#39;: 0.2364108489165383, &#39;Val Accur.&#39;: 0.8951612903225806, &#39;Val precision&#39;: 0.9119889351240156, &#39;Val recall&#39;: 0.8951612903225806, &#39;Val F1&#39;: 0.8986026195225786}]
## (&#39;./model_save/vocab.txt&#39;, &#39;./model_save/special_tokens_map.json&#39;, &#39;./model_save/added_tokens.json&#39;)
## 
## ======== Epoch 3 / 3 ========
## Training...
##   Batch    40  of    502.
##   Batch    80  of    502.
##   Batch   120  of    502.
##   Batch   160  of    502.
##   Batch   200  of    502.
##   Batch   240  of    502.
##   Batch   280  of    502.
##   Batch   320  of    502.
##   Batch   360  of    502.
##   Batch   400  of    502.
##   Batch   440  of    502.
##   Batch   480  of    502.
## 
## summary results
## epoch | trn loss | trn f1 | trn time 
##     3 | 0.22820 | 0.89896 | 0:01:20
## [{&#39;Train Loss&#39;: 0.33346027665701045, &#39;Train F1&#39;: 0.8556771397805686}, {&#39;Train Loss&#39;: 0.25252413576045835, &#39;Train F1&#39;: 0.8874199802234229}, {&#39;Train Loss&#39;: 0.22820203985454907, &#39;Train F1&#39;: 0.8989584674833365}]
## 
## Running Validation...
## 
## summary results
## epoch | val loss | val f1 | val time
##     3 | 0.23543 | 0.90296 | 0:00:05
## [{&#39;Val Loss&#39;: 0.24317258638480016, &#39;Val Accur.&#39;: 0.8961693548387096, &#39;Val precision&#39;: 0.9181362152632312, &#39;Val recall&#39;: 0.8961693548387096, &#39;Val F1&#39;: 0.901324986534041}, {&#39;Val Loss&#39;: 0.2364108489165383, &#39;Val Accur.&#39;: 0.8951612903225806, &#39;Val precision&#39;: 0.9119889351240156, &#39;Val recall&#39;: 0.8951612903225806, &#39;Val F1&#39;: 0.8986026195225786}, {&#39;Val Loss&#39;: 0.23543193816177307, &#39;Val Accur.&#39;: 0.9012096774193549, &#39;Val precision&#39;: 0.9158594094077964, &#39;Val recall&#39;: 0.9012096774193549, &#39;Val F1&#39;: 0.9029580560516259}]
## (&#39;./model_save/vocab.txt&#39;, &#39;./model_save/special_tokens_map.json&#39;, &#39;./model_save/added_tokens.json&#39;)</code></pre>
<p>After training, we organize the results nicely in <code>pandas</code>.</p>
<div class="sourceCode" id="cb26"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb26-1"><a href="#cb26-1"></a><span class="co"># organize results</span></span>
<span id="cb26-2"><a href="#cb26-2"></a>pd.set_option(<span class="st">&#39;precision&#39;</span>, <span class="dv">3</span>)</span>
<span id="cb26-3"><a href="#cb26-3"></a>df_train_stats <span class="op">=</span> pd.DataFrame(data<span class="op">=</span>training_stats)</span>
<span id="cb26-4"><a href="#cb26-4"></a>df_valid_stats <span class="op">=</span> pd.DataFrame(data<span class="op">=</span>valid_stats)</span>
<span id="cb26-5"><a href="#cb26-5"></a>df_stats <span class="op">=</span> pd.concat([df_train_stats, df_valid_stats], axis<span class="op">=</span><span class="dv">1</span>)</span>
<span id="cb26-6"><a href="#cb26-6"></a>df_stats.insert(<span class="dv">0</span>, <span class="st">&#39;Epoch&#39;</span>, <span class="bu">range</span>(<span class="dv">1</span>, <span class="bu">len</span>(df_stats)<span class="op">+</span><span class="dv">1</span>))</span>
<span id="cb26-7"><a href="#cb26-7"></a>df_stats <span class="op">=</span> df_stats.set_index(<span class="st">&#39;Epoch&#39;</span>)</span>
<span id="cb26-8"><a href="#cb26-8"></a>df_stats</span></code></pre></div>
<pre><code>##        Train Loss  Train F1  Val Loss  ...  Val precision  Val recall  Val F1
## Epoch                                  ...                                   
## 1           0.333     0.856     0.243  ...          0.918       0.896   0.901
## 2           0.253     0.887     0.236  ...          0.912       0.895   0.899
## 3           0.228     0.899     0.235  ...          0.916       0.901   0.903
## 
## [3 rows x 7 columns]</code></pre>
<div class="sourceCode" id="cb28"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb28-1"><a href="#cb28-1"></a><span class="co"># plot results</span></span>
<span id="cb28-2"><a href="#cb28-2"></a><span class="kw">def</span> plot_results(df):</span>
<span id="cb28-3"><a href="#cb28-3"></a>    <span class="co"># styling from seaborn.</span></span>
<span id="cb28-4"><a href="#cb28-4"></a>    sns.<span class="bu">set</span>(style<span class="op">=</span><span class="st">&#39;darkgrid&#39;</span>)</span>
<span id="cb28-5"><a href="#cb28-5"></a>    <span class="co"># uncrease the plot size and font size.</span></span>
<span id="cb28-6"><a href="#cb28-6"></a>    sns.<span class="bu">set</span>(font_scale<span class="op">=</span><span class="fl">1.5</span>)</span>
<span id="cb28-7"><a href="#cb28-7"></a>    plt.rcParams[<span class="st">&quot;figure.figsize&quot;</span>] <span class="op">=</span> (<span class="dv">12</span>,<span class="dv">6</span>)</span>
<span id="cb28-8"><a href="#cb28-8"></a></span>
<span id="cb28-9"><a href="#cb28-9"></a>    <span class="co"># plot the learning curve.</span></span>
<span id="cb28-10"><a href="#cb28-10"></a>    plt.plot(df_stats[<span class="st">&#39;Train Loss&#39;</span>], <span class="st">&#39;b-o&#39;</span>, label<span class="op">=</span><span class="st">&quot;Training&quot;</span>)</span>
<span id="cb28-11"><a href="#cb28-11"></a>    plt.plot(df_stats[<span class="st">&#39;Val Loss&#39;</span>], <span class="st">&#39;g-o&#39;</span>, label<span class="op">=</span><span class="st">&quot;Validation&quot;</span>)</span>
<span id="cb28-12"><a href="#cb28-12"></a></span>
<span id="cb28-13"><a href="#cb28-13"></a>    <span class="co"># Label the plot.</span></span>
<span id="cb28-14"><a href="#cb28-14"></a>    plt.title(<span class="st">&quot;Training &amp; Validation Loss&quot;</span>)</span>
<span id="cb28-15"><a href="#cb28-15"></a>    plt.xlabel(<span class="st">&quot;Epoch&quot;</span>)</span>
<span id="cb28-16"><a href="#cb28-16"></a>    plt.ylabel(<span class="st">&quot;Loss&quot;</span>)</span>
<span id="cb28-17"><a href="#cb28-17"></a>    plt.legend()</span>
<span id="cb28-18"><a href="#cb28-18"></a>    plt.xticks(<span class="bu">list</span>(<span class="bu">range</span>(<span class="dv">1</span>, epochs<span class="op">+</span><span class="dv">1</span>)))</span>
<span id="cb28-19"><a href="#cb28-19"></a>    <span class="cf">return</span> plt.show()</span>
<span id="cb28-20"><a href="#cb28-20"></a></span>
<span id="cb28-21"><a href="#cb28-21"></a></span>
<span id="cb28-22"><a href="#cb28-22"></a>plot_results(df_stats)</span></code></pre></div>
<div class="figure">
<img src="data:image/png;base64,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" style="width:75.0%" alt />
<p class="caption">Training Results</p>
</div>
<p>And lastly run our final test:</p>
<div class="sourceCode" id="cb29"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb29-1"><a href="#cb29-1"></a><span class="co"># test the model</span></span>
<span id="cb29-2"><a href="#cb29-2"></a>test_stats <span class="op">=</span> []</span>
<span id="cb29-3"><a href="#cb29-3"></a>model.load_state_dict(torch.load(<span class="st">&#39;distilbert-model1.pt&#39;</span>))</span></code></pre></div>
<pre><code>## &lt;All keys matched successfully&gt;</code></pre>
<div class="sourceCode" id="cb31"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb31-1"><a href="#cb31-1"></a>testing(model, test_dataloader)</span></code></pre></div>
<pre><code>## 
## Running Testing...
## [{&#39;Test Loss&#39;: 0.2900478038336, &#39;Test Accur.&#39;: 0.8729838709677419, &#39;Test precision&#39;: 0.8973139092090703, &#39;Test recall&#39;: 0.8729838709677419, &#39;Test F1&#39;: 0.8769558466879177}]</code></pre>
<div class="sourceCode" id="cb33"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb33-1"><a href="#cb33-1"></a>df_test_stats <span class="op">=</span> pd.DataFrame(data<span class="op">=</span>test_stats)</span>
<span id="cb33-2"><a href="#cb33-2"></a>df_test_stats  </span></code></pre></div>
<pre><code>##    Test Loss  Test Accur.  Test precision  Test recall  Test F1
## 0       0.29        0.873           0.897        0.873    0.877</code></pre>
</div>
</div>
<div id="distilbert-hyperband-and-asha-hyperparameter-search-with-optuna" class="section level1" number="3">
<h1 number="3"><span class="header-section-number">3</span> DistilBERT: Hyperband and ASHA Hyperparameter Search with Optuna</h1>
<p>The code below shows how we can use state-of-the-art pruning and search algorithms to improve our model’s performance through hyperparameter selection.</p>
<div class="sourceCode" id="cb35"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb35-1"><a href="#cb35-1"></a><span class="co"># fine tune DistilBERT</span></span>
<span id="cb35-2"><a href="#cb35-2"></a>training_stats <span class="op">=</span> []</span>
<span id="cb35-3"><a href="#cb35-3"></a>valid_stats <span class="op">=</span> []</span>
<span id="cb35-4"><a href="#cb35-4"></a>epochs <span class="op">=</span> <span class="dv">3</span></span>
<span id="cb35-5"><a href="#cb35-5"></a></span>
<span id="cb35-6"><a href="#cb35-6"></a><span class="co"># create gradient scaler for mixed precision</span></span>
<span id="cb35-7"><a href="#cb35-7"></a>scaler <span class="op">=</span> GradScaler()</span>
<span id="cb35-8"><a href="#cb35-8"></a><span class="kw">def</span> objective(trial):</span>
<span id="cb35-9"><a href="#cb35-9"></a></span>
<span id="cb35-10"><a href="#cb35-10"></a>    model <span class="op">=</span> DistilBertForSequenceClassification.from_pretrained(</span>
<span id="cb35-11"><a href="#cb35-11"></a>        <span class="st">&quot;distilbert-base-cased&quot;</span>,</span>
<span id="cb35-12"><a href="#cb35-12"></a>        num_labels<span class="op">=</span><span class="dv">2</span>)</span>
<span id="cb35-13"><a href="#cb35-13"></a></span>
<span id="cb35-14"><a href="#cb35-14"></a>    <span class="co"># instantiate model - attach to GPU</span></span>
<span id="cb35-15"><a href="#cb35-15"></a>    model.cuda()</span>
<span id="cb35-16"><a href="#cb35-16"></a></span>
<span id="cb35-17"><a href="#cb35-17"></a>    batch_size <span class="op">=</span> trial.suggest_int(<span class="st">&#39;batch_size&#39;</span>, low<span class="op">=</span><span class="dv">8</span>, high<span class="op">=</span><span class="dv">22</span>, step<span class="op">=</span><span class="dv">4</span>)</span>
<span id="cb35-18"><a href="#cb35-18"></a>    attention_dropout <span class="op">=</span> trial.suggest_float(<span class="st">&#39;attention_dropout&#39;</span>, low<span class="op">=</span><span class="fl">0.1</span>, high<span class="op">=</span><span class="fl">0.4</span>, step<span class="op">=</span><span class="fl">0.05</span>)</span>
<span id="cb35-19"><a href="#cb35-19"></a>    dropout <span class="op">=</span> trial.suggest_float(<span class="st">&#39;dropout&#39;</span>, low<span class="op">=</span><span class="fl">0.1</span>, high<span class="op">=</span><span class="fl">0.4</span>, step<span class="op">=</span><span class="fl">0.05</span>)</span>
<span id="cb35-20"><a href="#cb35-20"></a>    learning_rate <span class="op">=</span> trial.suggest_loguniform(<span class="st">&#39;lr&#39;</span>, <span class="fl">5e-6</span>, <span class="fl">2e-4</span>)</span>
<span id="cb35-21"><a href="#cb35-21"></a>    seq_classif_dropout <span class="op">=</span>  trial.suggest_float(<span class="st">&#39;seq_classif_dropout&#39;</span>, low<span class="op">=</span><span class="fl">0.1</span>, high<span class="op">=</span><span class="fl">0.4</span>, step<span class="op">=</span><span class="fl">0.05</span>)</span>
<span id="cb35-22"><a href="#cb35-22"></a>    n_layers <span class="op">=</span> trial.suggest_int(<span class="st">&#39;n_layers&#39;</span>, low<span class="op">=</span><span class="dv">6</span>, high<span class="op">=</span><span class="dv">8</span>, step<span class="op">=</span><span class="dv">1</span>)</span>
<span id="cb35-23"><a href="#cb35-23"></a>    weight_decay <span class="op">=</span> trial.suggest_float(<span class="st">&#39;weight_decay&#39;</span>, low<span class="op">=</span><span class="fl">0.5</span>, high<span class="op">=</span><span class="dv">1</span>, step<span class="op">=</span><span class="fl">0.05</span>)</span>
<span id="cb35-24"><a href="#cb35-24"></a></span>
<span id="cb35-25"><a href="#cb35-25"></a>    model.config.__dict__[<span class="st">&#39;attention_dropout&#39;</span>] <span class="op">=</span> attention_dropout</span>
<span id="cb35-26"><a href="#cb35-26"></a>    model.config.__dict__[<span class="st">&#39;dropout&#39;</span>] <span class="op">=</span> dropout</span>
<span id="cb35-27"><a href="#cb35-27"></a>    model.config.__dict__[<span class="st">&#39;seq_classif_dropout&#39;</span>] <span class="op">=</span> seq_classif_dropout</span>
<span id="cb35-28"><a href="#cb35-28"></a>    model.config.__dict__[<span class="st">&#39;n_layers&#39;</span>] <span class="op">=</span> n_layers</span>
<span id="cb35-29"><a href="#cb35-29"></a></span>
<span id="cb35-30"><a href="#cb35-30"></a>    <span class="co"># Generate the model.</span></span>
<span id="cb35-31"><a href="#cb35-31"></a>    train_dataloader <span class="op">=</span> data_loading(batch_size<span class="op">=</span>batch_size,</span>
<span id="cb35-32"><a href="#cb35-32"></a>                                    data_set<span class="op">=</span>train_dataset,</span>
<span id="cb35-33"><a href="#cb35-33"></a>                                    sampler<span class="op">=</span>train_sampler)</span>
<span id="cb35-34"><a href="#cb35-34"></a></span>
<span id="cb35-35"><a href="#cb35-35"></a>    valid_dataloader <span class="op">=</span> data_loading(batch_size<span class="op">=</span>batch_size,</span>
<span id="cb35-36"><a href="#cb35-36"></a>                                    data_set<span class="op">=</span>val_dataset)</span>
<span id="cb35-37"><a href="#cb35-37"></a></span>
<span id="cb35-38"><a href="#cb35-38"></a>    <span class="co"># optimizer</span></span>
<span id="cb35-39"><a href="#cb35-39"></a>    optimizer <span class="op">=</span> AdamW(model.parameters(),</span>
<span id="cb35-40"><a href="#cb35-40"></a>                      lr<span class="op">=</span>learning_rate,  <span class="co"># 2e-5 optimal from https://arxiv.org/pdf/1904.08398.pdf</span></span>
<span id="cb35-41"><a href="#cb35-41"></a>                      weight_decay<span class="op">=</span>weight_decay)</span>
<span id="cb35-42"><a href="#cb35-42"></a></span>
<span id="cb35-43"><a href="#cb35-43"></a>    <span class="co"># set LR scheduler</span></span>
<span id="cb35-44"><a href="#cb35-44"></a>    total_steps <span class="op">=</span> <span class="bu">len</span>(train_dataloader) <span class="op">*</span> epochs</span>
<span id="cb35-45"><a href="#cb35-45"></a>    <span class="kw">global</span> scheduler</span>
<span id="cb35-46"><a href="#cb35-46"></a>    scheduler <span class="op">=</span> get_linear_schedule_with_warmup(optimizer,</span>
<span id="cb35-47"><a href="#cb35-47"></a>                                                num_warmup_steps<span class="op">=</span><span class="dv">0</span>,</span>
<span id="cb35-48"><a href="#cb35-48"></a>                                                num_training_steps<span class="op">=</span>total_steps)</span>
<span id="cb35-49"><a href="#cb35-49"></a></span>
<span id="cb35-50"><a href="#cb35-50"></a>    <span class="kw">global</span> epoch</span>
<span id="cb35-51"><a href="#cb35-51"></a>    <span class="cf">for</span> epoch <span class="kw">in</span> <span class="bu">range</span>(epochs):</span>
<span id="cb35-52"><a href="#cb35-52"></a>        train(model, train_dataloader, optimizer)</span>
<span id="cb35-53"><a href="#cb35-53"></a>        validating(model, valid_dataloader)</span>
<span id="cb35-54"><a href="#cb35-54"></a></span>
<span id="cb35-55"><a href="#cb35-55"></a>    trial.report(avg_val_loss, epoch)</span>
<span id="cb35-56"><a href="#cb35-56"></a></span>
<span id="cb35-57"><a href="#cb35-57"></a>    <span class="co"># Handle pruning based on the intermediate value.</span></span>
<span id="cb35-58"><a href="#cb35-58"></a>    <span class="cf">if</span> trial.should_prune():</span>
<span id="cb35-59"><a href="#cb35-59"></a>        <span class="cf">raise</span> optuna.exceptions.TrialPruned()</span>
<span id="cb35-60"><a href="#cb35-60"></a></span>
<span id="cb35-61"><a href="#cb35-61"></a>    <span class="cf">return</span> avg_val_loss</span>
<span id="cb35-62"><a href="#cb35-62"></a></span>
<span id="cb35-63"><a href="#cb35-63"></a></span>
<span id="cb35-64"><a href="#cb35-64"></a>study <span class="op">=</span> optuna.create_study(direction<span class="op">=</span><span class="st">&quot;minimize&quot;</span>,</span>
<span id="cb35-65"><a href="#cb35-65"></a>                            sampler<span class="op">=</span>TPESampler(),</span>
<span id="cb35-66"><a href="#cb35-66"></a>                            pruner<span class="op">=</span>optuna.pruners.HyperbandPruner(min_resource<span class="op">=</span><span class="dv">1</span>,</span>
<span id="cb35-67"><a href="#cb35-67"></a>                                                                  max_resource<span class="op">=</span><span class="dv">3</span>,</span>
<span id="cb35-68"><a href="#cb35-68"></a>                                                                  reduction_factor<span class="op">=</span><span class="dv">3</span>,</span>
<span id="cb35-69"><a href="#cb35-69"></a>                                                                  ))</span>
<span id="cb35-70"><a href="#cb35-70"></a>study.optimize(objective, n_trials<span class="op">=</span><span class="dv">25</span>)</span>
<span id="cb35-71"><a href="#cb35-71"></a></span>
<span id="cb35-72"><a href="#cb35-72"></a></span>
<span id="cb35-73"><a href="#cb35-73"></a>pruned_trials <span class="op">=</span> [t <span class="cf">for</span> t <span class="kw">in</span> study.trials <span class="cf">if</span> t.state <span class="op">==</span> optuna.trial.TrialState.PRUNED]</span>
<span id="cb35-74"><a href="#cb35-74"></a>complete_trials <span class="op">=</span> [t <span class="cf">for</span> t <span class="kw">in</span> study.trials <span class="cf">if</span> t.state <span class="op">==</span> optuna.trial.TrialState.COMPLETE]</span>
<span id="cb35-75"><a href="#cb35-75"></a></span>
<span id="cb35-76"><a href="#cb35-76"></a><span class="bu">print</span>(<span class="st">&quot;Study statistics: &quot;</span>)</span>
<span id="cb35-77"><a href="#cb35-77"></a><span class="bu">print</span>(<span class="st">&quot;  Number of finished trials: &quot;</span>, <span class="bu">len</span>(study.trials))</span>
<span id="cb35-78"><a href="#cb35-78"></a><span class="bu">print</span>(<span class="st">&quot;  Number of pruned trials: &quot;</span>, <span class="bu">len</span>(pruned_trials))</span>
<span id="cb35-79"><a href="#cb35-79"></a><span class="bu">print</span>(<span class="st">&quot;  Number of complete trials: &quot;</span>, <span class="bu">len</span>(complete_trials))</span>
<span id="cb35-80"><a href="#cb35-80"></a></span>
<span id="cb35-81"><a href="#cb35-81"></a><span class="bu">print</span>(<span class="st">&quot;Best trial:&quot;</span>)</span>
<span id="cb35-82"><a href="#cb35-82"></a>trial <span class="op">=</span> study.best_trial</span>
<span id="cb35-83"><a href="#cb35-83"></a></span>
<span id="cb35-84"><a href="#cb35-84"></a><span class="bu">print</span>(<span class="st">&quot;  Value: &quot;</span>, trial.value)</span>
<span id="cb35-85"><a href="#cb35-85"></a></span>
<span id="cb35-86"><a href="#cb35-86"></a><span class="bu">print</span>(<span class="st">&quot;  Params: &quot;</span>)</span>
<span id="cb35-87"><a href="#cb35-87"></a><span class="cf">for</span> key, value <span class="kw">in</span> trial.params.items():</span>
<span id="cb35-88"><a href="#cb35-88"></a>    <span class="bu">print</span>(<span class="st">&quot;    </span><span class="sc">{}</span><span class="st">: </span><span class="sc">{}</span><span class="st">&quot;</span>.<span class="bu">format</span>(key, value))</span></code></pre></div>
</div>
<div id="sources" class="section level1" number="4">
<h1 number="4"><span class="header-section-number">4</span> Sources</h1>
<ul>
<li>Devlin, Jacob, Ming-Wei Chang, Kenton Lee, and Kristina Toutanova. “Bert: Pre-training of deep bidirectional transformers for language understanding.” arXiv preprint arXiv:1810.04805 (2018).</li>
</ul>
</div>



<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    script.src  = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML";
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>

</body>
</html>
