---
title: 'Text Generation: DistilGPT-2'
permalink: /NLP/DistilGPT2
date: 2020-07-16
tags:
  - Applied Machine Learning
  - Natural Language Processing
---

Language models are trained to predict the probability the next token considering the preceding tokens that came before it. A token can be a word, a letter, or a subcomponent of a word. In this guide, we use the a [decoder-only language model](/applied_nlp/gpt2.html){:target="_blank"} transformer to predict text from our novel insurgent propaganda corpus.