---
title: 'Classification: Hierarchical Attention Networks'
permalink: /NLP/HAN
date: 2020-07-19
tags:
  - Applied Machine Learning
  - Natural Language Processing
---

Hierarchical Attention Networks (HAN), as its name suggests, have a hierarchical structure that reflects the hierarchical nature of documents. It has two levels of attention mechanisms that are applied at the word and sentence level which afford it the differential ability to capture more and less important content which evaluating documents. In this guide, we walk through how to create a [Hieararchical Attention Network](/applied_nlp/HAN.html){:target="_blank"} in PyTorch and as well as how to create and structure our data appropriately.
